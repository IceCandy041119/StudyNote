# ComputerNetworkingNotes

## 目录

- [导论](#导论)
- [应用层](#应用层)
- [运输层](#运输层)
- [网络层](#网络层)
- [链路层和局域网](#链路层和局域网)
- [物理层](#物理层)
- [无线网络和移动网络](#无线网络和移动网络)
- [网络安全](#网络安全)

## 导论

### 1. 什么是因特网

什么因特网?回答这个问题有两种方式：
- 具体构成描述
- 服务描述

> [!qusition] Internet and internet
> Internet指代的是现如今最大互联网络,internet表示多个网络的互相连接.     

#### 1.1 具体构成描述

因特网是一个世界范围的计算机网络,即一个互联了遍及全世界的数十亿计算设备的网络.       

计算机网络由**节点**和**边**构成的.    

**节点**：    
- 端系统(又称主机)及其上运行的应用程序
- 分组交换设备(路由器(通常用于网络核心中),交换机(通常用于接入网中))等网络设备(网络负载设备...)

**边(通信链路)**：
- 接入网链路：主机连接到互联网的链路
- 主干链路：路由器间的链路

不同的链路以不同的速率传输数据,链路的传输速率以**比特/秒(bit/s)** 度量.   

端系统通过**因特网服务提供商(Internet Service Provider,ISP)接入互联网**,每个ISP自身就是一个由多台分组交换机和多段通信链路组成的网络.不仅为端系统提供接入服务,也为内容提供者提供接入服务.因为**因特网把各处的端系统彼此连接起来,因此ISP也必须互联,较低层ISP通过国家的,国际的较高层ISP互联起来,较高层则直接互联**.     

端系统,分组交换机和其他因特网部件都要运行多个**协议**,这些协议控制因特网中的信息的接收和发送.最为重要的为：
- TCP(Transmission Control Protocol),传输控制协议
- IP(Internet Protocol),网际协议

为了能实现全球互联,一个统一的标准是很重要的,**因特网标准(Internet Standard)** 由**因特网工程任务组(Internet Engineering Task Force,IETF)** 研发,IETF的标准文档称为**请求评论(Request For Comment,RFC)**,目的是解决因特网先驱者面临的网络和协议问题.       

#### 1.2 服务描述

将网络分为由**应用程序**和**为应用程序提供服务的基础设施**构成.      

应用程序：    
- 社交媒体
- 视频会议
- 游戏
- 等等

基础设施(即应用层以下的协议实体)：     
- 套接字系统
- 通信链路
- 网络交换设备
- 等等

#### 1.3 什么是协议

协议,对等实体间进行数据交换而建立的规则,标准或约定.主要由三个要素构成：
- 语法,即数据与控制信息的结果或格式
- 语义,即需要发出各种控制信息,完成何种动作以及做出何种响应
- 同步,即事件实现顺序的详细说明

就比如说你要追求一个人,首先要向她问好,然后根据她的回应来做出相应的动作,这是面向连接的TCP方式,你也可以直接向她表明心意,这是无连接的UDP方式.     

>掌握计算机网络知识的过程就是理解网络协议的构成,原理和工作方式的过程.      

### 2. 网络边缘

网络的边缘由**端系统**组成.因为处于网络的边缘所以叫端系统.     

**端系统**也称为**主机**,因为它们容纳应用程序,如Web浏览器程序,Web服务器程序,电子邮件客户程序或电子邮件服务器程序等.也包括了计算机,服务器和移动计算机,此外也有非传统物品也作为了端系统,如家电,汽车.       
  
**主机**有时又被进一步分为：**客户机**和**服务器**.众多的服务器构成了,服务器农场(又称服务器集群,server farm).           

一般的网络工作模式有**CS模式**,**P2P模式**.           

#### 2.1 接入网      

**接入网**指的是将**端系统**物理连接到其**边缘路由器(edge router)** 的网络.**边缘路由器**是端系统到任何其他远程端系统的路径上的第一台路由器.     

##### 家庭接入    

宽带住宅接入有两种最流行的类型：**数字用户线(Digital Subscriber Line,DSL)** 和**电缆(cable Internet access)**.现在基本上是**光纤到户(Fiber To The Home,FTTH)**.           

**DSL**   

每个用户的DSL调制解调器使用现有的电话线与位于电话公司的本地中心局(CO)中的数字用户线接入复用器(DSLAM)交换数据.     

家庭的DSL调制解调器得到数字数据后将其转换为高频谱,通过电话线传输给本地中心局,之后通过模数转换与互联网通信.     

电话线同时承载了数据和传统电话信号,以不同频率编码：
- 高速下行信道,位于50kHz~1MHz频段
- 中速上行信道,位于4kHz~50kHz频段
- 普通双向电话信道,位于0~4kHz频段

这些频段在**用户侧**用**无源的分频器**相隔,将电话信号发送给电话,数据信号发送个DSL调制解调器.而在**电话公司**一侧,数字用户线路接入复用器,把数据和电话信号分开.     

DSL标准定义了多个传输速率,包括24Mbps和52Mbps的**下行传输速率**,以及3.Mbps和16Mbps的**上行传输速率**.因为上行传输速率与下行传输速率并不相等,所以这种接入被称为不对称的.     

**电缆因特网接入**    

**电缆接入**利用了**有线电视基础设施**,通过光缆将电缆头端连接到地区枢纽,从这里通过传统的同轴电缆到达各个家庭和各个公寓.因为既用到了光纤也用了同轴电缆,所以也被称为**混合光纤同轴(Hybrid Fiber Coax,HFC)系统**.    

电缆因特网介入需要**电缆调制解调器(cable modem)**,其是一个外部设备,通过一个网口连接到家庭PC,在电缆头端有**电缆调制解调器端接系统(Cable Modem Termination System,CMTS)**.也是一个不对称的接入.    

一个重要的特性是**共享广播媒体**,头端发送的每个分组下行经每段链路到达每个家庭,每个家庭发送的每个分组经上行信道传输到头端.      

**光纤到户**    

即提供一条从本地中心局直接到家庭的光纤路径,考虑到成本,更多的是FTTZ,FTTC,FTTB等.      

有两种光纤分布体系结构：**有源光纤网络(Active Optical Network,AON)** 和**无源光纤网络(Passive Optical Network,PON)**.     

**PON**    

用于Verizon的FiOS服务中,每个家庭配有一个**光纤网络端接器(Optical Network Terminator,ONT)**,它由专门的光纤连接到邻近的**分配器(splitter)**,该分配器把 一些家庭连接到一根共享的光纤上,然后该光纤连接到本地电话和公司的中心局中的**光纤线路端接器(Optical Line Terminator,OLT)**.        

在PON体系结构中,从OLT发送到分配器的分组在分配器处复制.     

##### 企业(和家庭)接入：以太网和WiFi    

在众多局域网技术中,**以太网**是目前公司,大学,家庭网络最流行的接入技术.    

以太网用户使用双绞铜线与一台以太网交换机相连,交换机在连接其他交换机网络或更大的因特网.    

#### 2.2 物理媒介   

物理媒介分成两种类型：**导引型媒介(guided media)** 和**非导引型媒介（unguided media)**.    

**导引型媒介**   

电波沿着固体媒介前行,如**光缆**,**双绞线**,**同轴电缆**.  

**双绞线**    

最便宜并且最常用的导引型媒体.      

以规则的螺旋状排列着,这两根线被绞合起来,以减少邻近的双绞线的电气干扰.通常许多双绞线被捆扎在一起形成一根电缆,并在这些双绞线外面覆盖上保护性防护层.**一对电线构成一条通信链路**.    

**无屏蔽双绞线(Unshielded Twisted Pair,UTP)**,常用在局域网中.    

目前局域网中的双绞线的数据速率为10Mbps~10Gbps.所能达到的数据传输速率取决于导线线径以及传输方和接收方之间的距离.      

**同轴电缆**    

由**两根铜导体组成**,这两根导体是同心的而不是并行的,借助这种结构以及特殊的绝缘体和保护层,能够达到较高的数据传输速率.    

常用于电缆电视系统.      

产生的模拟信号从发送设备传送到一个或多个接受方,同轴电缆能被用作**导引型共享媒介(guided media shared medium)**,特别是,许多端系统能够直接与该电缆相连,每个端系统都能接收由其他端系统发送的内容.    

**光纤**    

一种细而柔软的,能够导引光脉冲的媒介,其中每个脉冲表示一个比特.   

有着不受电磁干扰,信号衰减低,难窃听等优点,使得其成为**长途导引型传输媒介**.     

广泛引用于因特网的主干,高成本的光设备(发射器,接收器,交换机),阻碍了光纤在短途传输中的应用.     
**非导引型媒介**    

电波在空气或外层空间中传播,如**无线局域网**或**数字卫星频道**.      

**陆地无线电信道**     

用电磁频谱承载信号.    

不需要安装物理线路,并具有穿透墙壁,提供与移动用户的连接以及长距离承载信号的能力,因而成为一种有吸引力的媒介.极大地依赖于传播环境和信号传输的距离.     

**卫星无线电信道**   

一颗通信卫星连接地球上的两个或多个微波发射器/接收器,它们被称为地面站.     

常使用两类卫星：**同步卫星(geostationary satellite)** 和**近地轨道卫星(Low-Earth Orbiting satellite)**.   

同步卫星永远停留在地球上方的相同点上,这种静止是通过将卫星置于地球表面上方36000km的轨道上而取得的.    

近地轨道卫星放置得非常靠近地球,绕地球旋转.     

传播时延很大,常用于无法使用DSL或HFC接入的地方.   

### 3. 网络核心  

即由互联因特网端系统的**分组交换机**和**链路**构成的网状网络.    

- 通信网络
	- 分组交换网络
		- 虚电路网络,差不多被淘汰了,在自顶向下的教材中未提及.     
		- 数据报网络
	- 电路交换网络
		- FDM
		- TDM
		- WDM


| 对比方面      | 虚电路                     | 数据报                       |
| --------- | ----------------------- | ------------------------- |
| 思路        | 可靠通信应当由网络来保证            | 可靠通信应当由用户主机来保证            |
| 连接的建立     | 必须有                     | 无                         |
| 终点地址      | 仅在连接建立阶段使用,每个分组使用短的虚电路号 | 每个分组都有终点完整地址,即IP地址        |
| 分组的转发     | 属于同一条虚电路的分组均按同一路由进行转发   | 每个分组独立查找转发表进行转发           |
| 当节点出现故障时  | 所有通过出故障的节点的虚电路均不能工作     | 出故障的节点可能会丢失分组,一些路由可能会发生变化 |
| 分组的顺序     | 总是按发送顺序到达终点             | 到达终点的顺序不一定按发送的顺序          |
| 差错处理和流量控制 | 可以由网络负责,也可以由用户主机负责      | 由用户主机负责                   |

#### 3.1 分组交换

端系统彼此交换**报文(message)**,报文包含设计者需要的任何东西,如数据,控制信息等.把长报文分成小的数据块,称其为**分组(packet)**,每个分组通过通信链路和**分组交换机(packet switch)**,交换机主要有**路由器(router)** 和**链路层交换机(link-layer switch)** 两类.     

多数分组交换机在输入端使用**存储转发传输(store-and-forward transmission)** 机制.即在开始输出分组的第一个比特之前,必须接收到整个分组.      

>注意,发送和接收都是同时进行的,也就是说,如果有n个分组进行发送并且途中经过m个链路,设d=分组长度/传输速率,发送和接收总的时间为(n+m-1)\*d,因为第一分组到达目的地时,花费的时间为m\*d,第二个分组紧随其后,花费了d到达目的地,第三个分组紧随其后,故总的时间为(n-1)\*d,加起来可得(n+m-1)\*d.    

由该机制可得我们在分组交换机需要缓存,即**输出缓存(output buffer,也称输出队列(output queue))**,如果分组要发送的链路正在工作,则放入缓存内,这样就诞生了**排队时延(queuing delay)**,如果很不幸的缓存满了,该分组就会被丢弃,出现**分组丢失(packet loss)**.     

通过**转发表**和**路由表**,就可以让分组知道发往那个链路.       

**路由表(routing table)**：由**路由选择协议(routing protocol)** 得出,决定分组采用的源到目标的路径.    

**转发表(forwarding table)**：由分组交换机得出,将分组从路由器的输入链路转发到输出链路.      

>路由表不等于转发表,路由表主要负责路径的选择和网络拓扑的管理,转发表主要负责指导数据包的转发,通过全局的路由表和局部的转发表配合,让分组可以到达目的地.     


#### 3.2 电路交换

**电路交换(circuit switching)**,在通信期间,预留了端系统间沿路径通信所需要的资源.即创建一个专用的**端到端连接(end-to-end connection)**.      

电路通过**频分复用(Frequency-Division Multiplexing,FDM)** 或**时分复用(Time-Division Multiplexing,TDM)** 实现.   

>还有波分复用,统计时分复用那些.    

**FDM**：在连接期间专设一个频段.    

**TDM**：将时间划分为固定的**帧**,每个帧又被分为固定数量的**时隙**.一条电路的传输速率为帧速率乘一个时隙中的比特数量.        

缺点：在**静默期(silent period)** 内专用电路是空闲的,造成资源的浪费.      

>总的来说,现在的趋势是向分组交换发展.    

#### 3.3 网络的网络

端系统通过一个接入ISP与因特网相连,该接入ISP能够提供有线或无线连接,使用多种接入技术.       

接入ISP不必是电信局或电缆公司,也可是如大学或公司这样的单位.       

网络结构1：用单一的全球传输ISP互联所有接入ISP,是一个由路由器和通信链路构成的网络.    

网络结构2：多个全球传输的ISP同台竞技.     

网络结构3：上面两个的抽象结构是两层的,网络由底层到区域,区域到全球,构成了网络结构3.如同收保护费一般,第一层的ISP收第二层的钱,第二层收第三层的钱...    

网络结构4：由接入ISP,区域ISP,第一层ISP,**PoP**,**多宿**,**对等**,和**IXP**组成.    

网络结构5：在结构4的顶部增加了**内容提供商网络(content provider network)**.    

**PoP(Point of Presence,存在点)**：高层ISP面向客户网络的接入点.    

**多宿(multi-home)**：除第一层ISP以外都可以选择与多个提供商ISP连接.    

**对等(peer)**：位于相同等级结构层次的邻近的一对ISP直接连接,不进行结算.    

**IXP(Internet Exchange Point,因特网交换点)**：多个对等ISP互联互通之处.    

**内容提供商网络(content provider network)**：可以直接与客户连接,也就通过于较低层ISP对等连接.      

### 4. 分组交换网中的时延,丢包和吞吐量

#### 4.1 分组交换网中的时延

##### 处理时延(nodal processing delay)

检查分组首部和决定将该分组导向何处所需要的时间以及检查比特级别的差错所需要的时间.      

高速路由器的处理时延通常是微妙或更低的数量级.    

##### 排队时延(queuing delay)   

在队列中,当分组在链路上等待传输的时间.排队时延取决于先期到达的正在排队等待链路传输的分组数量.        

实际的排队时延可以使毫秒到微秒量级.    

##### 传输时延(transmission delay)   

将所有分组的比特推向链路所需要的时间.即L/R.     

实际的传输时延通常是毫秒到微妙级量级.    

##### 传播时延(propagation delay)   

将一个比特从链路的起点到终点传播所需要的时间.该比特以该链路的传播速率传播,该传播速率取决于该链路的物理媒介,速率范围是2x10<sup>8</sup>~3x10<sup>8</sup>,这等于或略小于光速.    

该时延等于两台路由器之间的距离除以传播速率,在广域网中,传播时延为毫秒量级.      

#### 4.2排队时延和丢包

排队时延很大程度取决于流量到达该队列的速率,链路的传输速率到达流量的性质,即流量是突发性的还是周期性的.     

设a表示分组到达队列的平均速率,每个分组由L个bit组成,R为从队列中推出比特的速率,则称La/R为**流量强度**,当它大于1时,则比特到达队列的平均速率超过从该队列传输出去的速率,那么队列会无限增加,排队时延趋近于无穷,当它小于等于1时,到达的流量性质影响排队时延.    

(I/(1-I))\*(a/R)计算排队时延,I为流量强度.    

>流量工程中的一条金科玉律是：设计系统时流量强度不能大于1.     

当到达的分组遇见一个满的队列时,路由器将丢弃该分组.     

#### 4.3 端到端时延

端到端总时延,假定源主机到目的主机之间有N-1台路由器：    

d<sub>end-end</sub> = N(d<sub>proc</sub> + d<sub>trans</sub> + d<sub>prop</sub> + d<sub>queue</sub>).   

**Tranceroute**    

linux下的追踪路由命令,通过将ICMP报文中的TTL设置为相应的跳数达到追踪效果,总共发送3N次分组.      

**其他时延**    

希望向共享媒介传输分组的端系统可能有意地延迟它的传输,把这作为它与其他端系统共享媒介的协议的一部分.    

媒介分组化时延,出现在IP语言应用中.在VoIP中,发送方在向因特网传递分组之前必须首先用编码的数字化语音填充一个分组,这种填充一个分组的时间称为分组化时延.       

#### 4.4 计算机网络中的吞吐量

- 吞吐量(throughput)：在源端和目标端之间传输的速率
	- 瞬时吞吐量(instantaneous throughput)：在一个时间点的速率
	- 平均吞吐量(average throughput)：在一个长时间内的平均值   

**瓶颈链路(bottleneck link)**    

源端和目的端之间速率最小的那条链路为瓶颈链路.      

吞吐量不仅取决于沿着路径的传输速率,而去取决于干扰流量.     

### 5. 协议层次及其服务模型

#### 5.1 分层的体系结构

利用分层的体系结构,我们可以讨论一个大而复杂的系统中定义良好的特定部分,允许改变服务的实现而不影响该系统其他组件是分层的另一个重要优点.      

**协议分层**   

网络设计者以**分层(layer)** 的方式组织协议并实现这些协议的网络硬件和软件.     

一个协议层能够用软件,硬件或两者的结合来实现,应用层和运输层几乎总是在端系统中用软件实现,物理层和数据链路层通常在于给定链路相关联的网络接口卡,网络层则经常是硬件和软件实现的混合体.    

协议分层具有**概念化**和**结构化**的特点.分层提供了一种结构化方式来讨论系统组件,模块化使更新系统组件更为容易.   

分层的一个潜在缺点是一层可能冗余较低层的功能,如许多协议栈在基于每段链路和基于端到端两种情况下,都提供了差错恢复.第二种潜在的确定是某层的功能可能需要仅在其他某层才出现的信息,违反了层次分离的目标.    

**协议栈(protocol stack)**：各层的所有协议由以下五个部分(OSI是七层)    
- 应用层：是网络应用程序及它们的应用层协议存留的地方,数据单元为**报文(message)**  
- 运输层：在应用程序的端点之间传送应用层报文,有TCP和UDP两类,数据单元为**报文段(segment)**  
- 网络层：负责将数据报的网络层分组从一台主机移动到另一台主机.数据单元为**分组(packet)(无连接的方式称为数据报(datagram))**   
- 链路层：沿着路径将数据报传递给下一个节点,数据单元为**帧(frame)**   
- 物理层：将帧中的一个个比特从一个节点移动到下一个节点.    

#### 5.2 封装

简而言之：上层协议栈的数据单元作为下一层的数据部分加上头部信息封装为一个数据单元.    

### 6. 面对攻击的网络

互联网上恶意的东西可统称为**恶意软件(malware)**,它们一旦感染我们的设备,就能够做各种不正当的事,变为传染他人的**僵尸网络(botnet)** 中的一员,多数恶意软件是**自我复制(self-replicating)**.    

**拒绝服务攻击(Denial-of-Service (DoS) attack)** 大多数属于：
- 弱点攻击
- 带宽洪泛
- 连接洪泛

在带宽洪泛之中,若所有流量都从一个地方发出,第一可能无法产生足够伤害服务器的流量,其次,容易被检测拦截.于是就有了**分布式DoS(Distributed DoS)**.攻击者控制多个源向目标发送流量.   

**嗅探分组**   

在无线接入中,攻击者通过在无线传输分组的附近放置一台被动的接收器,该接收器就能得到传输每个分组的副本,这些副本包含各种敏感信息.这种接受器称为**分组嗅探器(packet sniffer)**.其也可部署在有线环境中,在有限的广播环境下就能嗅探.       

**IP哄骗(IP spoofing)**    

生成具有任意地址,分组内容和目的地址的分组,然后将这个人工制作的分组传输到因特网中.    

解决这个问题,需要采用**端点鉴别**.   


## 应用层  

### 1. 网络应用原理    

研发网络应用程序的核心是写出能够运行在不同的端系统和通过网络彼此通信的程序.     

#### 1.1 网络应用体系结构   

当进行软件编码之前,应当对应用程序有一个宽泛的体系结构计划,应用程序的体系结果明显不同于网络的体系结构.网络体系结构是固定的,并为应用程序提供了特定的服务集合,**应用体系结构(application architecture)** 由应用程序研发者设计,规定了如何在各种端系统上组织该应用程序.     

现代网络应用中所使用的两种主流的体系结构：  
- 客户-服务器体系结构(client-server architecture)
- 对等体系结构  

#### 1.2 进程通信  

进行通信的实际上是**进程(process)** 而不是程序.  

网络应用程序由成对的进程组成,这些进程通过网络相互发送报文,对每对通信进程,我们通常将这两个进程之一标识为**客户(client)**,另一个为**服务器(server)**.    

在一对进程之间的通信会话场景中,发起通信的进程被标识为**客户**,等待联系的进程是**服务器**.   

进程通过一个称为**套接字(socket)**,的软件接口向网络发送报文和从网络接收报文,也称为应用程序之间和网络之间的**应用编程接口(Application Programming Interface,API)**,应用开发者可以控制套接字在应用层端的一切,但对于该套接字的运输层端几乎没有控制权.     

通信还需要知道发送去哪,给谁,因此需要定义两种信息：主机地址和目的主机中指定接受进程的标识符,即**IP地址**和**端口号(port number)**.    

#### 1.3 可供应用层使用的运输服务   

**应用程序服务要求分类**：
- 可靠数据传输(reliable data transfer)：确保由应用程序的一端发送的数据正确并完全地交付给该应用程序的另一端
- 吞吐量：能够确保可用吞吐量总是为至少 **r** bps.  
- 定时：能够提供定时保证
- 安全性：能够为应用程序提供一种或多种安全性服务   

#### 1.4 因特网提供的运输服务    

TCP/IP网络为应用程序提供两个运输层协议：UDP和TCP.    

**TCP**   

包括面向连接服务和可靠数据传输服务,还具有拥塞控制机制.       

**UDP**   

不提供不必要服务的轻量级运输协议,仅提供最低限度的服务,无连接,没有拥塞控制.   

>无论是TCP还是UDP,都没有加密机制,因此有了TCP的加强版本,称为**运输层安全(Transport Layer Secunity,TLS)**.    

目前的因特网运输协议并没有提供对吞吐量或定时保证的讨论,尽管现在能够提供满意的服务,但并不保证.    

#### 1.5 应用层协议   

**应用层协议(application-layer protocol)** 定义了运行在不同系统上的应用程序如何相互传递报文,特别是,应用层协议定义了以下内容：
- 交换的报文类型
- 各种报文类型的语法
- 字段的语义
- 确定一个进程何时以及如何发送报文,对报文进行响应的规则

>应用层协议只是网络应用的一部分    

### 2. Web和HTTP    

#### 2.1 HTTP概述

Web的应用层协议是**超文本传输协议(HyperText Transfer Protocol,HTTP)**,由两个程序实现：一个客户程序和一个服务器程序.      

**Web页面(Web page,也叫文档)**,是由**对象(object)** 组成的,多数Web页面含有一个HTML基本文件以及几个引用对象.HTML基本文件通过对象的URL引用页面中的其他对象.    

>URL,统一资源定位符,一般格式为   
>`协议://主机名:端口/路径` ,端口也可以放在最后   

**Web浏览器(Web browser)**,实现了HTTP的客户端.    

**Web服务器(Web server)**,实现了HTTP的服务器端,用于存储Web对象,流行的Web服务器有Apache和Microsoft Internet Information server.    

HTTP定义了Web客户向Web服务器请求Web页面的方式,以及服务器向客户端传送Web页面的方式.当点击一个超链接时,客户端向服务器发送一个请求报文,服务器发出响应报文.   

HTTP使用TCP作为它的支撑运输协议,HTTP是一个**无状态协议(stateless protocol)**,不保存客户的任何信息.    

#### 2.2 非持续连接和持续连接

**非持续连接(non-persistent connection)**   

对每个请求/响应对是经一个单独的TCP连接发送.    

总的响应时间为两个**RTT(Round-Trip Time,往返时间)** 加上服务器传输HTML文件的时间.    

**缺点**：
1. 必须为每一个请求的对象建立和维护一个全新的连接,每个连接在客户和服务器中都要分配TCP的缓冲区和保持TCP变量,给服务器带来严重负担
2. 每个对象经受两倍RTT的交付时延  

**持续连接(persistent connection)**   

在采用**HTTP 1.1**持续连接的情况下,服务器在发送相应后保持该TCP打开,在相同客户端和服务器之间的后续请求和响应报文通过相同的连接进行传送.   

有流水方式的和非流水方式的,前者遇到一个引用对象就立即产生一个请求,后者只能在收到前一个响应后才能发出新的请求.    

#### 2.3 HTTP 报文格式   

**请求报文**   

格式：
```
方法 URL 版本 crlf //请求行(request line)
首部字段名 值 crlf //首部行(header line)
...
首部字段名 值 crlf
crlf //空行
entity body //实体体
```

请求报文的第一行叫做请求行,其后继行叫做首部行.   

请求行：    
- 方法字段：可以取几种不同的值
	- GET：请求对象
	- POST：提交表单
	- HEAD：收到报文响应,但是并不返回请求对象
	- PUT：允许用户上传对象到指定的Web服务器指定的路径
	- DELETE：允许用户或者应用程序删除Web服务器上的对象
- URL字段：带有请求对象的标识
- 版本字段：HTTP的版本


实体体：使用POST提交表单时包含用户在表单字段中输入的值.    

>用表单生成的请求报文不是必须使用POST方法,使用GET,在URL中包括输入的数据,如www.somesite.com/animalsearch?monkey&bananas.   

>早期的报文都是用ASCII文本书写,便于阅读调试   

**响应报文**   

格式：
```
版本 状态码 短语 crlf //状态行
首部字段名 值 crlf
...
首部字段名 值 crlf
crlf
实体体
```

**状态行(status line)**：   
- 协议版本
- 状态码
- 相应状态信息

实体体：报文的主要部分,包含了所请求对象的本身.   

>状态码都是三位数字的分为5大类：
>1xx 表示通知信息
>2xx 表示成功,如200 OK 请求成功
>3xx 表示重定向,如301 Moved Permanently 请求对象已经永久转移了,新的URL定义在Location：首部行中
>4xx 表示客户的差错,如400 Bad Request 一个通用差错代码,指示该请求不能被服务器理解
>5xx 表示服务器的差错,如505 HTTP Version Not Supported 服务器不支持请求报文使用的HTTP版本   

#### 2.4 用户与服务器的交互：cookie

当一个Web站点希望识别用户,就用到了cookie技术.    

cookie技术有4个组件：
1. 在HTTP响应报文中的一个cookie首部行
2. 在HTTP请求报文中的一个cookie首部行
3. 在用户端系统中保留的一个cookie文件,并由用户的浏览器进行管理
4. 位于Web站点的一个后端数据库

#### 2.5 Web 缓存   

**Web缓存器(Web cache)** 也叫**代理服务器(proxy server)**,能够代表初始的Web服务器来满足HTTP请求的网络实体,有自己的磁盘存储空间,并在存储空间中保存最近请求过的对象的副本.    

通过配置浏览器将请求都指向代理服务器.    

使用的原因有：
- 可以大大减少对客户请求响应的时间,特别是当客户与初始服务器之间的瓶颈带宽远低于客户与Web缓存器之间的瓶颈带宽时更是如此
- 能够大大减少一个机构的接入链路到因特网的通信量,因此就不必急于增加带宽,降低了费用

**条件GET**   

使用高速缓存能减少用户感受到的响应时间,但存放的内容可能是陈旧的.    

为此使用 `If-modified-since` 首部行,代理会发送请求报文到服务器,仅当修改过才发送对象.没有修改过发过来的报文为304未修改.    

#### 2.6 HTTP/2   

HTTP/2于2015年标准化,HTTP/1.1于1997年标准化.   

主要目标为减少感知时延,手段是**经单一TCP连接使请求与相应多路复用,提供请求优先次序和服务器推,并提供HTTP首部字段的有效压缩**.不改变HTTP方法,状态码,URL或首部字段,而是改变数据格式化方法以及客户和服务器之间的传输方式.     

队首阻塞(Head Of Line blocking,HOF),当传输一个当视频片段和该视频下面许多小对象,使用一条TCP连接,视频片段将花费许多时间来通过,与此同时,许多小对象将被延迟,HTTP/1.1解决问题的方式为打开多个并行的TCP连接,从而让同一个Web页面的多个对象并行地发送给浏览器.TCP拥塞控制针对每条共享同一条瓶颈链路的TCP连接,给出一个平等共享该链路的可用带宽,通过打开多条并行TCP连接来传送一个Web页面,浏览器能够“欺骗”并霸占该链路的大部分带宽,许多HTTP/1.1打开多达6条并行TCP连接并非为了避免HOL阻塞,而是为了更多带宽.    

HTTP/2的基本目标之一是摆脱(或至少减少数量)传送单一Web页面时的并行TCP连接.这不仅减少了服务器需要打开与维护的套接字数量,而且允许TCP拥塞控制像设计的那样运行.   

**HTTP/2成帧**   

用于HOL阻塞的HTTP/2解决方案是将每个报文分成小帧,并且在相同TCP连接上交错发送请求和响应报文.将每个对象的报文分成小帧,交错发送,则小对象的帧可以优先发完.   

将一个HTTP报文分成独立的帧,交错发送它们并在接收端将其装配起来的能力是通过HTTP/2协议的**成帧子层**完成的.除此之外,也会对帧进行二进制编码.    

**响应报文的优先次序和服务器推**   

优先次序允许研发者根据用户要求安排请求的相对优先权,从而更好地优化应用性能.   

服务器推为对用户的请求提前将需求的对象推送过去,而不是等待请求后推送.   

**HTTP/3**   

QUIC是一种新型的运输协议,它在应用层中最基本的UDP之上实现.许多HTTP/2特征已被收入到其中,使得对HTTP/3的设计更为简单合理.   

### 3. FTP

文件传输协议,向远程主机上传输文件或从远程主机接受文件.采用CS模式,标准为RFC959.熟知端口为21.    

在一台典型的FTP会话中,用户坐在一台主机(本地主机)前面,向一台远程主机传输(或接收来自远程主机的)文件.    

为使用户能访问它的远程账户,用户必须提供一个用户标识和口令.在提供了这种授权信息后,用户就能从本地文件系统向远程主机文件系统传送文件,反之亦然.       

使用TCP传输协议,客户端通过控制连接获得身份确认,发送命令浏览远程目录.      

FTP使用了两个并行的TCP连接来传输文件,一个是**控制连接(control connection)**,一个是**数据连接(data connection)**.    

控制连接用于在两台主机之间传输控制信息,如用户标识,口令,改变远程目录的命令以及存放(put)和获取(get)文件的命令.    

数据连接用于实际发送一个文件.       

因为FTP使用一个独立的控制连接,所以也称FTP的控制信息是**带外(out-of-band)** 传送的.而HTTP也可以说是**带内(in-band)** 发送控制信息的,它数据与控制信息都在一个连接上发送.      

工作流程：
- 客户端首先在服务器21号端口与服务器发起一个**控制连接**,发送用户标识和口令
- FTP的服务器如果收到一个文件传输的命令后,就建立一个**数据连接**,传送完毕后,**关闭**
- 同一个会话期间,如果还要传输数据,则打开另一个数据连接

FTP服务器必须在整个会话期间保留用户状态.如当前目录路径等,对每个用户进行追踪,大大限制了FTP同时维护的会话总数.   

FTP命令：从客户到服务器的命令和从服务器到客户的回答,都是以7比特ASCII格式在控制连接上传送的,因此是人可读的.为了区分连续的命令,每个命令后跟回车换行.每个命令由4个大写字母ASCII字符组成,有些还有可选参数.常见命令：
- USER username：用于向服务器传送用户标识
- PASS password：用于向服务器发送用户口令
- LIST：用于请求服务器回送当前远程目录中的所有文件列表,该文件列表是经一个(新建且非持续连接)数据连接传送的,而不是在控制TCP连接上传送的
- RETR filename：用于从远程主机当前目录检索文件,该命令引起远程主机发起一个数据连接,并经该数据连接发送所请求的文件
- STOP filename：用于在远程主机的当前目录下存放文件

贯穿控制连接,在用户发出的命令和FTP发送的命令之间通常有一一对应关系,每个命令都对应着一个从服务器发向客户的回答,回答是一个3位的数字,后跟一个可选信息,这与HTTP响应报文状态行的状态码和状态信息的结构相同,一些典型的报文：
- 331 Username OK,Password required
- 125 Data connection already;transfer starting 
- 425 Can't open data connection
- 452 Error writing file

更多看RFC 959

### 4. 因特网中的电子邮件   

因特网的组成部分：
- 用户代理
- 邮件服务器
- 简单邮件传输协议

用户代理允许用户阅读,回复,转发,保存和撰写报文.   

邮件服务器形成了电子邮件体系结构的核心.发送方的邮件首先传输到发送方的邮件服务器,再传输到接收方的邮件服务器,接收方的代理再从其服务器中读取.如果不能交付到其服务器,发送方的邮件服务器在一个**报文队列(message queue)** 中保持该报文并在以后尝试发送.   

#### 4.1 SMTP

SMTP是因特网电子邮件中主要的应用层协议,使用TCP可靠数据传输服务.    

原始的SMTP限制了所有报文的体部分(不只是其首部)只能采用简单的7比特ASCII表示,因此要传送图像那些需要对其进行编码与解码,如bash64,quoted-printable等,传输多媒体使用了**MIME(多媒体邮件拓展,multimedia mail extension)** 协议,其在报文首部用额外的行申明了MIME内容类型.     

SMTP一般不使用中间邮件服务器发送邮件,即使这两个服务器位于地球的两端.    

#### 4.2 邮件报文格式

SMTP使用CRLF.CRLF决定报文的尾部.使用的持续连接.   

**邮件报文格式**：   有首部和报文体,每个首部必须含有一个From:和一个To:,也许包含一个Subject:.首部之后,紧接着一个空白行,然后是以ASCII格式表示的报文体.     

>书上的2.3.1和2.3.2,前者用telnet写邮件,后者为发送报文的格式.   

#### 4.3 邮件访问协议   

不能用SMTP得到报文,因为SMTP是一个推协议,取回邮件一般使用HTTP,POP3(邮局协议版本3),IMAP(因特网邮件访问协议)协议等.    

一般不在本地PC布置邮件服务器,因为邮件服务器要长期开机,不然不能及时接收邮件.   

一般是先发送到邮件服务器,在由服务器对邮件进行发送,因为通过服务器可以不断地尝试发送,直到成功,出问题也可以甩锅,有的邮件代理支持邮寄特快,直接发送至对方邮件服务器中.    

### 5. DNS：因特网的目录服务   

因特网上的主机可以使用多种方式进行标识：   
- 主机名(host name)：www.facebook.com   
- IP地址(IP address)：127.0.0.1 

#### 5.1 DNS提供的服务  

主要任务：将主机名到IP地址转换的目录服务.   

DNS是：
- 一个由分层的DNS服务器实现的分布式数据库
- 一个使得主机能够查询分布式数据库的应用层协议

DNS服务器通常是运行BIND(Berkeley Internet Name Domain)软件的UNIX机器,运行在DNS之上.    

DNS还提供一些重要的服务：
- 主机别名：有着复杂主机名的主机能拥有一个或者多个别名,复杂的名称称为**规范主机名(canonical hostname)**
- 邮件服务器别名(mail aliasing)：允许邮件服务器与Web服务器使用相同的别名
- 负载分配(load distrubution)：在冗余的服务器之间进行负载分配,使用轮询等技术,将请求分配到各个主机

#### 5.2 DNS工作机理概述   

DNS若采用集中式设计会产生以下问题：
- 单点故障(single point of failure),若DNS服务器崩溃,整个因特网随之瘫痪
- 通信容量(traffic volume),单个DNS服务器不得不处理所有的DNS查询
- 远距离的集中数据库(distant centralized database),不可能每个用户都很近
- 维护(maintenance),不得不为所有因特网主机保留记录,使得数据库无比庞大,以及频繁的更新

**分布式,层次数据库**  

基本分为3中类型：
- 根DNS服务器
- 顶级域(Top-Level Domain,TLD)DNS服务器
- 权威DNS服务器

**根DNS服务器**  

有超过1000台根DNS服务器实体遍及全世界,都为13个不同根服务器的副本,有12个不同组织管理,并通过因特网号码分配机构来协调.  

根服务器提供TLD服务器的IP地址.    

**顶级域(TLD)DNS服务器**   

对于每个顶级域和所有国家的顶级域,都有TLD服务器(或服务器集群).    

TLD服务器提供了权威DNS服务器的IP地址.   

**权威DNS服务器**   

在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的DNS记录,这些记录将主机的名字映射为IP地址.   

一个组织机构的权威DNS服务器收藏了这些DNS记录.一种方法是,自己实现自己的权威DNS服务器以保存这些记录,另一种方法为,支付费用,让这些记录存储在某个服务提供商的一个权威DNS服务器中.    

还有另一类重要的DNS服务器,为**本地DNS服务器(local DNS server)**,严格来说,本地DNS服务器并不属于DNS的层次结构,当对其是至关重要的.   

**递归查询(recursive query)**：客户端向DNS服务器请求解析域名时,服务器需完成整个查询过程,最终返回确切的IP地址或错误信息.     

**迭代查询(Iterative query)**：每次查询时,被请求的服务器仅返回已知的最佳结果,由请求方继续查询.  

一般都采用,主机向本地DNS递归查询,本地DNS向根服务器,TLD服务器,权威服务器迭代查询.     

**DNS缓存**   

本地DNS在收到查询结果后,会进行保存,一般保存两天,供后来者使用.   

#### 5.3 DNS记录和报文   

所有DNS服务器存储了**资源记录(Resource Record,RR)**.    

RR格式为：
- Domain_name 域名
- Ttl time to live 生存时间
- Class 类别 对于Internet 值为IN
- Value 值 可以是数字,域名或ASCII串
- Type 类别  

RR：(name,value,type,ttl)     

Name和Value的意义取决于Type：  
- Type=A,Name为主机名,Value为IP地址
- Type=NS,Name为域名,Value为该域名的权威服务器的主机名
- Type=CNAME,Name为规范名字的别名,Value为规范主机名
- Type=MX,Name为邮件服务器的别名,Value为邮件服务器的规范主机名

TTL：生存时间,决定了资源记录应当从缓存中删除的时间.缓存记录TTL短,权威记录TTL很长.     

**DNS报文**   

查询和回答报文的格式相同：

<table>
<tr><td align=center>标志符identification</td><td align=center>标志fiags</td><td align=center rowspan=3>12字节</td></tr>
<tr><td align=center>问题数questions</td><td align=center>回答RR数answer RRs</td></tr>
<tr><td align=center>权威RR数authority RRs</td><td align=center>附加RR数additional RRs</td></tr>
<tr><td align=center colspan=2>问题questions(问题的变量数variable # of questions)</td><td align=center>查询的名字和类型字段</td></tr>
<tr><td align=center colspan=2>回答answers(资源记录的变量数variable # of RRs)</td><td align=center>对查询的响应中的RR</td></tr>
<tr><td align=center colspan=2>权威authority(资源记录的变量数variable # of RRs)</td><td align=center>权威服务器中的记录</td></tr>
<tr><td align=center colspan=2>附加信息additional info(资源记录的变量数variable # of RRs)</td><td align=center>可被使用的附加"有帮助的"信息</td></tr>
</table>

前12字节是首部区域,第一字段是一个16比特的数,用于标志该查询,以便匹配请求与接受的回答.标志字段含有若干标志,1比特的**查询/回答**指出是查询报文(0)还是回答报文(1),当请求权威DNS服务器时,1比特的**权威的**标志位被置1,希望递归查询,将设置1比特的**希望递归**标志位.若服务器支持,则回答报文中的1比特**递归可用**标志位置位.**数量的字段指出在首部后4类数据区域出现的数量**.    

问题区域包含了正在进行的查询信息,包括**名字字段**,正在被查询的主机名,**类型字段**,指出有关该名字的正被询问的问题类型.   

回答区域包含了对最初请求的名字的资源记录,可以包含多条RR.   

权威区域包含了其他权威服务器的记录.  

附加信息区域包含了其他有帮助的记录.    

**在DNS数据库中插入记录**   

首先,注册域名,向注册登记机构提供基本的,辅助权威DNS服务器的名字和IP地址.    

确保Web服务器的类型A资源记录和用于邮件服务器的类型MX资源记录被输入到你的权威DNS服务器中.(可以静态的配置,也可动态的配置的服务器).     

### 6. P2P文件分发 

P2P应用分为结构化P2P,如DHT,和非结构化的P2P.   

P2P相比与CS模式有着很好的扩展性.   

>书上有具体的分析.    

非结构化P2P分为：
- 集中化目录
- 完全分布式
- 混合体

集中化目录,通过连接时向一个服务器报告状态,然后去连接P2P网络.   

完全分布式,通过初始的配置文件,建立连接后使用**泛洪**的方式组建网络与获取信息.   

混合体则是建立起一个个小组,由组长进行通信,里面的每一个文件都有一个散列标识码和一个描述符.   

**BitTorrent**   

在BitTorrent中,对一个特定文件的所有对等方的集合称为一个**洪流(torrent)**,在一个洪流中的对等方彼此下载长度相同的文件块,典型的长度为256KB.   

Peer一开始加入时,没有块,随着时间积累块.下载块的同时也为其他对等方上载了多个块.    

每个洪流具有一个基础设施节点,称为**追踪器(tracker)**,当一个对等方加入时,它向追踪器注册自己,并周期性地通知追踪器它仍在该洪流中.追踪器会随机为它分配一个参与对等方的子集让它可以与其建立邻近对等方.    

**请求块**  

在任何给定时间,不同peer节点拥有一个文件块的子集.   

周期性向每个邻近对等方询问它们拥有那些块的信息.   

优先选择在它没有的块里在邻居中最稀缺的块.   

>新加入的话没有的选择    

**发送块**   

采用一报还一报的机制.   

对能够以最高速率向它提供数据的邻居优先上载,每10秒测量接收到流量,向前4名发送.这4个对等方称为**疏通(unchoked)**.  

每隔30秒,随机选择另外一个邻居并向其发送块,不然会形成小团体,传输就会死掉.   

此外,还有片(小块),流水线,随机优先选择,残局模型和反怠慢等机制.    

**结构化P2P：DHT分布式散列表**   

Hash表   

DHT方案   

环形DHT以及覆盖网络   

Peer波动   

### 7. 视频流和内容分发网   

**视频流**   

视频是一系列的图像,通常以一种恒定的速率来展现.今天现成的压缩算法能够将一个视频压缩成所希望的任何比特率.   

到目前为止,对于六十视频最为重要的性能为平均端到端吞吐量.    

在HTTP流中,视频只是存储在HTTP服务器中作为一个普通文件,每个文件有一个特定的URL.当要观看时,客户与服务器创建一个TCP连接并发送对该URL的HTTP GET请求.服务器以底层网络协议和流量条件允许的尽可能快的速率发送文件,客户收集字节在客户应用缓存中,一旦字节数量达到预先设定的门槛就开始播放,并周期性地从客户应用缓存中抓取帧.   

在HTTP流中有个严重缺陷,即所有客户接受到相同的编码视频.因此有了**经HTTP的动态适应性流(Dynamic Adaptive Streaming over HTTP,DASH)**.  

在DASH中,视频编码被分为几个不同的版本,每个版本有不同的比特率,客户动态请求来自不同版本且长度为几秒的视频段数据块.  

使用DASH后,每个视频文件存储在HTTP服务器上,HTTP服务器有一个**告示文件(manifest file)**,为每个版本提供了一个URL及其比特率.客户首先请求告示文件并且得知各种各样的版本,然后通过请求报文中对每块指定一个URL和一个字节范围,一次选择一块,在下载的同时,运行一个**速率决定算法**来选择下次请求的块.   

**内容分发网(Content Distribution Network,CDN)**   

简要：即中心服务器的存储副本,客户通过访问这个来加快访问.   

CDN通常采用两种不同的服务器安置原则：  
- **深入**：由Akamai首创,通过遍及全球的接入ISP中部署服务器集群来深入ISP接入网中,在数以千计个位置用着用办法部署,目标为靠近用户,但高度分布式设计,维护和管理成为挑战
- **邀请做客**：由Limelight和许多其他CDN公司采用,通过在少量关键位置建造大集群来邀请到ISP做客,通常将它们的集群放置在IXP,与上者相比,成本低,但对用户有较高时延和较低吞吐量

一旦CDN集群准备就绪,就可以跨越集群复制内容,许多CDN并没有将全部视频推入他们的集群,而是使用一种简单的拉策略：如果客户向一个未储存该视频的集群的请求视频,则该视频从某中心仓库或另一个集群中检索该视频,向客户流式传输视频的同时在本地储存一个副本.    

**CDN操作**   

但用户主机一个浏览器指令检索一个特定的视频,CDN必须截获该请求,以便能够：   
1. 确定此时适合用于该客户的CDN服务器集群
2. 将客户的请求重定向到该集群的某台服务器  

大多数CDN利用DNS来截获和重定向请求.    

**集群选择策略(cluster selection strategy)**     

一种简单的策略是指派客户到**地理上最为邻近(geographically closest)** 的集群.但对于某些用户来说,并不是太好.   

还有对其集群和客户之间的时延和丢包性能执行周期性的**实时测量(real-time measurement)**.但许多的LDNS被配置为不响应这些探测报文.    

## 运输层  

### 1. 概述和运输层服务   

运输层为运行在不同主机上的应用程序之间提供了逻辑通信(logic communication).   

#### 1.1 运输层和网络层的关系   

运输层为运行在不同主机上的进程之间提供了逻辑通信,网络层提供了主机之间的逻辑通信.      

运输层协议能够提供的服务常常受制于底层网络协议的服务模型,如果网络层协议无法为主机之间发送的运输层报文段提供时延或带宽保证的话,运输层协议也就无法为进程之间发送的报文提供时延或带宽保证.     

然而,即使底层网络协议不能在网络层提供相应的服务,运输层协议也能够提供某些服务.例如,提供可靠传输服务,加密服务等.   

#### 1.2 因特网运输层概述   

运输层提供两种截然不同的运输层协议：   
- UDP：为调用它的应用程序提供一种不可靠,无连接的服务  
- TCP：提供一种可靠的,面向连接的服务

为了简化术语,称运输层分组称为**报文段(segment)**,然而,因特网文献(如RFC)也将TCP的运输层分组称为报文段,而将UDP的分组称为**数据报(data gram)**,而这类文档也将网络层分组称为数据报.    

UDP和TCP最基本的责任是,将两个端系统间的IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务.将主机间交付扩展到进程间交付被称为**运输层的多路复用(transport-layer multiplexing)** 与**多路分解(demultiplexing)**.UDP和TCP还可以通过在其报文段首部中包括差错检查字段而提供完整性检查,进程到进程的数据交付和差错检查是两种最低限度的运输层服务,也是UDP所能提供的仅有的两种服务.  

TCP为应用程序提供了几种附加服务,首先,它提供**可靠数据传输(reliable data transfer)**,通过使用**流量控制,序号,确认和定时器**确保正确地,按序地将数据从发送进程交付给接收进程.也提供**拥塞控制**,这是一种提供给整个因特网的服务,一种带来通用好处的服务.   

### 2. 多路复用与多路分解   

**套接字(socket)**,相当于从网络向进程传递数据和从进程向网络传递数据的门户.每个套接字都有唯一的标识符,格式取决于它是UDP还是TCP套接字.   

将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解(demultiplexing)**.   

在源主机从不同套接字中收集数据块,并为每个数据块封装上首部信息从而生成报文段,然后将报文段传递到网络层,所有这些工作称为**多路复用(multiplexing)**.     

**端口号**是一个16比特的数,大小为0~65535之间,其中0~1023范围的端口号被称为**周知端口号(well-known port number)**,保留给诸如HTTP和FTP之类的周知应用层协议来使用.    

UDPsocket使用一个二元组,本地的IP和端口号.   

TCPsocket使用一个四元组,源IP和端口,目的IP和端口.  

Web服务器在TCP的连接中会首先创建一个**欢迎接口**,之后对每一个连接创建一个具有新连接套接字的新线程.之所以有欢迎套接字,是因为建立连接的需要.    

### 3. 无连接运输：UDP  

许多应用更适合UDP,原因如下：  
- 关于发送什么数据以及何时发送的应用控制更为精细：因为数据传递给UDP就会打包发送,而TCP则有拥塞控制机制
- 无须连接建立：少了一些时延
- 无连接状态：无须像TCP一样在端系统中维护连接状态
- 分组首部开销小：UDP首部仅有8字节,而TCP有20字节

>由于原始UDP没有拥塞,从而可能会挤垮TCP会话.如果每个人都启动高比特率视频而不使用任何拥塞控制的话,就会使路由器中有大量分组溢出,而导致非常少的UDP分组能成功通过源到目的的路径传输.   

UDP的应用是可能实现可靠的数据传输的,这可以应用程序自身中建立可靠性机制来完成.    

#### 3.1 UDP报文段结构  

结构：  
<table>
<tr><td align=center>源端口号</td><td align=center>目的端口号</td></tr>
<tr><td align=center>长度</td><td align=center>检验和</td></tr>
<tr><td align=center colspan=2>应用数据(报文)</td></tr>
</table>

UDP首部只有4个字段,每个字段由两个字节组成.   

通过端口号可以使目的主机将应用数据交付给运行在目的端系统中的相应进程.   

长度字段指示了UDP报文段中的字节数(首部和数据).因为数据字段的长度在一个UDP段中不同于在另一个段中,故需要一个明确的长度.   

接收方使用检验和来检查在该报文段中是否出现差错,计算检验和还需要用到一个IP数据报的伪首部.   

#### 3.2 UDP检验和   

检验和用于确定当UDP报文段从源到目的地移动时,其中的比特是否发生了改变.   

发送方的UDP对报文段中的所有16比特字(这时的检验和置0)的和进行反码运算,求和时遇到的任何溢出都被回卷(即溢出加到最低位).    

得到的结果放在UDP报文段的检验和字段.  

在接收方,全部的4个16比特字(包括检验和),加在一起,如果没有引入差错,则该和为16个1.  

>当然,全1,也可能会有差错,这样的差错称为残存差错.  

为什么UDP提供差错检验：   
- 不能保证源和目的端之间的所有链路都提供差错检验
- 报文段存储在某台路由器的内存中时,也可能引入比特差错

在既无法确保逐链路的可靠性,也无法保证内存中的差错检验,如果端到端数据传输服务要提供差错检验,UDP必须在端到端基础上在运输层提供差错检验,这在系统设计中称为**端到端原则(end-end principle)**：与在较高级别提供这些功能的代价相比,在较低级别上设置的功能可能是冗余的或几乎没有价值的.   

即使UDP提供差错检验,但它对差错恢复无能为力,其的某种实现只是丢弃受损的报文段,其他的实现是将受损的报文段交给应用程序并给出警告.   

### 4. 可靠数据传输原理   

#### 4.1 构造可靠数据传输协议  

**1.经完全可靠信道的可靠数据传输：rdt1.0**  

很可靠.    

**2.经具有比特差错信道的可靠数据传输：rdt2.0**  

使用了**肯定确认(positive acknowledgment)** 与**否定确认(negative acknowledgment)** ,这些控制报文使得接收方可以让发送方知道那些内容被正确接收,哪些内容接收有误并因此需要重复.   

在计算机网络环境中,基于这样的可靠数据传输协议称为**自动重传请求(Automatic Repeat reQuest)协议**.   

重要的是,ARQ协议还需要另外三种协议功能来处理存在比特差错的情况：  
- 差错检测：使用检验和字段
- 接收方反馈：使用肯定确认和否定确认反馈
- 重传：收到有差错的分组时,发送方将重传该分组

为了解决**确认字段**可能损坏的问题,增加一个新字段**序号(sequence number)**,接收方只需要检查序号即可确定收到的分组是否是重传.即**rdt2.1**.   

把NAK取消,而采用接收到**冗余ACK(duplicate ACK)** 也可以知道接收方有没有正确接收到跟在被确认两次的分组后面的分组,即**rdt2.2**.    

两者的差别为,rdt2.2接收方此时必须包括由一个ACK报文所确认的分组序号.发送方此时必须检查接收到的ACK报文中被确认的分组序号.    

**3.经具有比特差错的丢包信道的可靠数据传输：rdt3.0**  

使用了基于时间的重传机制,设定一个**倒计数定时器(countdown timer)**,在一个给定的时间量过期后,可中断发送方,因此,发送方需要做到：
- 每次发送一个分组,便启动一个定时器
- 响应定时器中断
- 终止定时器

rdt3.0有时被称为**比特交替协议(alternating-bit protocol)**.   

有了**检验和,序号,定时器,肯定和否定确认分组**这些技术,每种机制都在协议的运行中起到了必不可少的作用,至此,得到了一个可靠的数据传输协议.    

#### 4.2 流水线可靠数据传输协议   

rdt3.0是一个功能正确的协议,但性能并不行,问题的核心在于它是一个**停等协议(stop-and-wait protocol)**.    

这种特殊的性能问题的一个简单的解决方案是：不以停等方式运行,允许发送方发送多个分组而无须等待确认.    

因为许多从发送方向接收方输出的分组可以被看成是填充到一条流水线中,故这种技术被称为**流水线(pipelining)**,这种技术对可靠数据传输协议可带来以下影响：  
- 必须增加序号范围,因为每个输送中的分组必须有一个唯一的序号,而且也许有多个在输送中的未确认报文
- 协议的发送方和接收方两端也许不得不缓存多个分组,发送方最低限度应当能缓冲那些已发送但没有确认的分组
- 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失,损坏及延时过大的分组,解决流水线的差错恢复有两种基本方法：**回退N步(Go-Back-N,GBN)** 和**选择重传(Selective Repeat,SR)** 

回退N步和选择重传都基于**滑动窗口(slide window)协议**.   

#### 4.3 回退N步   

>GBN也被称为滑动窗口协议,教科书上是这样写的,但视频我理解的是分开的.    

**滑动窗口协议**   

发送缓冲区：  
- 形式：内存中的一个区域,落入缓冲区的分组可以发送
- 功能：用于存放已发送,但是没有得到确认的分组
- 必要性：需要重发时可用

发送缓冲区的大小：一次最多可以发送多少个未经确认的分组   
- 停止等待协议=1
- 流水线协议>1,合理的值,不能很大,链路利用率不能够超100%

发送缓冲区中的分组：
- 未发送的：落入发送缓冲区的分组,可以连续发送出去
- 已经发送出去的,等待对方确认的分组：发送缓冲区的分组只有得到确认才能删除

发送窗口：发送缓冲区内容的一个范围
- 那些已发送但是未经确认分组的序号构成的空间


发送窗口的最大值<=发送缓冲区的大小   

一开始：没有发送任何一个分组  
- 后沿=前沿
- 之间为发送窗口的尺寸=0

每发送一个分组,前沿前移一个单位.   

发送窗口前沿移动的极限：不能够超过发送缓冲区   

发送窗口的后延移动：  
- 条件：收到老分组(后延)的确认
- 结果：发送缓冲区罩住新的分组,来了分组可以发送
- 移动的极限：不能够超过前沿

接收窗口  

接收窗口的滑动和发送确认：
- 滑动：
	- 低序号的分组到来,接收窗口移动
	- 高序号分组乱序到,缓存但不交付(因为要实现rdt,不允许失序),不滑动
- 发送确认：
	- 接收窗口尺寸=1：发送连续收到的最大的分组确认(累计确认)
	- 接收窗口尺寸>1：收到分组,发送那个分组的确认(非累计确认)


在实践中,一个分组的序号承载在分组首部的一个固定长度字段中,如果分组序号字段的比特数是k,则该序号范围是\[0,2<sup>k</sup>-1\],在一个有限的序号范围内,所有涉及序号的运算必须使用模2<sup>k</sup>运算.   

GBN**发送方**必须响应三种类型的事件：
- 上层的调用：上层调用rdt_send()时,发送方首先检查发送窗口是否已满,如果未满,则产生一个分组并将其发送,并相应地更新变量,如果已满,将数据返回上层,然后上层可能过会再试.实际实现中,更可能缓存这些数据,或者使用同步机制允许上层在仅当窗口不满时才调用rdt_send()
- 收到一个ACK：在GBN中,使用**累计确认(cumulative acknowledgment)** 的方式
- 超时事件：重传所有已发送但还未确认过的分组,如果收到一个ACK,但仍有已发送但未确认的分组,则定时器被重新启动.如果没有已发送但未确认的分组,停止该定时器

**接收方**：  
如果一个序号为n的分组被正确接收到,并且按序,则发送一个ACK,并将该分组的数据部分交付给上层.   
在所有其他情况下,接收方丢弃该分组,并为最近按序接收的分组重新发送ACK.   

#### 4.4 选择重传

选择重传协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免不必要的重传.   

SR接收方将确认一个正确接受的分组而不管其是否按序,失序的分组将被缓存直到所有丢失分组皆被受到为止,这时才可以将一批分组按序交付给上层.    

SR发送方的事件与操作：
1. 从上层收到数据,当从上层接收到数据后,SR发送方检查下一个可用于该分组的序号,如果序号位于发送方的窗口内,则将数据打包并发送,否则就像在GBN中的一样,要么将数据缓存,要么将其返回给上层以便以后传输
2. 超时,定时器再次被用来防止丢失分组,然而现在每个分组都有其自己的逻辑定时器,因为超时后只能发送一个分组,可以使用单个的硬件定时器模拟多个逻辑定时器的功能
3. 收到ACK,如果收到ACK,该分组序号在窗口内,则SR发送方将那个被确认的分组标记为以接收,如果该分组序号等于send_base,则窗口基序号向前移动到具有最小序号的未确认分组处,如果窗口移动了并且有序号落在窗口内的未发送分组,则发送这些分组

SR接收方的事件与操作：  
1. 序号在\[rev_base,rev_base+N-1\]内的分组被正确接收,在此情况下,收到的分组落在接收方的窗口内,一个选择ACK被回送给发送方,如果该分组以前没有收到过,则缓存该分组,如果该分组等于接收窗口基序号,则该分组以及以前缓存的序号连续的分组交付给上层,然后,接收窗口按向前移动分组的编号向上交付这些分组.
2. 序号在\[rev_base-N,rev_base-1\]内的分组被正确收到,在此情况下,必须产生一个ACK,即使该分组是接收方以前确认过的分组
3. 其他情况,忽略该分组

对SR协议而言,窗口长度必须小于或等于序号空间大小的一半.   

对比GBN和SR   
<table>
<tr><td align=center></td><td align=center>GBN</td><td align=center>SR</td></tr>
<tr><td align=center>优点</td><td align=center>简单,所需资源少</td><td align=center>出错时,重传一个代价小</td></tr>
<tr><td align=center>缺点</td><td align=center>一旦出错,回退N步代价大</td><td align=center>复杂,所需资源多</td></tr>
<tr><td align=center>适用范围</td><td align=center>出错率低</td><td align=center>链路容量大,延迟大,带宽大</td></tr>
<tr><td align=center>窗口的最大尺寸</td><td align=center>2<sup>n</sup>-1</td><td align=center>2<sup>n-1</sup></td></tr>
</table>

> [!question] 序号大小与窗口大小之间的关系
> 假设序号为0,1,2,3,n=2,首先是GBN,如果发送窗口大小为2<sup>n</sup>即0,1,2,3.接收方的接收窗口为1,如果发送方发送完了报文,接收方也顺利的接收了报文,但返回的ACK报文却全部丢失了,而接收方的窗口会期待下一个周期的0号报文,但发送方却会发送本周期的0号报文,于是发生了错误.  
> 然后是SR,如果发送窗口大小为2<sup>n-1</sup>+1,即0,1,2.接收方窗口等同,那么,假设发送方发送了完了报文,接收方也顺利收到了,那么接收方目前的接收窗口序列为3,0,1.如果这时一不小心,ACK又全部丢失了,那么重发时,接收方就会把老的0,1号报文当新的,于是发生了错误.  

### 5. 面向数据的运输：TCP   

#### 5.1 TCP连接  

TCP被称为是**面向连接的(connection-oriented)**,这是因为在一个应用程序可以开始向另一个应用程序发送数据之前,这两个进程必须互相"握手",即它们必须相互发送某些预备报文段,以建立确保数据传输的参数.连接双方都将初始化与TCP连接相关的许多TCP状态变量.   

TCP的连接是一条**逻辑**连接,其共同状态仅保留在两个通信系统的TCP程序中.   

TCP协议只在端系统中运行,所以中间的网络元素不会维持TCP连接状态.    

TCP连接提供**全双工服务(full-duplex service)**.   

TCP连接也总是**点对点(point-to-point)** 的.即在单个发送方与单个接收方之间的连接.  

一旦建立起一条TCP连接,两个应用进程就可以相互发送数据了.TCP将数据引导到该连接的**发送缓存(send buffer)**.TCP从缓存中取出并放入报文段中的数据数量受限于**最大报文段长度(Maximum Segment Size,MSS)**.TCP规范里没有规定TCP应该何时发送数据,只是描述为"TCP在它方便的时候以报文段的形式发送数据".   

MSS是指报文段里应用层数据的最大长度,而不是指包括首部的TCP报文段的最大长度.   

TCP连接的组成包括：  
- 一台主机上的缓存
- 变量
- 与进程连接的套接字
- 另一台主机上的另一组缓存,变量和套接字

#### 5.2 TCP报文段结构  

TCP报文段结构：
<table width=1000>
<tr><td align=center width=50%>源端口号</td><td align=center  width=50%>目的端口号</td></tr>
<tr><td align=center colspan=2>序号</td></tr>
<tr><td align=center colspan=2>确认号</td></tr>
<tr><td align=center ><table><tr><td align=center width=25%>首部长度</td> <td align=center width=25%>保留未用</td><td align=center>CWR</td><td align=center >ECE</td><td align=center >URG</td><td align=center >ACK</td><td align=center >PSH</td><td align=center >RST</td><td align=center >SYN</td><td align=center >FIN</td></tr></table></td><td align=center width=50%>接收窗口</td></tr>
<tr><td align=center width=50%>因特网检验和</td><td align=center width=50%>紧急数据指针</td></tr>
<tr><td align=center colspan=2 rowspan=2>选项</td></tr>
<tr>
<tr><td align=center colspan=2 rowspan=2>数据</td></tr>
</table>

与UDP不同的字段有：  
- 32比特的**序号字段(sequence number field)** 和32比特的**确认号字段(acknowledgement number field)**.这些字段被TCP发送方和接收方用来实现可靠数据传输服务
- 16比特的**接收窗口字段(receive window field)** ,用于流量控制
- 4比特的**首部长度字段(header length field)**,指示了以32比特的字为单位的TCP首部长度
- 可选与变长的**选项字段(options field)**,用于发送方与接收方协商最大报文段长度(MSS)时,或在高速网络环境下用作窗口调节因子时使用,首部字段还定义了一个时间戳选项
- 6比特的**标志字段(flag field)**,**ACK**比特用于指示确认字段中的值是有效的,即该报文段包括一个对已被成功接收报文段的确认,**RST,SYN,FIN**比特用于连接的建立和拆除,在明确拥塞通告中使用了CWR和EXE比特,当**PSH**比特被置位时,指示接收方应立即将数据交给上层,**URG**比特用于表示报文段存在着被发送端的上层实体置为"紧急"的数据,紧急数据的最后一个字节由16比特的**紧急数据指针**字段指出.当紧急数据存在并给出指向紧急数据尾指针的时候,TCP必须通知接收段的上层实体(实践中,PSH,URG和紧急数据指针并没有使用)   

**序号和确认号**  

TCP把数据看成一个无结构的,有序的字节流.   

一个报文的**序号**因此是该报文段首字节的字节流编号.   

**确认号**是发送方期望接收方发出报文的下一字节的序号.   

TCP只确认该流中至第一个丢失字节为止的字节,所以TCP被称为提供**累计确认(cumulative acknowledgement)**.  

当收到失序报文时,TCP并没有规定这样行为,根据具体的实现而不同：  
- 立即丢弃
- 保留,并等待缺少的字节以填补该间隔

#### 5.3 往返时间的估计与超时  

**1. 估计往返时间**  

大多数TCP的实现仅在某个时刻做一次SampleRTT的测量,而不是为每一个发送的报文段测量一个SampleRTT,另外,TCP绝不为已被重传的报文段计算SampleRTT,因为可能导致错误的结果,比如重传报文的确认报文来晚一步导致重传,会导致认为这个确认报文是刚才发出那个,让原本可能是300ms的RTT,变为30ms.   

为了估计一个典型的RTT,自然要采取某种对SampleRTT取平均值的办法,TCP维持一个SampleRTT均值称为EstimateRTT.一旦获得一个新的SampleRTT,TCP就会根据下列公式来更新EstimateRTT：  
`EstimateRTT=(1-a)*EstimatedRTT + a*SampleRTT`  

在\[RFC 6298\]中给出的a推荐值是0.125.   

从统计学观点讲,这种平均被称为**指数加权移动平均(Exponential Weighted Moving Average,EWMA)**.在EWMA中的"指数"一词看起来是指一个给定的SampleRTT的权值在更新的过程中呈现指数型快速衰减,比如,一开始为SampleRTT1,第二周期为(1-a)\*SampleRTT1,第三个周期为(1-a)<sup>2</sup>\*SampleRTT1,以此类推.   

除了估算RTT外,测量RTT的变化也是有价值的,RTT偏差DevRTT：  
`DevRTT=(1-beta)*DevRTT + beta*|SampleRTT-EstimateRTT|`  

注意到DevRTT是一个SampleRTT与EstimatedRTT之间差值的EWMA,如果SampleRTT波动小,那么DevRTT就小,反之越大.beta推荐0.25.   

**2. 设置和管理重传超时间隔**  

超时间隔应该大于等于EstimatedRTT,否则,将造成不必要的重传,但是也不应该比EstimatedRTT大太多,否则当报文段丢失时,TCP不能很快地重传,导致时延大,因此要求将超时间隔设为EstimatedRTT加上一定余量：  
`TimeoutInterval=EstimatedRTT+4*DevRTT`  

推荐的初始TimeoutInterval值为一秒,出现超时后,TimeoutInterval加倍,以免即将被确认的后继报文段过早超时导致重传,进而加剧网络的堵塞.获取到新的报文段并更新EstimatedRTT就会重新计算TimeoutInterval.    

#### 5.4 可靠数据传输   

推荐的定时器管理过程仅使用单一的重传定时器.   

**超时间隔加倍**  

TCP重传具有最小序号的还未被确认的报文段,只是每次重传都会将下一次的超时间隔设为先前值的两倍,而不是用从EstimatedRTT和DevRTT推算出的值.  

提供了一个形式受限的拥塞控制.   

**快速重传**   

因为TCP不使用否定确认,所以接收方不能向发送方发回一个显示的否定确认.相反,它只是对已经接收到的最后一个按序字节数据进行重复确认.  

当接收方收到3个冗余ACK,TCP就执行**快速重传(fast retransmit)**,即在该报文段的定时器过期之前重传丢失的报文段.  

>**冗余ACK(duplicate ACK)** 就是再次确认某个报文段的ACK.   

> [!question] 为什么等待3个而不是等待1个冗余ACK
> 因为1个的话可能没有丢,只是来晚了.   

**是回退N步还是选择重传**   

都不是.   

TCP确认是累积的,正确接收但失序的报文段并且缓存起来是不会被接收方逐个确认,TCP仅需要维持已发送过但未被确认的字节的最小序号和下一个要发送的字节的序号.   

TCP至多重传一个分组,此外,如果对报文n+1的确认报文在报文段n超时之前到来,甚至不会重传报文段n.   

对TCP提出的一种修改意见是所谓的**选择确认(selective acknowledgment)**.允许接收方有选择地确认失序报文段,而不是累积地确认最后一个正确接收的有序报文段.   

因此,TCP的差错恢复机制也许最好被分类为GBN协议与SR协议的混合体.   

#### 5.5 流量控制  

TCP为它的应用程序提供了**流量控制服务(flow-control service)** 以消除发送方使接收方缓存溢出的可能性.   

TCP也可能因为IP网络拥塞而被遏制.这种形式被称为**拥塞控制(congestion control)**.  

>两者的区别为,前者是主机间的接收能力,后者是整个网络被堵住了.    

TCP通过让发送方维护一个称为**接收窗口(receive window)** 的变量来提供流量控制.即给对方指示自己还有多少的缓存空间.    

当一方的接收窗口为0,另一方继续发送只有一个字节数据的报文段,这些报文段会为接收方确认,最终清空缓存,并且确认报文里将包含一个非0的rwnd值,避免死锁.     

#### 5.6 TCP连接管理   

建立过程： 
1. 客户端的TCP首先向服务器端发送一个特殊的TCP报文段,不包含应用层数据,SYN置1,因此,该报文段被称为SYN报文段,随机地选择一个初始序号(client_isn),并放入报文段的序号字段中,为了避免某些安全性攻击,在适当地随机化选择有很多研究,如通过时间戳来选择序号
2. 一旦SYN报文段达到服务器主机,服务器会为TCP连接分配TCP缓存和变量,并向客户TCP发送允许连接的报文段,该报文段也不包含应用层数据,但有3个重要信息,SYN置1,确认号为client_isn+1,服务器自己的初始序,称为**SYNACK报文段(SYNACK segment)** 
3. 在收到SYNACK报文段后,客户也要给该连接分配缓存和变量,客户主机则向服务器发送另外一个报文段,这最后一个报文段对服务器允许连接的报文段进行了确认,将server_isn+1放入确认号字段,SYN置0,此时可以携带数据  

这种过程称为**三次握手(three-way handshake)**,谢希仁的教材第8版使用了**三报文握手**的译名,因为RFC文档上写**three-way(three segment) handshake**.  

>[!question] 为什么要3次握手,而不是两次,而且还有序号
> 因为两次握手可能导致半连接和接收老数据的问题,如客户端请求建立连接,结果这个报文不知道跑哪去了,于是重新发了一个,建立完连接,发送数据,结果又抽风了,再重新发一遍,美滋滋弄完结束连接,结果上次的连接报文跑了过来,服务器以为客户又要建立连接,屁颠屁颠的发送了一个确认报文,因为我是两次连接,客户端不鸟它,于是产生了半连接,这时,数据的那个报文段出现了,于是服务器被骗了,收到了老数据还以为是真的,而采用了三次,在服务器收到旧的报文来确认时,告诉它没这回事,避免了之后的影响,这说明了感情的维持和防诈需要多沟通确认   
> 采用序号是因为可能网络上有些残党报文可能会对客户端和服务器的历史性握手造成影响   

关闭过程：   
1. 客户发出一个特殊的TCP报文段,FIN置1
2. 服务器发送确认报文,这时客户机不再发数据,服务器可以
3. 服务器发送终止报文
4. 客户机确认,有个定时等待,确保服务器收到了,典型的值有30s,60s,120s,为两倍的MSL(最长报文生存时间)

>TCP的关闭连接并不完美,如同三军问题,客户响应服务器的结束报文的确认报文没有到达,而导致服务器重传,结果又超过了定时等待的时间,导致没有关闭.   

服务器因为在响应SYN时,会分配资源,因此会受到SYN泛洪攻击,这是一种DoS攻击,只建立半连接不完成三次握手,导致服务器资源用尽崩溃.   

使用SYN cookie防范,简单来说就是服务器先不分配资源,先向你发送一个精心制作的初始序列号的SYNACK分组,该序列号通过源和目的IP地址与端口号以及一个秘密数的一个复杂函数(Hash Function).如果客户合法,则返回一个ACK报文,服务器就生成一个具有套接字的全开连接.   

如果服务器的端口不接受连接,则服务器发送一个特殊重置报文段,RST置1,告诉客户,端口未开放.UDP则是一个特殊的ICMP数据报.   

使用nmap工具进行端口扫描,有3种可能的输出：  
- 返回一个SYNACK报文段,打开的端口
- 接收到一个RST报文段,没有运行在该端口的应用程序,且没有任何防火墙阻挡
- 什么也没有,有防火墙


### 6. 拥塞控制原理  

#### 6.1 拥塞的原因与代价  

**情况1. 两个发送方和一台具有无穷大缓存的路由器**   

随着发送速率越接近R/2,吞吐量也到达R/2,但时延也会随之越来越大,但发送速率超过R/2,路由器的平均排队分组数就会无限增加,平均时延也会变成无穷大.    

**情况2. 两个发送方和一台具有有限缓存的路由器**   

在此看到了一种网络拥塞的代价,即发送方必须执行重传以补偿因为缓存溢出而丢弃的分组.   

还有一种是发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组.   

**情况3. 四个发送方和具有有限缓存的多台路由器及多跳路径**   

当一个分组沿一条路径被丢弃时,每个上游路由器用于转发该分组到丢弃,该分组而使用的传输容量最终被浪费了.   

#### 6.2 拥塞控制方法   

实践上所采用的两种主要拥塞控制方法,根据网络层是否为运输层拥塞控制提供了显示帮助来区分：  
- 端到端拥塞控制：在这里,网络层没有为运输层拥塞控制提供显示支持,即使网络中存在拥塞,端系统也必须通过对网络行为的观察来推断之.  
- 网络辅助的拥塞控制：在这里,路由器向发送方提供关于网络中拥塞状态的显式的反馈信息.这种反馈可以简单地使用一个比特来指示链路中的堵塞情况.这种方法在IBM SNA,DEC DECnet和ATM等体系结构中被采用.这种方式的通知通常采用了一种**阻塞分组(choke packet)** 的形式.经典的TCP不提供,但现在也能提供了.     

**ATM ABR(Available Bite Rate,可用比特率)** 拥塞控制中,路由器显式地通知发送方它(路由器)能在输出链路上支持的最大主机发送速率.   

ATM采用**信元(一种53字节的报文,首部为5字节)** 来传输数据.弹性的服务：  
- 如果发送端的路径轻载,发送方使用可用带宽
- 如果拥塞了,发送方限制其发送速率到一个最低保障速率上  

**RM(资源管理)信元**   

由发送端发送,在数据信元中间隔插入  

RM信元中的比特被交换机设置(网络辅助)  
- NI bit：no increase in rate(轻微阻塞),速率不要增加了
- CI bit：congestion indication 拥塞指示

发送端发送的RM信元被接收端,接收端不做任何改变.  

在RM信元中的2个字节ER(explicit rate)字段  
- 拥塞的交换机可能会降低信元中ER的值
- 发送端发送速度因此是最低的可支持速率

即将ER值设为通过的路径中最小的流量.    

数据信元中的EFCI bit：被拥塞的交换机设置成1  
- 如果在管理信元RM前面的数据信元EFCI被设置成了1,接收端在返回的RM信元中设置CI bit.    

### 7. TCP拥塞控制  

经典的TCP使用端到端拥塞控制而不是网络辅助的拥塞控制,因为IP层对端系统不提供明确的涉及网络拥塞的反馈.但是有变种可以,使用一种由网络层提供的明确拥塞指示.   

#### 7.1 经典的TCP拥塞控制   

TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率,但这种方法提出了三个问题：  
1. TCP发送方如何限制它向其连接发送流量的速率
2. TCP发送方如何感知从它到目的地之间的路径上存在拥塞
	1. 某个段超时了(丢失事件)：
		1. 超时时间到,某个段的确认没有到来
		2. 原因1.网络拥塞(某个路由器缓冲区没有空间了,被丢弃),概率大
		3. 原因2.出错被丢弃了(各级错误,没有通过校验,被丢弃),概率小
		4. 一旦超时,就认为拥塞了,有一定误判,但是总体控制方向是对的
	2. 有关某个段的3次重复ACK：轻微拥塞
		1. 段的第1个ACK,正常
		2. 段的第2个重复ACK,意味着有分组乱序达到
		3. 段的第2,3,4个ACK重复,意味着有段丢失概率大
		4. 网络这是还能够进行一定程度的传输,拥塞但情况要比第一种好
3. 当发送方感知到端到端的拥塞时,采用何种算法来改变发送速率

TCP连接每一端都是由一个接收缓存,一个发送缓存和几个变量(LastByteRead,rwnd等)组成.运行在发送方的TCP拥塞控制机制跟踪一个额外的变量,即**拥塞窗口(congestion window)**.表示为cwnd,它对一个TCP发送方能向网络中发送流量的速率进行了限制,特别是,在一个发送方中未被确认的数据量不会超过cwnd与rwnd中的最小值.即与流量控制做了缝合,下文假设rwnd无限大.   

上面的限制条件允许发送方向该连接发送cwnd个字节的数据,在该RTT结束时发送方接收方接收对数据的确认报文,因此,该发送方的发送速率大概为cwnd/RTT 字节/秒.通过调节cwnd的值,能调整它向连接发送数据的速率.    

因为TCP使用确认来触发(或计时)增大它的拥塞窗口长度,TCP被说成是**自计时(self-clocking)** 的.   

**TCP拥塞控制算法(TCP congestion control algorithm)** 包括3个主要部分：  
- 慢启动
- 拥塞避免
- 快速恢复

前两者是TCP的强制部分,两者的差异在于对收到的ACK做出反应时增加cwnd长度的方式,快速恢复是推荐部分,并非必需.  

**慢启动**  

一开始cwnd为1个MSS开始,然后对于每个发出去的报文接收到的确认就将cwnd增加一个MSS,即cwnd=1,收到ACK后cwnd=2,收到ACK后cwnd=4,实现指数增长.   

它还维护了一个状态变量ssthresh(慢启动阈值).   

何时结束：  
1. 当超时事件发生时,TCP发送方将cwnd设置为1,把ssthresh设置为cwnd/2,并重新开始慢开始过程
2. 当cwnd大于等于ssthresh,结束慢启动并进入到拥塞避免模式
3. 检测到3个冗余ACK,执行快速重传,进入快速恢复模式

由于慢启动启动慢,RTT很大时,用户体验不好,因此企业使用TCP分岔技术,用户以慢启动的方式向最近的CDN请求,CDN直接以前端非常大的窗口向数据中心建立连接.   

**拥塞避免**   

一旦进入拥塞避免,则cwnd的值大约是上次遇到拥塞时的一半,即距离拥塞并不遥远.因此采用一个较保守的增长方案,每个RTT只将cwnd的值增加一个MSS,这能够以几种方式完成,一种通用的方法为,无论何时到达一个新的确认,就将cwnd增加一个MSS\*(MSS/cwnd)字节.在一个RTT内,cwnd是固定的.具体实现有一个专门的计数器.     

何时结束：
1. 出现超时,进行慢启动,cwnd设置为1个MSS,ssthresh更新为cwnd的一半
2. 收到3个冗余ACK,进入快速恢复模式,ssthresh=cwnd/2,cwnd=ssthresh+3MSS(为使测量效果更好,已收到的3个冗余的ACK要加3个MSS)

**快速恢复**  

在快速恢复中,对于引起TCP进入快速恢复状态的缺失报文段,每当收到一个冗余ACK(前面已经收到了3个冗余,所以初始就有加3),cwnd增加一个MSS,最终,当对丢失报文段的一个ACK到达时,TCP在降低cwnd后进入拥塞避免.  

出现超时,进入慢启动模式,ssthresh=cwnd/2,cwnd=1.    

**TCP拥塞控制：回顾**  

TCP拥塞控制因为上面的机制被称为**线性加,乘性减(Additive-Increase,Multiplicative-Decrease,AIMD)**.    

**TCP Tahoe/Reno/CUBIC**  

1. 早期版本,没有快速恢复
2. 经典版
3. 随时间探测版

**对吞吐量的宏观描述**  

每到W/RTT时,发生丢包,然后发送速率减半,得到：
`一条连接的平均吞吐量=(0.75\*W)/RTT=((W/2)+w)/2\*RTT`  

#### 7.2 网络辅助明确拥塞通告和基于时延的拥塞控制  

**明确拥塞通告(Explicit Congestion Notification,ECN)**  

涉及TCP/IP.  

在网络层,有两个比特被用于ECN,位于IP的服务类型字段中.  

路由器使用一种ECN比特指示该路由器正在历经拥塞,该拥塞指示由被标记的IP数据报携带交给目的主机,再由目的主机通知发送主机.即绕了一圈.   

没有提供路由拥塞时刻的定义,由厂商自行决定.   

我们的直觉是在实际发生丢包之前设置拥塞指示位置比特,以向发送方发出拥塞开始的信号,发送主机使用的另一种ECN比特设置通知路由器发送方和接收方是ECN使能的,因此能够对ECN指示的网络拥塞采取行动.   

如收到的数据报得到ECN指示,将接收方到发送方的TCP ACK报文段中的ECE(明确拥塞通告回显)比特置位,从而通知发送主机中的TCP拥塞指示以收到.接下来,发送方通过减半拥塞窗口对一个具有ECN指示的ACK做出反应,并且在下一个传输的TCP发送方到接收方的报文段首部中对CWR比特进行置位.   

除了TCP以外的其他运输层协议也可以利用网络层发送ECN信号,如**数据报拥塞控制协议(Datagram Congestion Controll Protocol,DCCP)** 提供了一种低开销的类似UDP的不可靠服务.DCTCP(数据中心TCP)和DCQCN(数据中心拥塞通告)专门为数据中心网络设计,也利用了ECN.  

**基于时延的拥塞控制**  

目的是在丢包之前主动检测拥塞.   

TCP Vegas,测量RTT最小值,得到一个未拥塞吞吐量速率cwmd/RTT<sub>min</sub>,快速接近这个值,超出时,则减小发送速率.背后的客观事实为"保持管道刚好充满,而不可以更满".即让链路(尤其是瓶颈链路)始终忙于传输,但不会建立长队列.   

BBR拥塞控制协议,在上面的基础上构建,并且综合了允许与TCP公平竞争的机制.谷歌有所布置.   

#### 7.3 公平性  

即考虑一个传输速率为Rbps,没有其他流量,每个连接的平均传输速率接近R/K.  

TCP的AIMD算法,随着时间的推移会逐渐平均,因为考虑(3,1),减半后变为(1.5,0.5),(0.75,0.25),(0.325,0.125)...,最后逐渐接近1:1.   

**公平性和UDP**  

UDP没有内置的拥塞控制,对于TCP来说,运行在UDP上的多媒体应用是不公平的,因为它们不与其他连接合作,也不适时调整其传输速率.  

TCP在面临拥塞时,将降低传输速率,而UDP不会,UDP源可能压制TCP流量.  

当今的一个主要研究领域就是开发一种因特网中的拥塞控制机制,用于阻止UDP流量不断压制直至中断因特网吞吐量的情况.   

>TCP像个君子,处处讲礼,UDP像个海盗,风行雷厉.   

**公平性和并行TCP连接**  

即使用多个并行TCP连接会抢占多的传输速率.   

如一个支持了9个连接的服务器,每个连接的传输速率为R/9,假设加入了新的用户,如果是一个连接则每个用户为R/10,如果他不讲武德,建立了11个连接,则他将独占一半以上的带宽.   

### 8. 运输层功能演化  

TCP和UDP也不断的在演化,有了很多的版本.  

TCP不同的版本包括：无线链路,具有大RTT的高带宽路径,具有分组重排的路径和数据中心内部的严格短路径而设计的多种TCP版本.当然还有更多,见书上原话吧(p184,第8版自顶向下).  

这些变种唯一的共同点是使用了TCP报文段格式,并且面对网络拥塞会"公平"竞争.   

**QUIC**  

**应用层协议**.  

如果你的应用不是完全适合TCP和UDP,也可以在应用层构建自己的协议.  

QUIC就是一种典型,旨在提高安全HTTP的运输层服务的性能.尽管它还只是处于标准化的过程中,但得到了广泛的部署.   

其使用UDP作为支撑协议,专门为简化HTTP/2版本而设计,在将来,HTTP/3将与生俱来地综合进QUIC,其主要特点：  
- 面向连接和安全：建立QUIC连接
- 数据流：使用流控制协议,让多个数据流在一个QUIC上复用,web页面的每一个对象有一个数据流,每条连接有一个连接ID,每个数据流有个流ID,都包含在QUIC首部中,来自多条流的数据可能包含在单个QUIC报文段中
- 可靠的,TCP友好的拥塞控制数传输：使用类似TCP的应答机制,由于基于UDP,因此丢失的报文段仅影响其数据正由该报文段承载的那些数据流,而那些其他数据流中的HTTP报文能够继续为该应用程序所接收和交付,而不是直到丢失的字节被重传,余下的HTTP请求才交付   

QUIC的拥塞控制基于TCP NewReno,后者仅与TCP Reno有少量差别.    

## 网络层   

### 1. 网络层概述  

网络层能够被分解为两个层面：
- 数据平面：主要作用是从其输入链路向其输出链路转发数据报
- 控制平面：主要作用是协调这些本地的每个路由器转发操作,使得数据报沿着源和目的地主机之间的路由器路径最终进行端到端的传送

#### 1.1 转发和路由选择  

网络层的作用需要使用两种重要的网络层功能：
- 转发：当一个分组到达某路由器的一条输入链路时,该路由器必须将该分组移动到适当的输出链路,分组也可能被现有的路由器阻挡,修改等
- 路由选择：当分组从发送方流向接收方时,网络层必须决定这些分组所采用的路由或路径,计算这些路径的算法被称为**路由选择算法(routing algorithm)** 

**转发(forwarding)** 通常在很短的时间尺度(通常为几纳秒).由硬件实现.   

**路由选择(routing)** 通常在长得多的时间尺度(通常为几秒).由软件实现.   

每台网络路由器中有一个关键元素是它的**转发表(forwarding table)**.通过检查到达分组首部的一个或多个字段值,进而使用这些首部值在转发表中索引,通过这种方法来转发分组.   

**1. 控制平面：传统的方法**   

路由选择算法决定了插入该路由器转发表的内容.一台路由器的路由选择算法与其他路由器中的路由选择算法通信,以计算出它的转发表的值,这种通信是通过路由选择协议交换包含路由选择信息的路由选择报文.  

当然也可以人工配,但耗时耗力,还不一定配的好.  

使用该方法,每台路由器都有一个与其他路由器的路由选择组件通信的路由选择组件.   

**2. 控制平面：SDN方法**  

将控制平面与数据平面进行物理上的分离,远程控制器计算和分布转发表以供每台路由器所使用.   

控制平面路由选择功能与与物理的路由器是分离的,即路由选择设备仅执行转发,而远程控制器计算并分发转发表.   

远程控制器可能实现在具有高可靠性和冗余的远程数据中心中,并可能通过ISP或第三方进行管理.   

路由器与远程控制器通过交换包含转发表和其他路由选择信息的报文进行通信.  

SDN即**软件定义网络(Software Defined Networking,SDN)**,因为计算转发表并与路由器交互的控制器是用软件实现的,故网络是"软件定义"的,这些软件实现是开源的.   

#### 1.2 网络服务模型 

**网络服务模型(network service model)** 即定义了分组在发送与接收主机之间的端到端传输特性如：
- 实时
- 确保交付
- 有序
- 安全
- 最小带宽
- etc

因特网只提供单一的服务,即**尽力而为服务(best-effort service)** ,即没有特性.  

但因特网的尽力而为服务模型与适当带宽供给和带宽自适应应用级协议的结合,已被证明超过"足够好",能够用于大量的应用.   

### 2. 路由器工作原理   

通用的路由器体系结构包含：  
- 输入端口：
	- 在路由器中执行终止来自外部物理链路的连接至路由器的物理层功能(书上翻译为终结入物理链路的物理层功能,个人理解为终止链路的传输,进行封装)
	- 与位于入链路远端的数据链路层交互操作来执行数据链路层功能
	- 执行查找功能
	- 控制分组从输入端口转发到路由选择处理器
- 交换结构：
	- 将路由器的输入端口连接到输出端口
- 输出端口：
	- 存储从交换结构接收的分组,并通过执行必要的链路层和物理层功能在输出链路上传输这些分组
- 路由选择处理器：
	- 执行控制平面功能
		- 在传统路由器中,执行路由选择协议,维护路由选择表与关联链路状态信息,并为该路由器计算转发表
		- 在SDN中,负责与远程控制器通信,目的是接收由远程控制器计算的转发表项,并在该路由器的输入端口安装这些表项
	- 执行网络管理功能

路由器的输入端口,输出端口和交换结构几乎总是用硬件实现,因为硬件实现的速度远快于软件实现的速度.  

控制平面的功能通常用软件实现并在路由选择处理器上执行.   

#### 2.1 输入端口处理和基于目的地转发  

1. 路由器使用转发表来查找输出端口
2. 转发表通过路由选择器计算和更新,或从SDN控制器中接收
3. 转发表通过独立总线复制到线路卡
4. 使用线路卡的影子副本,转发决策能在每个输入端口本地做出,无须基于每个分组调用集中式路由选择处理器

转发表使用了地址前缀进行简化,同时对地址进行**最长前缀匹配规则(longest prefix matching rule)**,找出准确的地址转发.    

为了更快,不仅必须使用硬件执行查找,而且需要对大型转发表使用简单线性搜索以外的技术,如快速查找算法.  

同时,对内存访问时间格外关注,结果是采用嵌入式的DRAM和更快的SRAM内存设计,实践也常用**三态内容可寻址存储器(Tenary Content Address Memory,TCAM)** 来查找.   

一旦通过查找确定了某分组的输出端口,则该分组就能够发送进入交换结构,在某些设计中,如果来自其他输入端口的分组当前正在使用该交换分组,一个分组可能会在进入交换结构时被暂时阻塞.因此,被阻塞的分组必须要在输入端口处排队,并等待稍后被及时调度以通过交换结构.     

尽管查找很重要,但还是必须采用许多其他的操作：
- 必须出现物理层和链路层处理
- 必须检查分组的版本号,检验和以及寿命字段,并且重写后面两个字段
- 必须更新用于网络管理的计数器

#### 2.2 交换   

交换结构位于一台路由器的核心部位,因为正是通过这种交换结构,分组才能实际地从一个输入端口交换到一个输出端口中.   

交换可以用许多方式完成：  
- 经内存交换
	- 最简单,最早的路由器是传统的计算机,输入端口与输出端口之间的交换是在CPU(路由选择控制器)的直接控制下完成的
	- 输入与输出端口的功能就像传统的操作系统中的I/O设备一样.一个分组到达一个输入端口时,该端口会先通过中断方式向路由选择器发送信号,于是,该分组从输入端口处被复制到处理器的内存中
	- 路由器选择器从首部提取目的地址,在转发表中查找适当的输出端口,并将该分组复制到输出端口的缓存中
	- 如果内存带宽为每秒可写进或读出最多B个分组,则总吞吐量必然小于B/2
	- 不能同时转发两个分组,即使它们有不同的目的端口,因为经过共享系统总线一次仅能执行一个内存读/写
	- 许多现代路由器通过内存进行交换,然而,与早期路由器的一个主要差别是,目的地址的查找和将分组存储进适当的内存存储位置是由输入线路卡来处理的,在某些方面,经内存交换的路由器看起来很像共享内存的多处理器,用一个线路卡上的处理器将分组交换写进适当的输出端口的内存中
- 经总线交换
	- 经一根共享总线将分组直接传送到输出端口,不需要路由选择处理器干预,通常按以下方式完成该任务：
		- 让输入端口为分组预先计划一个交换机内部标签(首部),指示输出端口,使分组在总线上传送和传输到输出端口
		- 该分组能由所有输出端口收到,但只有与该标签匹配的端口才能保存该分组
		- 然后标签在输出端口被去除,因为其仅用于交换机内部来跨越总线
	- 如果多个分组到达路由器,每个位于不同的输出端口,除了一个分组外所有其他分组必须等待,因为一次只有一个分组能够跨越总线
	- 因为每个分组必须跨过单一总线,故路由器的交换带宽受总线速率的限制
- 经互联网络交换
	- 纵横式交换机就是一种由2N条总线组成的互联网络,它连接N个输入端口与N个输出端口
	- 每条垂直的总线在交叉点与每条水平的总线交叉,交叉点通过交换结构控制器(其逻辑是交换结构自身的一部分)能够在任何时候开启或闭合
	- 纵横式网络能够并行转发多个分组,纵横式交换机是**非阻塞的(nonblocking)** ,即只要没有其他分组当前被转发到该输出端口,转发到输出端口的分组就不会被到达其他输出端口的分组阻塞
	- 如果来自两个不同输入端口的两个分组的目的地为相同的输出端口,则一个分组必须在输入端等待,因为在某个时刻经给定总线仅能够发送一个分组
	- 更为复杂的互联网络使用多级交换元素,以使来自不同输入端口的分组通过交换结构同时朝着相同的输出端口前行

#### 2.3 输出端口处理  

输出端口处理已经存放在输出端口内存中的分组并将其发送到输出链路上,这包括选择和取出排队的分组进行传输,执行所需的链路层和物理层传输功能.    

#### 2.4 何处出现排队   

##### 2.4.1 输入排队  

当交换结构不能快得(相对于输入线路速度而言)使所有到达分组无时延地通过它传送,就会在输入端口出现分组排队.    

在一个输入队列中排队的分组必须等待通过交换结构发送(即使输出端口是空闲的),因为它被位于队列首部的另一个分组阻塞,称为**队列首部(Head-Of-the-Line,HOL)**.   

##### 2.4.2 输出队列   

当交换结构的速度远大于输入输出线路的速率,且转发的分组目的转发端口一致就会出现分组排队,最终排队的分组能够变得足够大,耗尽输出端口的可用内存.    

当没有足够的内存来缓存一个入分组时,就必须做出决定：要么丢弃到达的分组(弃尾),要么删除一个或多个已排队的分组为新来的分组腾出空间(高贵的VIP),在某些情况下,在缓存填满之前便丢弃一个分组(或在其首部加上标记)的做法是有利的,这可以向发送方提供一个拥塞信号,使用明确拥塞通告比特的方法可对分组进行标记,已经提出和分析了许多分组丢弃与标记策略,这些策略统称为**主动队列管理(Active Queue Management,AQM)** 算法,**随机早期检测(Random Early Detection,RED)** 算法是得到最广泛研究和实现的AQM算法之一.   

##### 2.4.3 多少缓存才"够用"   

多年以来,用于缓存大小的经验方法是缓存数量(B)应当等于平均往返时延(RTT)乘以链路的容量(C),即B=RTT\*C.这个结果是基于相对少量的TCP流的排队动态性分析得到的.   

然而,更新的理论和实验研究提出,当有大量的TCP流流过一条链路时,所需要的缓存数量为B=RTT\*C/N<sup>1/2</sup>.典型的情况是有大量流经过的大型主干路由器链路,N的值可能非常大,从而使得所需的缓存明显减少.   
更多的缓存将使路由器有能力承受的分组到达率的更大波动,从而降低路由器的分组丢失率,但是更大的缓冲区也意味着潜在的更长的排队时延.对于一些用户而言,十几毫秒很重要,为减少丢包而将每跳缓冲区的数量增加10倍,可能会增加10倍的端到端时延,增加的RTT也使TCP发送方的响应速度降低,对早期拥塞或分组丢失的响应速度变慢.这些基于时延的考虑表明,缓存是一把双刃剑,即缓存可用于承受流量中的短期统计波动,但也可能导致时延增加带来的问题.   

> [!note] 根据书上P212例子理解的缓存膨胀
>当发送的数据包在经过一个RTT时间后还没有发完,因为有传输TCP,则响应报文发过来,又发出一个数据报,导致队列维持一个常数,这个因持续缓冲而导致长时延的场景被称为**缓存膨胀(bufferbloat)**,说明不仅吞吐量重要,而且最小的时延也重要,而且,网络边缘的发送者之间的交互和网络中的队列的确起到复杂和微妙的作用.   

#### 2.5 分组调度   

##### 2.5.1 先进先出(First-In-First-Out,FIFO)  

如果链路当前正忙于传输另一个分组,到达链路输出队列的分组要排队等待传输.如果没有足够的缓存空间来容纳,队列的分组丢弃策略则确定该分组是否将被丢弃或者从队列中去除其他分组以便为达到的分组腾出空间.   

FIFO(也称为先来先服务,FCFS)调度规则按照分组到达输出链路队列的相同次序来选择分组在链路上传输.    

##### 2.5.2 优先权排队(priority queuing)  

到达输出链路的分组被分类放入输出队列中的优先权类,每个优先权类通常都有自己的队列,当选择一个分组传输时,优先权排队规则将从队列为非空的最高优先权类中选择传输一个分组,在同一优先权类的分组之间的选择通常以FIFO方式完成.   

>在普通用户之上的是最尊贵的VIP,而在VIP之上的是更加尊贵的SVIP,而在SVIP之上的是...etc...   

##### 2.5.3 循环和加权公平排队(round robin queuing discipline)   

分组像使用优先权排队那样被分类.然而,在类之间不存在严格的服务有限权,循环调度器在这些类之间轮流提供服务.在最简单的循环调度中,类1的分组被传输,接着是类2的分组,接着又是类1的分组,再接着又是类2的分组...   

一个所谓的**保持工作排队(work-conserving queuing)** 规则在有(任何类的)分组排队等待传输时,不允许链路保持空闲.当寻找给定类的分组但是没有找到时,保持工作的循环规则将立即检查循环序列中的下一个类.    

一种通用形式的循环排队已经在路由器中广泛地实现,它就是所谓的**加权公平排队(Weighted Fair Queuing,WFQ)** 规则.   

不同之处在于,每个类在任何时间间隔内可能收到不同数量的服务.即,每个类i被分配一个权w<sub>i</sub>,使用WFQ的方式,在类i有分组要发送的任何时间间隔中,类i将确保接收到的服务部分等于w<sub>i</sub>/每个w<sub>j</sub>的和,分母的和为通过计算所有有分组排队等待传输的类别得到,在最坏的情况下,即使所有的类都有分组排队,类i也能保证分配到带宽的w<sub>i</sub>/(每个w<sub>j</sub>的和)部分,这里的描诉理想化了,分组是离散的数据单元,并且不能打断一个分组的传输来开始传输另一个分组.    

### 3. 网际协议：IPv4,寻址,IPv6及其他   

#### 3.1 IPv4数据报格式     

格式：
<table width = 500 >
<tr ><td align=center width = 12%>版本</td><td align=center width = 13%>首部长度</td><td align=center width = 25%>服务类型</td><td  colspan = 2 width=50% align = center>数据报长度(字节)</td></tr>
<tr ><td width = 50% align=center colspan = 3>16比特标识</td><td align=center width = 10%>标志</td><td align=center width = 40%>13比特片偏移</td></tr>
<tr><td align=center width = 25% colspan = 2>寿命</td><td width = 25% align=center>上层协议</td><td align=center width = 50% colspan = 2>首部校验和</td></tr>
<tr><td colspan = 5 align = center>32比特源IP地址</td></tr>
<tr><td colspan = 5 align = center>32比特目的IP地址</td></tr>
<tr><td colspan = 5 align = center>选项(如果有的话)</td></tr>
<tr><td colspan = 5 align = center>数据</td></tr>
</table>

关键字段：  
- 版本：
	- 4比特规定了数据报的IP协议版本
	- 通过查看版本号,路由器能够确定如何解释IP数据报的剩余部分
	- 不同的IP版本使用不同的数据报格式
- 首部长度：
	- 因为一个IPv4数据报可包含一些可变数量的选项(这些选项包括在IPv4数据报首部中),故需要用这4比特来确定IP数据报中载荷实际开始的地方
	- 大多数IP数据报不包含选项,所以一般的IP数据报具有20字节的首部
- 服务类型：
	- 使不同类型的IP数据报能相互区别开来
	- PS：基本弃用了
- 数据报长度：
	- 这是IP数据报的总长度,以字节计
	- 因为长为16比特,所以理论最大长度为65535字节,然而数据报很少有超过1500字节的,该长度使得IP数据报能容纳最大长度以太网帧的载荷字段
- 标识,标志,片偏移：
	- 这三个字段与所谓的IP分片有关
	- 一个大的IP数据报被分解成几个小的IP数据报,然后这些小的IP数据报被独立地转发到目的地,在那里被重新组装,然后其有效载荷数据向上传递到目的主机的运输层
	- IPv6不允许分片
- 寿命：
	- Time-to-Live,TTL
	- 用来确保数据报不会永远在网络中循环,每当一太路由器处理数据报时,该字段的值就减1
	- 为0就被丢弃
	- PS：如果没有该字段,或者TTL非常大,我是旧网络的数据包,新网络没有容纳我的空间,或者把网络缓存资源通通占满:)
- 协议：
	- 该字段通常仅当一个IP数据报到达其最终目的地时才会有用,该字段值指示了IP数据报的数据部分应交给那个特定的运输层协议如6TCP,17UDP
- 首部检验和：
	- 用来帮助路由器检测收到的IP数据报中的比特错误
	- 将首部中的每2个字节当作一个数,用反码算数对这些数求和
	- 路由器要对每个收到的IP数据报计算其首部校验和,如果数据报首部中校验和与计算得到的校验和不一致,则检测出是个差错,一般会丢弃检测出错误的数据报
	- 注意到在每台路由器上必须重新计算校验和并再次存放到原处,因为TTL字段以及可能的选项字段会改变
	- 为什么TCP/IP都执行差错检测
		- 首先IP只对IP首部计算了检验和,而TCP/UDP是对整个报文段进行的
		- TCP/UDP与IP不一定属于同一个协议栈,原则上TCP能够运行在一个不同的协议,而IP能够携带不一定要传递给TCP/UDP的数据
- 源和目的IP地址：
	- 当某源生成一个数据报时,它在源IP字段插入它的IP地址,在目的IP地址字段插入其最终目的地的地址
	- 通常主机通过DNS查找来决定目的地址
- 选项：
	- 选项字段允许IP首部被扩张
	- 首部选项意味着很少使用,因此决定对每个数据报首部不包括选项字段中的信息,能够节约开销
	- 然而,少量选项的存在的确使问题复杂了,因为数据报首部长度可变,故不能预先确定数据字段从何处开始
	- 还因为有些数据报要求处理选项,而有些数据报则不要求,故导致一台路由器处理一个IP数据报所需要的时间可能变化很大
- 数据(有效载荷)：
	- 大多数情况下,IP数据报包含要交付给目的地的运输层报文段
	- 也可承载其他类型的数据

注意到一个IP数据报有总长为20字节的首部.     

**IP分片和重组**   
- 网络链路有MTU,即链路层帧所携带的最大数据长度
	- 有不同的链路类型
	- 不同的MTU
- 大的IP数据报在网络上被分片
	- 一个数据报被分割成若干个小的数据报
		- 相同的ID
		- 不同的偏移量
		- 最后一个分片标记为0
	- 重组只在最终的目标主机进行
	- IP头部的信息被用于标识,排序相关分片

例：   
有一个4000字节的IP数据报,MTU为1500,需要分片   
第一片：标识设为1,MF1,片偏移0   
第二片：标识设为1,MF1,片偏移185   
第三片：标识设为1,MF1,片偏移370  

分出来的片需要有首部,片偏移的计算为第一个字节的序号除以8.   

为什么除8：  
因为有13位比特的片偏移长度,而数据报的长度有16比特,即通过除8来映射到16比特的长度.   

#### 3.2 IPv4编址   

一台主机通常只有一条链路连接到网络,当主机中的IP想发送一个数据报时,它就在该链路上发送.主机与物理链路之间的边界叫做**接口(interface)**.  

一台路由器的任务是从链路上接收数据报并从某些其他链路转发出去,所以路由器必须拥有两条或更多条链路与它连接.路由器与它的任意一条链路之间的边界也叫作接口.路由器因此有多个接口,每个接口有其链路,因为每台主机与路由器都能发送和接收IP数据报,IP要求每台主机和路由器接口拥有自己的IP地址.   

因此,从技术上讲,一个IP地址与一个接口相关联,而不是与包括该接口的主机或路由器相关联.   

每个IP地址长32比特,使用**点分十进制记法(dotted-decimal notation)** 即地址中的每个字节用它的十进制形式书写,各字节间以句号隔开.   

在全球因特网中,每台主机和路由器上的每个接口都必须有一个全球唯一的IP地址,然而,这些地址不能随意地自由选择.一个接口的IP地址的一部分需要其连接的子网来决定.    

**子网(subnet)**  

一个子网内的节点,它们的IP地址的高位部分相同,这些节点构成的网络的一部分叫做子网.   
无需路由器介入,子网内各主机可以在物理上相互直接达到.    

要判断一个子网,将每一个接口从主机或者路由器上分开,构成了一个个网络的孤岛.   

每一个孤岛(网络)都是一个都可以被称为子网.    

因特网的地址分配策略被称为**无类别域间路由选择(Classless Interdomain Routing,CIDR)**,CIDR将子网寻址的概念一般化了,当使用子网寻址时,32比特的IP地址被划分为两部分,并且也具有点分十进制数形式a.b.c.d/x,其中x指示了第一部分中的比特数,称为**子网掩码(network mask)**.x最高比特构成了IP地址的网络部分,并且经常被称为该地址的**前缀(prefix)**.后32-x位被称为**主机号**,可以进一步划分子网,也可用于标识设备.     

通过仅考虑网络前缀,相当大地减少了在这些路由器中转发表的长度.    

一般一个组织拿到一块地址时,可以将这块地址进一步划分,如同推恩令一般,并且对外的路由器可以使用单个网络前缀(即最初拿到的那块)通告外界自己内部所有划分的网络,称为**地址聚合(address aggregation),或者路由聚合(route aggregation)与路由摘要(route summarization)**,如果在一块大块地址里分出来的小的子网并不是连续,如有几块在其他组织,可以对连续小的子网进行聚合,对单独的子网单独声明,路由器将采用**最长前缀匹配**来转发数据报.   

在CIDR之前,IP地址的网络部分被限制为长度为**8,16,24**比特,这是一种称为**分类编址(classful addressing)** 的编址方案,这是因为8,16,24比特子网被称为A,B,C类网络.   

这中方案的地址空间分配不合理,导致大的太大,小的太小,不够分.     

**IP地址分类**：  
- Class A：126 networks,16 million hosts
- Class B：16382 networks,64 K hosts
- Class C：2 million networks,254 host
- Class D：multicast
- Class E：reserved for future

<table>
<tr><td>A：0开头,8位net地址,24位主机地址</td><tr>
<tr><td>B：10开头,16位net地址,16位主机地址</td><tr>
<tr><td>C：110开头,24位net地址,8位主机地址</td><tr>
<tr><td>D：1110开头,多播地址</td><tr>
<tr><td>E：11110开头,保留地址</td><tr>
</table>

**特殊IP地址**：  
- 子网部分：
	- 全0本网络
- 主机部分：
	- 全0本主机
	- 全1广播地址,这个网络的所有主机

<table>
<tr><td>全0</td><td>用于标志本主机,在DHCP中有使用</td></tr>
<tr><td>只有主机部分全0</td><td>标志网络地址</td></tr>
<tr><td>只有网络部分全0</td><td>标志本网络的一台主机地址</td></tr>
<tr><td>全1</td><td>受限广播地址,仅限当前本地网络使用,路由器不转发</td></tr>
<tr><td>只有主机部分全1</td><td>本地网络广播地址,向同一子网内所有主机发送数据</td></tr>
<tr><td>高8位为127其余任意</td><td>环回地址,用于本机内部通信,数据不经过物理网卡</td></tr>
<tr><td>169.254.0.0/16</td><td>链路本地地址,当设备无法通过DHCP获取IP时自动分配</td></tr>
<tr><td>224.0.0.0 239.255.255.255</td><td>组播地址,用于一对多通信</td></tr>
</table>

**内网(专用)IP地址**：
- 专用地址：地址空间的一部分供专用地址使用
- 永远不会被当做公用地址来分配,不会与公用地址重复
	- 只在局域网中有意义,区分不同的设备
- 路由器不对目标地址是专用地址的分组进行转发
- 专用地址范围：
	- Class A 10.0.0.0-10.255.255.255 MASK 255.0.0.0
	- Class B 172.16.0.0-172.31.255.255 MASK 255.255.0.0
	- Class C 192.168.0.0-192.168.255.255 MASK 255.255.255.0

**得到IP地址**  

1. 获取一块地址   
	1. 从ISP中获取
	2. ISP从**因特网名字和编号分配机构(Internet Corporation for Assigned Names and Numbers,ICANN)** 得到分配的IP地址,其还管理DNS根服务器以及分配域名与解决域名纷争
2. 获取主机地址:：动态主机配置协议
	1. 系统管理员通常手动配置路由器中的IP地址,主机地址也能够手动配置,但是这项任务目前更多的是使用**动态主机配置协议(Dynamic Host Configuration Protocol,DHCP)** 来完成
	2. 网络管理员能够配置DHCP,以使某给定主机每次与网络连接时能得到一个相同的IP地址,或者某主机将被分配一个临时的IP地址,每次与网络连接时该地址也许是不同的,除了主机IP地址分配外,DHCP还允许一台主机得知其他信息,例如它的子网掩码,它的第一跳路由器地址与它的本地DNS服务器的地址
	3. 由于DHCP具有将主机连接到一个网络的网络相关方面的自动化能力,故它又常被称为**即插即用协议(plug-and-play protocol)** 或**零配置(zeroconf)** 协议
	4. DHCP是一个客户-服务器协议,在最简单场合下,每个子网将具有一台DHCP服务器,如果没有,则需要一个DHCP中继代理服务的路由器
	5. DHCP是一个4个步骤的过程：
		1. DHCP服务器发现,一台新到达的主机通过使用**DHCP发现报文(DHCP discover message)** 来完成,客户在UDP分组中向端口67发送该发现报文,该UDP分组封装在一个IP数据报中,目的地址为广播地址255.255.255.255并且源IP为0.0.0.0.DHCP客户将该IP数据报传递给链路层,链路层然后将该帧广播到所有与该子网连接的节点
		2. DHCP服务器提供,DHCP服务器收到一个DHCP发现报文时,用**DHCP提供报文(DHCP offer message)** 向客户做出响应,该报文向该子网的所有节点广播,因为这时还没有分配给客户IP地址,这时可能会存在几个DHCP服务器,该客户也许会发现它处于能在几个提供者之间进行选择的优越位置(PS.就像老板们抢着要你),每台服务器提供的报文包含收到的发现报文的事务ID,向客户推荐的IP地址,网络掩码以及**IP地址租用期(address lease time)**,即IP地址有效时间量,通常为几小时或几天   
		3. DHCP请求,客户从一个或多个服务器提供中选择一个,并向选中的服务器提供**DHCP请求报文(DHCP request message)** 进行响应,回显配置的参数
		4. DHCP ACK,服务器用**DHCP ACK报文(DHCP ACK message)** 对DHCP请求进行响应,证实所要求的参数

#### 3.3 网络地址转换(Network Address Translation,NAT)  

用于将**专用网络(private network)或具有专用地址的地域(realm with private)** 接入外界,对外界而言,NAT路由器就如同一个具有单一IP地址的设备.从本质上讲,NAT路由器对外界隐藏了内部网络的细节.   

路由器从DHCP服务器得到IP地址,家庭主机从运行着DHCP服务器的NAT路由器得到地址.   

NAT路由器使用一张**NAT转换表(NAT translation table)** 来知道如何转发分组,表中包含了端口号及其IP.比如,一个发往外界的报文IP192.168.0.5:5008,经过路由器时修改为93.5.1.6:7252,选出一个未用的端口修改原有报文发出去,然后通过记录接收发回对应主机.   

>这显然违反了**端到端原则**因此也有人贬低.    

这种方式对于运行在家庭网络中的服务器会有问题,解决方案有**NAT穿越(NAT traversal)** 工具和通用即插即用(Universal Plug and Play,UPnP).UPnP是一种允许发现和配置邻近NAT的协议.   

解决方案：  
1. 静态配置NAT：转发进来的对服务器特定端口连接请求
2. UPnP和Internet Gateway Device协议：
	1. 获知网络的公共IP地址
	2. 列举存在的端口映射
	3. 增/删端口映射
	4. PS：自动化静态NAT端口映射配置
3. 中继(used in Skype)  
	1. NAT后面的服务器建立和中继连接
	2. 外部客户连接到中继
	3. 中继在2个连接中桥接

#### 3.4 IPv6  

在2011年2月,IANA向一个区域注册机构分配完了未分配IPv4地址的最后剩余地址池.    

> [!question] IPv5呢?
> IPv5是个实验性的协议,最初预想为ST-2协议将成为IPv5,但被舍弃了.   

##### 3.4.1 IPv6数据报格式   

<table width = 320>
<tr><td width = 40 align = center>版本</td><td width = 80 align=center>流量类型</td><td width = 200 align=center colspan=3>流标签</td></tr>
<tr><td width = 160 align = center colspan=3>有效载荷长度</td><td width=80 align=center>下一个首部</td><td width=80 align=center>跳限制</td></tr>
<tr><td colspan = 5 align=center>原地址(128比特)</td></tr>
<tr><td colspan = 5 align=center>目的地址(128比特)</td></tr>
<tr><td colspan = 5 align=center>数据</td></tr>
</table>

IPv6中引入的最重要的变化显示在其数据报格式中：   
- 扩大的地址容量
	- 将IP地址长度从32比特增加到128比特,这就确保了全世界将不会用尽IP地址(PS:我觉得至少在我活着的时候用不完,但以后说不准)
	- 除了单播与多播地址以外,IPv6还引入了一种**任播地址(anycast address)** 的新型地址,这种地址可以使数据报交付给一组主机中的任意一个
- 简化高效的40字节首部
	- 许多IPv4字段已被舍弃或作为选项,因而所形成的40字节定长首部允许路由器更快地处理IP数据报,一种新的选项编码允许进行更灵活的选项处理
- 流标签
	- 该字段可以用于"给属于特殊流的分组加上标签,这些特殊流是发送方要求进行特殊处理的流,如一种非默认服务质量或需要实时服务的流"
	- PS：我的理解为就是给流量进行标识,然后区别对待

IPv6字段：  
- 版本：
	- 4比特标识IP版本号
	- 这不是想标什么就标什么,如6不能标成4
- 流量类型：
	- 类似IPv4中的服务类型(TOS)
	- 用于标识数据包的优先级或服务质量(QoS)需求
	- 告知网络设备如何优先处理该数据包,如区分实时流量和普通流量
- 流标签：
	- 20比特的字段用于标识一条数据报的流,标志属于同一条流的数据报序列,一个流通常指特定源和目标之间的一组相关数据报
	- 能够对一条流中的某些数据报给出优先权,或者它能够用来对来自某些应用的数据报给出更高优先级,以优于来自其他应用的数据报
	- 帮助网络设备快速识别并统一处理同一流的所有数据报,避免逐包解析头部,提升处理效率
- 有效载荷长度：
	- 该16比特值作为一个无符号整数,给出了IPv6数据报中跟在定长的40字节数据报首部后面的字节数量
- 下一个首部：
	- 使用与IPv4协议字段相同的值,是协议字段和选项字段的结合体
	- 指示紧接当前头部之后的内容类型
		- 该字段标志数据报中的内容(需要交付给哪个协议)
	- 构建扩展头部链
		- 若存在多个扩展头部(如逐跳选项,路由,分片等),每个扩展头部均包含自己的下一个首部字段,形成链式结构,直至最终的上层协议
		- 主IPv6头部：
			- Next Header字段指向第一个扩展头部类型
		- 扩展头部：
			- 每个扩展头部内部也包含一个Next Header字段,指向下一个头部
		- 终止条件：
			- 当Next Header值为传输层协议时,扩展头部链终结
	- 无法识别某个扩展头部,根据Next Header值决定丢弃或转发
	- 逐跳选项(值为0)：
		- 唯一必须被路径上所有路由器处理的扩展头部,其他仅由目标节点处理
	- 顺序要求：
		- 必须按规范顺序出现(如逐跳必须出现在最前)
- 跳限制：
	- 根据转发数据报的每台路由器将对该字段的内容减1,如果跳限制计数达到0,丢弃该数据报
- 源和目的地址：
	- 在RFC4291中有描述
- 数据：
	- 数据报的有效载荷部分,到达目的地时,该有效载荷就从IP数据报中移出,并交给在下一个首部字段中指定的协议处理

以下几个字段在IPv6中不复存在：  
- 分片/重新组装：
	- IPv6不允许中间路由器进行分片与重新组装,只能在目的和源上进行
	- 如果路由器收到数据报太大而不能转发,则丢弃,并向发送方发送一个ICMP报文告知,于是发送方能够使用较小长度的IP数据报重发数据
	- 分片与重新组转是一个耗时的操作,将该功能从路由器中删除并放到端系统中大大加快了网络中IP数据报转发的速度
- 首部校验和：
	- 因为因特网层中的运输层和数据链路层协议执行了检验操作,IP设计者大概觉得在网络层中具有该项功能实属多余,所以去除了
	- 快速处理IP分组是关注的重点,因为TTL的存在每次都要重新计算校验和在封装,很耗时
- 选项：
	- 不是首部的一部分了,但从未离去,而是可能出现在首部下一个首部指出的位置上
	- 删除了选项后,是IPv6首部成为定长
	- 被Next Header字段标示

IPv6还带来了ICMPv6,附加了报文类型与多播组管理功能,即把IGMP吞掉了.   

##### 3.4.2 从IPv4到IPv6的迁移

IPv6可以处理IPv4,但IPv4并可以处理IPv6,所以要把v4换掉有以下方法：  
- 宣布一个标志日
	- 到点全世界停机升级,这在NCP升级到TCP时用过
	- 现在不可能了,因为设备太多了现在
- 建立隧道(tunneling)
	- 如果两个IPv6路由器要使用IPv6数据报进行交付,但它们是经由中间IPv4路由器互联的,成中间IPv4路由器的集合称为一个**隧道(tunnel)**  
	- 借助隧道,把整个IPv6的数据报放入 一个IPv4数据报的数据字段里,再发送给隧道中的第一个节点,中间的IPv4路由器在它们之间提供路由,就像对待其他数据报一样,完全不知道里面有个IPv6数据报
	- IPv6最终收到该IPv4数据报,并确定含有一个IPv6的数据报(IPv4数据报的首部中的协议号字段是41,指示该数据报是IPv6数据报),从中取出再进行处理
	- 最终慢慢替换掉IPv4
	- 上层协议的更换比底层协议更换快的多

### 4. 泛化转发和SDN  

在2.1节中的转发总结为两个步骤：  
- 查找目的IP地址(匹配)
- 将分组发送到有特定输出端口的交换结构(操作)  

在泛化转发中,匹配加操作表推广了基于目的地的转发表的概念,通过匹配多个首部字段(与不同层次的不同协议相关联),进行不同的操作.   

匹配加操作转发表在OpenFlow中称为**流表(flow table)**,它的每个表项包括：  
- 首部字段值的集合,入分组将与之匹配
	- 与基于目的地转发的情况一样,基于硬件匹配在TCAM内存中执行得最为迅速(TCAM内存中可能有上百万条地址表项)
	- 匹配不上的流表项的分组将被丢弃或发送到远程控制器做更多处理
	- 在实践中,为了性能或成本原因,一个流表可以由多个流表实现
- 计数器集合(当分组与流表项匹配时更新计数器)
	- 这些计数器可以包括已经与该表项匹配的分组数量,以及自从该表项上次更新以来的时间
- 当分组匹配流表项时所采取的操作集合
	- 这些操作可能将分组转发到给定的输出端口,丢弃该分组,复制该分组和将它们发送到多个输出端口,和/或重写所选的首部字段

流表本质上是一个API,通过这种抽象每台分组交换机的行为能被编程.   

#### 4.1 匹配  

<table><tr><td>入端口</td><td>源MAC</td><td>目的MAC</td><td>以太网类型</td><td>VLAN ID</td><td>VLAN优先权</td><td>IP源</td><td>IP目的</td><td>IP协议</td><td>IP TOS</td><td>TCP/UDP源端口</td><td>TCP/UDP目的端口</td></tr></table>

以上的11个首部字段和入端口ID可以于OpenFlow 1.0中的匹配加操作规则所匹配.   

OpenFlow的匹配抽象允许对来自三个层次的协议首部所选择的字段进行匹配(光天化日之下违反端到端原则).   

可以看到OpenFlow使能的设备能够等价于路由器转发数据报以及交换机转发帧.   

以太网类型对应于较高层协议,利用该字段将解复用该帧的载荷.   

最新的版本的OpenFlow不止这些.    

入端口指分组交换机上接收分组的输入端口.     

流表项也可以有通配符,每个流表项也具有相应优先级.   

IP首部中不是所有字段都可以匹配,在OpenFlow中不允许基于TTL字段或数据报长度字段进行匹配.   

>why?
>因为这会变得过于复杂,选择抽象的艺术是提供足够的功能来完成某种任务(在这种情况下是实现,配置和管理宽泛的网络层功能,以前这些一直是通过各种各样的网络层设备来实现),但不应用过多的细节和通用性使抽象变得超负荷,这种抽象会变得臃肿和不可用.    

#### 4.2 操作   

每个流表项都有零个或多个操作列表,这些操作决定了应用于与流表项匹配的分组的处理,如果有多个操作,它们以在表中规定的次序执行.   

其中最为重要的操作可能是：  
- 转发：
	- 一个入分组可以转发到一个特定的物理输出端口,广播到所有端口(分组到达的端口除外),或通过所选的端口集合进行多播
	- 该分组被封装并发送到该设备的远程控制器,该控制器则可能(或可能不)对该分组采取某些操作,包括安转新的流表项,以及可能将该分组返回给该设备以在更新的流表规则集合下进行转发
- 丢弃：
	- 没有操作的流表项表明某个匹配的分组应当被丢弃
- 修改字段：
	- 在分组被转发到所选的输出端口之前,分组首部10个字段(上表除IP协议字段外的所有第二三四层的字段)中的值可以重写

##### 4.3 运行中的匹配加操作的OpenFlow例子  

1. 简单转发
2. 负载均衡
3. 充当防火墙  

>具体看书  

匹配加操作流表表实际上是一种有限形式的可编程性,基于数据报的首部值和匹配条件之间的匹配,指定路由器应该如何转发和操作数据报.    

为了形式更丰富的可编程性,即一种具有更高层次结构的编程语言,如变量,通用算术,布尔运算,函数和条件语句,以及专门为以线速处理数据报而设计的结构,设计了编程协议独立的分组处理器(Programming Protocol-independent Packet Processors,P4).   

### 5 中间盒   

路由器是网络层的主力设备,我们也遇到了网络中的其他设备,它们位于数据路径上,执行转发以外的功能,如Web缓存,TCP连接分岔器,网络地址转换器,防火墙和入侵检测系统等.   

这些都是**中间盒(middlebox)**：  
- 在源主机和目的主机之间的数据路径上,执行除了IP路由器的正常标准功能之外的其他功能的任何中间的盒子.    
- 提供的服务：
	- NAT转换：
		- 实现了专用网络寻址,重写数据报,首部IP地址和端口号
	- 安全服务：
		- 防火墙基于首部字段值或重定向分组来阻塞流量,从而进行附加处理,如深度分组检测(DPI)
		- 入侵检测系统(IDS)能够检测预先确定的模式,并相应地过滤分组
		- 应用程序级电子邮件过滤器可以拦截垃圾邮件,网络钓鱼邮件或其他构成安全威胁的邮件
	- 性能增强：
		- 这些中间盒向能够提供所需服务的服务器集合之一,执行诸如压缩,内容缓存和负载均衡等服务的服务请求
- 在有线和无线蜂窝网络中,许多其他的中间盒可提供三种类型的服务功能

随着中间盒的增多,产生了操作,管理和升级该设备的相关需求,单独的专用硬件盒,单独的软件堆栈和单独的管理/操作技能都意味着巨大的运营成本和投资费用,因此,研究人员正在探索使用商用硬件,并试图在通用软件堆栈之上构建专门的软件来实现这些服务,SDN就是采用这种方法,该方法称为**网络功能虚拟化(NFV)**,另一种已经被探索过的方法是将中间盒功能外包给云.   

即使中间盒违背了端到端原则,但中间盒已经必不可少.   

### 6. 控制平面概述   

互联网控制平面的实现方式特点：  (PS:网课笔记)   
- 互联网网络设备：传统方式都是通过分布式,每台设备的方法来实现数据平面和控制平面功能
	- 垂直集成：每台路由器或其它网络设备,包括：
		- 硬件,在私有的操作系统
		- 互联网标准协议(IP,RIP,IS-IS,OSPF,BGP)的私有实现
		- 从上到下都由一个厂商提供
	- 每个设备都实现了数据平面和控制平面的事情
		- 控制平面的功能是分布式实现的
	- 设备基本上只能按照固定方式工作,控制逻辑固化,不同的网络功能需要的不同
- (数据+控制平面)集成>(控制逻辑)分布->固化
	- 代价大,升级困难,管理困难等

转发表和流表是怎样计算,维护和安装：  
- 每路由器控制
	- 每台路由器中都包含转发和路由选择功能
	- 每台路由器有一个路由选择组件,用于与其他路由器中的路由选择组件通信,以计算其转发表的值
- 逻辑集中式控制
	- 通过逻辑集中式控制器计算并分发转发表以供每台路由器使用
	- 该控制器经一种定义良好的协议与每台路由器中的一个控制代理(CA)进行交互,以配置和管理该路由器的转发表
	- CA一般具有最少的功能,其任务是与控制器通信并且按照控制器命令行事
	- 这些CA既不能直接相互交互,也不能主动参与计算转发表,这是每路由控制和逻辑集中式控制之间的关键差异

### 7. 路由选择算法   

路由的概念：  
- 路由：
	- 按照某种指标(传输延迟,所经过的站点数目等)找到一条从源节点到目标节点的较好路径
		- 较好路径：按某种指标较小的路径
		- 指标：站数,延迟,费用,队列长度等,或者是一些单纯指标的加权平均
		- 采用什么样的指标,表示网络使用者希望网络在什么方面表现突出,什么指标网络使用者比较重视
	- 路由器-路由器之间的最优路径 = 主机对之间的最优路径
		- 路由器连接子网,子网到路由器之间的跳数就一跳,必须要走
		- 路由器到下一跳路由器(节点到节点)之间的最优路径找到了也就找到了从源子网向目标子网所有主机的最有路径
		- 大大降低了路由计算的规模
		- 在路由计算中按照子网到子网的路径计算为目标,而不是主机到主机
- 路由选择算法(routing algorithm)：网络层软件的一部分,完成路由功能

路由选择算法的分类：
- 按集中式还是分散式来划分
	- 集中式路由选择算法(centralized routing algorithm)：
		- 用完整的,全局性的网络知识计算出从源到目的地之间的最低开销路径
		- 以所有节点之间的连通性及所有链路的开销为输入
		- 要求在计算以前,要以某种方式获得这些信息,计算本身可在某个场点进行,或在每台路由器的路由选择组件中重复进行
		- 集中式算法具有关于连通性和链路开销方面的完整信息,具有全局状态信息的算法常被称作**链路状态(Link State,LS)算法**.因为其必须知道网络中每条链路的开销
	- 分散式路由选择算法(decentralized routing algorithm)：
		- 以迭代,分布式的方式计算出最低开销路径,没有节点拥有关于所有网络链路的开销的完整信息
		- 每个节点仅有与其直接相连链路的开销知识即可开始工作
		- 然后,通过迭代计算过程以及与相邻节点的信息交换,一个节点逐渐计算出到达某目的节点或一组目的节点的最低开销路径
		- 有距离向量(Distance Vector,DV)算法
- 根据是静态还是动态来分
	- 静态路由选择算法(static routing algorithm)：
		- 路由随时间的变化非常缓慢,通常是人工进行调整
	- 动态路由选择算法(dynamic routing algorithm)：
		- 随着网络流量或拓扑发生变化而改变路由选择路径
		- 可周期性地运行或直接响应拓扑或链路开销的变化而运行
		- 虽然易于对网络的变化做出反应,但也更容易受诸如路由器选择循环,路由振荡之类的问题的影响
- 根据它是负载迟钝还是负载敏感进行划分
	- 负载敏感算法(load-sensitive algorithm)：
		- 链路开销会动态地变化以反映出底层链路的当前拥塞水平
		- 早期的ARP Anet是这种类型的
	- 负载迟钝(load-insensitive)
		- 某条链路的开销不明确地反映其当前(或最近)的拥塞水平
		- RIP,OSPF和BGP

**最优化原则(optimality principle)**  

- 汇集树(sink tree)
	- 此节点到所有其他节点的最优路径形成的树
	- 路由选择算法就是为所有路由器找到并使用汇集树

**路由的原则**   

- 路由选择算法的原则
	- 正确性(correctness)
		- 算法必须是正确的和完整的
		- 正确发往目标站
		- 目标所有的站地址,在路由表中都能找到相应的表项
	- 简单性(simplicity)
		- 算法在计算机上应简单
		- 最优但复杂的算法,时间延迟很大,不实用,不应为了获取路由信息增加很多的通信量
	- 健壮性(robustness)
		- 算法能适应通信量和网络拓扑的变化
		- 通信量变化,网络拓扑的变化算法能很快适应,不向很拥挤的链路发数据,不向断了的链路发送数据
	- 稳定性(stability)
		- 产生的路由不应该摇摆
	- 公平性(fairness)
		- 对每一个站点都公平
	- 最优性(optimality)
		- 某一个指标的最优,时间上,费用上等指标,或综合指标,实际上,获取最优的结果代价较高,可以是次优的

#### 7.1 链路状态路由选择算法

因为LS算法需要知道网络拓扑与所有的链路开销,所以通过**链路状态广播(link state broadcast)算法**来完成,节点广播的结果是所有节点都具有该网络的统一,完整的视图.      

链路状态广播算法使用泛洪的机制,将分组通过扩散的方法发到所有其他的路由器,这可能会导致广播风暴,为此使用了：
- 顺序号：用于控制无穷的扩散,每个路由器都(源路由器,顺序号),发现重复的或老的就不扩散
	- 具体问题
		1. 循环使用问题
		2. 路由器崩溃之后序号从0开始
		3. 序号出现错误
- 年龄字段：
	- 生成一个分组时,年龄字段不为0
	- 每过一个时间段,AGE字段减1
	- AGE字段为0的分组将被抛弃
- 关于扩散分组的数据结构：
	- Source：从那个节点收到LS分组
	- Seq,Age：序号年龄
	- Send flags：发送标记,必须向指定的那些相邻站点转发LS分组
	- ACK flags：本站点必须向哪些相邻站点发送应答
		- 使用的有确认的泛洪,即必须发送回应,不然发送方认为你没有收到,便会一直发
	- DATA：来自source站点的LS分组

书上使用的链路状态选择算法为Dijkstra算法,其是一个迭代的算法,其性质是经算法的第k次迭代后,可知道到k个目的节点的最低开销路径.   

>Dijkstra一般的复杂度为O(n<sup>2</sup>),可以通过堆优化至O(nlog(N)),具体的算法数据结构中有.另一种图的最短路径算法为Prim算法.    

使用LS算法,会出现振荡,也就是说一会这条路通了,人人都想走,结果把路堵了,另一条路通了,又跑到那一条路去,跟你在超市或食堂排队一样.     

这种振荡不止发生在LS算法中,也可能出现在任何使用拥塞或基于时延的链路测度算法中.    

 一种解决方案可能强制链路开销不依赖与所承载的流量,但那是一种不可接受的解决方案,因为路由选择的目标之一就是要避开高度拥塞(如高时延)的链路.   

另一种解决方案就是确保并非所有的路由器都同时运行LS算法,这似乎很合理,因为我们希望即使路由器以相同周期运行LS算法,在每个节点上算法执行的实际也将是不同的.但有趣的是,研究人员注意到因特网上的路由器能在它们之间进行自同步,即即使以同一周期但不同时刻执行算法,最终会变成同步并保持,为了避免自同步,让每台路由器发送链路通告的时间随机化.

#### 7.2 距离向量路由选择算法

距离向量(Distance-Vectir,DV)算法是一种迭代的,异步的和分布式的算法,说它是分布式的,是因为每个节点都要从一个或多个直接相连邻居接收某些信息,执行计算,然后将其计算结果分发给邻居.说它是迭代的,是因为此过程一直要持续到邻居之间无更多信息要交换为止(此算法是自我终止的,即没有计算因该停止的信号,它就停止了),说它是异步的,是因为它不要求所有节点相互之间步伐一致地操作.      

通过迭代的方式计算最低开销路径需要使用Bellman-Ford方程：
d<sub>x</sub>(y) = min<sub>v</sub>{c(x,v) + d<sub>v</sub>(y)},即x通过所有邻居v到达y的最低开销.    

在该DV算法中,当节点x发现它的直接相连的链路开销变化或从某个邻居接收到一个距离向量的更新时,它就更新其距离向量估计值.    

在实践中,许多类似的DV的算法被用于多种路由选择协议中,包括因特网的RIP和BGP,ISO IDRP,Novell IPX和早期的ARP Anet.   

##### 7.2.1 DV算法：链路开销改变于链路故障   

当一个运行DV算法的节点检测到从它自己到邻居的链路开销发生变化时,它就更新其距离向量,并且如果最低开销路径的开销发生了变化,向邻居通知其新的距离向量.   

当一个链路开销减少时,可以很快的传遍整个网络(确切的说是该AS).   

但当开销增加时,会遇到**路由选择环路(routing loop)**,即当路由A与路由B的链路发生了故障无法通信时,路由B会寻找一个代替的方案到达路由A,这时依赖路由B到达路由A的路由C说"哎！我有路径,走此小道",然后就开始不停的绕圈圈,直到它们之间链路开销很大.这种问题有时被称为无穷计数(count-to-infinity)问题.     

所以DV算法有句话是~~传的越快,传的越慢~~,好消息传的快,坏消息传的慢.    
- 好消息的传播以每一个交换周期前进一个路由器的速度进行

##### 7.2.2 DV算法：增加毒性逆转   

对于**路由选择环路**的解决方法可以通过使用一种被称为**毒性逆转(poisoned reverse)** 的技术而加以避免,有的叫做**水平分裂(split horizon)**.其思路为：  
- 如果z通过y路由选择到达目的地x,则z将通过y,它到x的距离为无穷大
- 只要z经y路由选择到x,z就持续地向y讲述这个善意的小谎言,~~点子王不再出点子了,从良了~~
- 因为y相信z没有到x的路径,故只要z继续经y路由选择到x,将永远不会试图经由z路由选择到x
- 毒性逆转并没有解决一般的无穷计数问题,当涉及3个或更多节点(而不只是两个直接相连的邻居节点)的环路将无法用毒性逆转技术检测到

##### 7.2.3 LS与DV路由选择算法的比较   

DV和LS算法采用互补的方法来解决路由选择计算的问题.   

- 报文复杂度：   
	- LS：
		- 要求每个节点都知道网络中的每条链路开销,这就要求发送O(NE)个报文,N个节点,E条链路
		- 而且无论何时一条链路的开销改变时,必须向所有节点发送新的链路开销
		- 局部的路由信息,全局传播
	- DV：
		- 在直接相连的邻居之间交换报文
		- 仅当在新的链路开销导致与该链路相连的节点的最低开销发生改变时,才传播已改变的链路开销
		- 全局路由信息,局部传播
- 收敛速度：
	- LS：
		- O(N<sup>2</sup>)算法,可能更快
		- 有可能振荡
	- DV：
		- 收敛较慢
		- 存在路由选择环路问题
		- count-to-infinity问题
- 健壮性：如果一台路由器~~发癫~~发生故障,行为错乱或受到蓄意破坏,如向外说,我的链路开销都是0,都是优质链路
	- LS：
		- 节点广播不正确的开销
		- 一个节点也可损坏或丢弃它收到的任何LS广播分组,但一个LS节点只计算自己的转发表
		- 在LS算法下,路由计算在某种程度上是分离的,提供了一定的健壮性
		- 错误信息影响较小,局部,路由较健壮
	- DV：
		- DV节点可向任意或所有目的节点通过其不正确的最低开销路径
		- 每次迭代时,在DV算法中的一个节点计算会传递给它的邻居,然后在下次迭代时再间接传给邻居的邻居,最终扩散到全网

### 8. 因特网中自治系统的路由选择

因为以下原因将路由器组织进**自治系统(Autonomous System,AS)**：
- 规模：
	- 随着路由器数目变得很大,涉及路由选择信息的通信,计算和存储的开销将高得不可实现
	- 当今的因特网由数亿台主机组成,在这些主机中存储的路由选择信息显然需要巨大容量的内存
	- 在所有路由器之间广播联通性和链路开销更新所要求的负担将是巨大的,在如此大量的路由器中迭代的DV算法将肯定永远无法收敛
- 管理自治：
	- 因特网是ISP的网络,其中每个ISP都有它自己的路由器网络
	- ISP通常希望按自己的意愿运行路由器或对外隐藏其网络的内部组织面貌

每个AS由一组通常处在相同管理控制下的路由器组成,通常在一个ISP中的路由器以及互联它们的链路构成一个AS,某些ISP将它们的网络划分为多个AS,特别是某些一级ISP在其整个网络中使用一个庞大的AS,而其他ISP则将它们的ISP拆分为数十个互联的AS,一个自治系统由其全局唯一的AS号(ASN)所标识.就像IP地址那样,AS号由ICANN区域注册机构所分配.     

>从技术上讲,并非每个AS都有一个ASN,特殊是有一种所谓**桩(stub)** AS通常就没有ASN,这种桩AS仅承载源地址或目的地址为本AS的流量.    

在相同AS中的路由器都运行相同的路由选择算法并且有彼此的信息,在一个自治系统内运行的路由选择算法叫做**自治系统内部路由选择协议(intra-autonomous system routing protocol)**.   

#### 8.1 RIP  

RIP是最早的AS内部因特网路由选择协议之一,且目前仍在广泛应用.   

它的产生与命名源于Xerox网络系统(XNS)体系结构,广泛应用主要是由于它被包含在支持TCP/IP的1982年的UNIX伯克利软件分发(BSD)版本中,有版本1和版本2.    

RIP是一种距离向量协议,在RFC 1058中定义的RIP版本使用跳数作为其费用测度,即每条链路的费用为1.   

无论是在RIP还是OSPF中,费用实际上是从源路由器到目的子网.而不是7.2中定义在路由器对之间.          

RIP使用术语**跳**,**跳**是沿着源路由器到目的子网(包括目的子网)的最短路径所经过的子网数量.    

一条路径的最大费用被限制为15,因此RIP的使用限制在网络直径不超过15跳的AS内.超过15达到16,就认为不可达.      

在RIP中,路由选择更新信息在邻居之间通过使用一种**RIP响应报文(RIP response message)** 来交换,大约每30秒相互交换一次.    

由一台路由器或主机发出的响应报文包含了一个该AS内多达25个目的子网的列表,以及发送方到其中每个子网的距离,响应报文又被称作**RIP通告(RIP advertisement)**.   

如果一台路由器一旦超过180秒没有从邻居听到报文,则该邻居不再被认为是可达的,要么其死机了,要么连接的链路中断了.这时RIP修改本地路由选择表,然后通过向相邻的路由器发送通告来传播该信息.   

路由器也可通过使用RIP请求报文,请求其邻居到指定目的地的费用.   

路由器在UDP上使用端口520相互发送RIP请求与响应报文.封装在标准的IP数据报中的UDP报文段在路由器之间传输.    

RIP使用一个位于网络层协议(IP)之上的运输层协议(UDP)来实现网络层功能.   

通过一个称为routed的进程执行RIP,即维护路由选择信息并与相邻的路由器中的routed进程交换报文,因为RIP被当作一个应用层进程来实现(虽然它是一个能操作UNIX内核中的转发表的特殊进程),它能在一个标准的套接字上发送和接收报文,并使用一个标准的运输层协议.即RIP是一个运行在UDP上的应用层协议.     

具体实现(Quagga 2012),也有OSPF,BGP.    

#### 8.2 OSPF

OSPF及其关系密切的IS-IS协议通常都设置在上层ISP中(IS-IS几乎和OSPF一样),而RIP却被设置在下层ISP和企业网中.    

OSPF中的开放(Open)一词是指路由选择协议规范是公众可用的,最新版本是版本2在RFC 2328中定义.     

OSPF的核心是一种链路状态算法.使用OSPF,一台路由器构建了一幅关于整个AS的完整拓扑图,通过Dijkstra算法确定一个以自身为根节点的到所有子网的最短路径树.    

各条链路的开销是由网络管理员配置的,OSPF不强制使用设置链路权值的策略,而是提供了一种机制,为给定链路权值集合确定最低开销路径的路由选择.在实践中,一般是通过一个特定的目标而设置的权重.   

使用OSPF时,路由器向AS内所有其他路由器广播路由选择信息,而不是仅仅是向其相邻路由器广播.每当一条链路的状态发生变化,路由器就会广播链路状态信息,即使没有发生变化,也要周期性地(至少每隔30min一次)广播链路状态信息.    

OSPF通过包含在OSPF报文中,该OSPF报文直接由IP承载,对OSPF其上层协议的值为89.因此OSPF协议必须自己实现诸如可靠报文传输,链路状态广播等功能.   

OSPF协议还要检查链路正在运行(通过向相连的邻居发送HELLO报文),并允许OSPF路由器获得相邻路由器的网络范围链路状态的数据库.    

OSPF的优点(高级特性)：
- 安全：
	- 能够鉴别OSPF路由器之间的交换
	- 使用鉴别,仅有受信任的路由器能参与一个AS内的OSPF协议,因此可以防止恶意入侵者(或一个跃跃欲试的网络专业学生)将不正确的信息注入路由器表内
	- 在默认状态下,OSPF报文是未被鉴别的并能被伪造
	- 能够配置两类鉴别
		- 简单的：
			- 每台路由器配置相同的口令,当一台路由器发送一个OSPF分组,它以明文方式包括了口令
		- MD5的：
			- 基于配置在所有路由器上的共享秘密密钥,对发送的每个OSPF分组,路由器对附加了秘密密钥的OSPF分组内容计算MD5散列值,然后路由器将所得的散列值包括在该OSPF分组中
			- 接收路由器使用预配置的秘密密钥计算出该分组的MD5散列值,并于该分组携带的散列值进行比较,从而验证了该分组的真实性
			- 在MD5鉴别中也使用了序号对重放攻击进行保护
- 多条相同开销的路径：
	- 当达到某目的地的多条路径具有相同的开销时,OSPF允许使用多条路径
- 对单播与多播路由选择的综合支持：
	- 多播OSPF(Multicast OSPF,MOSPF)提供了对OSPF的简单扩展,以便提供多播路由选择
	- MOSPF使用现有的OSPF链路数据库,并为现有的OSPF链路状态广播机制增加了一种新型的链路状态通告
- 支持在单个AS中的层次结构：
	- 一个OSPF自治系统能够层次化地配置多个区域,每个区域都运行自己的OSPF链路状态路由选择算法,区域内的每台路由器都向该区域内的所有其他路由器广播其链路状态
	- 在每个区域中,一台或多台**区域边界路由器(area border router)** 负责为流向该区域以外的分组提供路由选择
	- 在AS内只有一个OSPF区域配置成**主干(backbone,~~逆骨~~)** 区域
		- 主干区域主要作用是为AS内其他区域之间的流量提供路由选择
		- 该主干总是包含本AS中的所有区域边界路由器,并且可能还包含了一些非边界路由器
	- 在AS内的区域的路由选择要求分组首先路由到一个区域边界路由器(区域内路由选择),然后通过主干路由到位于目的区域的区域边界路由器,进而再路由到最终目的地.    
	- 2个级别的层次性：本地,骨干
		- 链路状态通过仅仅在本地区域Area范围内进行
		- 每一个节点拥有本地区域的拓扑信息：
			- 关于其他区域,知道去它的方向,通过区域边界路由器
	- 区域边界路由器：
		- 汇总(聚集)到自己区域内网络的距离,向其他区域边界路由器通告
	- 骨干路由器：
		- 仅在骨干区域内,运行OSPF
	- 边界路由器：
		- 连接其他的AS's

### 9. ISP之间的路由选择

为了连接不同的AS,需要了**自治系统间路由选择协议(inter-autonomous system routing)**,因为AS间路由选择协议涉及多个AS之间的协调,所以AS通信必须运行相同的AS间路由路由选择协议,在因特网中,所有的AS运行相同的AS间路由选择协议,称为**边界网关协议(Broder Gateway Protocol,BGP)**.   

BGP无疑是所有因特网协议中最为重要的(唯一的竞争者可能是IP协议),因为它把数以千计的ISP粘合起来,其是一种分布式和异步的协议.       

BGP是事实上的标准.    

基于距离矢量算法,进行了优化,包括了到达各个目标网络的详细路径,能够避免简单DV算法导致的路由环路问题.    

**BGP报文**    

- 使用TCP协议交换BGP报文
- BGP报文：
	- OPEN：打开TCP连接,认证发送方
	- UPDATE：通告新路径(或者撤销原路径)
	- KEEPALIVE：在没有更新时保持连接,也用于对OPEN请求确认
	- NOTIFICATION：报告以前消息的错误,也用来关闭连接

#### 9.1 BGP的作用   

在BGP中,分组并不是路由到一个特定的目的地址,而是路由到CIDR化的前缀,其中的每个前缀表示一个子网或一个子网的集合.    

当一台路由器得知一个新前缀时,它为该前缀在其转发表中创建一个项.     

一台路由器的转发表将具有形式为(x,I)的表项,其中x是一个前缀,I是该路由器的接口之一的接口号.   

BGP为每台路由器提供了一种完成以下任务的手段：  
1. 从邻居AS获得前缀的可达性信息
	- 特别是,BGP允许每个子网向因特网的其余部分通告它的存在,一个子网高声宣布"我存在,我在这里",而BGP确保在因特网中的所有的AS知道该子网
	- 如果没有BGP的话,每个子网将是隔离的孤岛,即它们孤独地存在,不为因特网其余部分所知和所达
2. 确定到该前缀的"最好的"路由
	- 一台路由器可能知道两条或更多条到特定前缀的不同路由
	- 为了确定最好的路由,该路由器将本地运行一个BGP路由选择过程(使用它经过相邻的路由器获得的前缀可达性信息),该最好的路由将基于策略以及可达性信息来确定

#### 9.2 通告BGP路由信息    

对于每个AS,每台路由器要么是一台**网关路由器(gateway router)**,要么是一台**内部路由器(internal router)**.    

网关路由器：
- 一台位于AS边缘的路由器,直接连接到在其他AS中的一台或多台路由器

内部路由器：
- 仅连接在它自己AS中的主机和路由器

在BGP中,每对路由器通过使用179端口的半永久TCP连接交换路由选择信息.   

对于每条TCP连接,位于该连接端点的两台路由器称为**BGP对等方(BGP peers)**.    

每条直接连接以及所有该连接发送的BGP报文,称为**BGP连接(BGP connection)**.   

跨越两个AS的BGP连接称为**外部BGP(eBGP)** 连接.   

在相同AS中的两台路由器之间的BGP会话称为**内部BGP(iBGP)** 连接.    

#### 9.3 确定最好的路由   

当通过一个子网前缀时,通告包括BGP属性：
- prefix + attributes = route

BGP属性(BGP attribute)：
- AS-PATH
	- 包含了前缀的通告已经通过的那些AS,当一个前缀传送到一个AS时,该AS将它的ASN增加到AS-PATH属性中
	- 路由器使用该AS-PATH来检测和防止循环通告
- NEXT-HOP
	- NEXT-HOP具有敏感而重要的作用
	- NEXT-HOP是AS-PATH起始的路由器接口的IP地址
	- 不属于源子网,但该IP地址的子网直接与源子网相连
	- 比如说AS-PATH为AS1 AS2；x,则NEXT-HOP就是AS1的AS边界路由器的IP地址,通过这个来标识不同的一个路径,以及更好的选择
- etc...
	- 路由偏好指标
	- 如何被插入的属性

**基于策略的路由**   

- 当一个网关路由器接收到一个路由通过,使用**输入策略(import policy)** 来接受或过滤(accept/decline)
	- 过滤原因1：不想经过某个AS,转发某些前缀分组
	- 过滤原因2：已经有了一条往某前缀的偏好路径
- 策略也决定了是否向它别的邻居通过收到的这个路由信息

##### 9.3.1 热土豆路由选择(hot potato routing)    

选择具有最小最低开销的网关转发,即尽可能快地将分组送出其AS,而不担心其AS外部到目的地的余下部分的开销.   

当在转发表中增加AS向外前缀时,AS间路由选择协议(BGP)和AS内部路由选择协议(如OSPF)都要用到.    

##### 9.3.2 路由器选择算法   

在实践中,BGP使用了一种比热土豆路由选择更为复杂但却结合了其特点的算法,对于任何给定的目的地前缀,进入BGP的路由器选择算法的输入是到某前缀的所有路由的集合,该前缀是已被路由器学习和接受的,如果仅有一条这样的路由,BGP则显然选择该路由,如果到相同的前缀有两条或多条路由,则顺序地调用下列消除规则直到余下一条路由：
1. 路由被指派一个**本地偏好(local preference)** 值作为其属性之一(除了AS-PATH和NEXT-HOP以外),一条路由的本地偏好可能由该路由器设置或可能由在相同AS中的另一台路由器学习到.本地偏好属性的值是一种策略决定,完全取决于该AS的网络管理员,具有最高本地偏好值的路由将被选择
2. 从余下的路由中,将选择具有最短AS-PATH的路由,如果该规则是路由选择的唯一规则,则BGP将使用DV算法决定路径,其中距离测度使用的是AS跳的跳数而不是路由器跳的跳数
3. 从余下的路由中,使用热土豆路由选择,即选择具有最靠近NEXT-HOP路由器的路由
4. 如果仍留下多条路由,使用BGP标识符选择路由

>表项是怎样进入转发表的？    
>为是一个前缀进入路由器的转发表,路由器必须首先知晓该前缀,经过BGP路由器通告,该路由器知道了前缀,这种通告可能经一个eBGP连接,也可能经一个iBGP连接      
>知道前缀后,在它能够在其转发表加入该前缀之前,需要决定适当的输出端口——目的地指向该前缀的数据报将转发到该端口    
>如果路由器接收到对该前缀的多个路由通告,该路由器使用BGP路由选择进程,找到对于该前缀"最好的"路由    
>选择的路由包括了NEXT-HOP属性,它是沿着这条最好路径的该路由器AS之外的第一台路由器的IP地址
>使用AS内部路由选择协议来确定通向NEXT-HOP路由器的最短路径    
>最后通过指出沿最短路径的第一段链路,确定端口号以关联其前缀   
>路由器则能够最终将前缀-端口对加入其转发表   
>由路由选择过程计算的转发表则被推入路由器的输入端口线路卡    

#### 9.4 IP任播(any cast)   

除了作为因特网的AS间路由选择协议外,BGP还常被用于实现IP任播服务

IP任播的动机：
- 在许多分散的不同地理位置,替换不同服务器上的相同内容
- 让每个用户从最靠近的服务器访问内容
- etc...

如CDN公司把它的多台服务器配置为相同的IP地址,并且使用标准的BGP从这些服务器中的每台来通告该IP地址,当某台BGP路由器收到了对于该IP地址的多个路由通告,它将这些通告处理为对相同物理位置提供不同的路径,事实上对于不同的物理位置是有不同路径的.配置其路由选择表时,每台路由器将本地化地使用BGP路由选择算法来挑选到该IP地址的"最好"路由.   

实践中,CDN通常选择不使用IP任播,因为BGP路由选择变化能够导致相同TCP连接的不同分组到达Web服务器的不同实例.    

当IP任播被DNS系统广泛用于将DNS请求指向最近的根DNS服务器.     

#### 9.5 路由选择策略   

当某路由器选择到目的地的一条路由时,AS路由选择策略能够胜过所有其他考虑.   

在路由选择算法中,实际上首先根据本地偏好属性选择路由,本地偏好值由本地AS的策略所确定.   

>为什么会有不同的AS间和AS内部路由选择协议?   
- 策略：
	- 在AS之间,策略问题起主导作用,一个给定AS产生的流量不能穿过另一个特定的AS,这可能非常重要,类似地,一个给定AS也许想很好地控制它承载的其他AS之间穿越的流量
	- 在一个AS的内部,一切都是在相同的管理控制名义下进行的,因此策略问题在AS内部选择路由中起着微不足道的作用
- 规模：
	- AS间路由必须考虑规模问题,以便支持全网的数据转发
	- AS内部路由规模不是一个大的问题
		- 如果单个ISP变得太大时,总是能将其分成两个AS
		- AS之间只不过多了一个点而已
		- 或者AS内部路由支持层次性,层次性路由节约了表空间,降低了更新的数据流量
- 性能：
	- AS间路由是面向策略的,因此所用路由质量是次要的
	- AS内部对策略不太关心,更多的关注性能

>BGP是一个很复杂的技术,具体要看文档.   

### 10. SDN控制平面   

SDN体系结构具有4个关键特征：
- 基于流的转发：
	- SDN控制的交换机的分组转发工作,能够基于运输层,网络层或链路层首部中任意数量的首部字段进行
	- SDN控制平面的工作是计算,管理和安装所有网络交换机中的流表项
- 数据平面与控制平面分离：
	- 数据平面由网络交换机组成,在其流表中执行"匹配加操作"的规则
	- 控制平面由服务器以及决定和管理交换机流表的软件组成
- 网络控制功能：
	- 位于数据平面交换机外部
	- 控制平面自身由两个组件组成：一个SDN控制器,以及若干网络控制应用程序
	- 实践中,控制器仅是逻辑上集中的,通常在几台服务器上实现,这些服务器提供协调的,可扩展的性能和高可用性
- 可编程的网络：
	- 通过运行在控制平面中的网络控制应用程序,该网络是可编程的

#### 10.1 SDN控制平面：SDN控制器和SDN网络控制应用程序   

SDN控制平面大体划分为两个部分：
- SDN控制器
- SDN网络控制应用程序

SDN控制器大体组织为3个层次：
- 通信层：
	- SDN控制器和受控网络设备之间的通信
	- 需要一个协议来传送控制器与受控设备之间的信息
	- 控制器和受控设备之间的通信跨越了一个接口,被称为南向接口
- 网络范围状态管理层：
	- 由SDN控制平面所做出的最终控制决定,将要求控制器具有有关网络的主机,链路,交换机和其他SDN控制设备的最新状态信息
- 对于网络控制应用程序层的接口：
	- 控制器通过它的北向接口与网络控制应用程序交互
	- 该API允许网络控制层应用程序在状态管理层之间读/写网络状态和流表
	- 当状态改变事件出现时,应用程序能够注册进行通告

SDN控制器在"逻辑上集中,物理上分布".    


#### 10.2 OpenFlow协议   

OpenFlow协议运行在SDN控制器和SDN控制的交换机或其他实现OpenFlowAPI的设备之间.    

OpenFlow协议运行在TCP之上,使用6653的默认端口号.    

从控制器流向受控交换机的重要报文如下：
- 配置：该报文允许控制器查询并设置交换机的配置参数
- 修改状态：该报文由控制器所使用,以增加/删除或修改交换机流表中的表项,并且设置交换机端口特性
- 读状态：该报文被控制器用于从交换机的流表和端口收集统计数据和计数器值
- 发送分组：该报文被控制器用于在受控交换机从特定的端口发送出一个特定的报文

从受控交换机流向控制器的重要报文如下：
- 流删除：该报文通知控制器已删除一个流表项,例如由于超时,或作为收到"修改状态"报文的结果
- 端口状态：交换机用该报文向控制器通知端口状态变化
- 分组入：如果一个分组到达交换机端口,并且不能与任何流表项匹配,那么这个分组将被发送给控制器进行额外处理.匹配的分组也可能发送给控制器,作为匹配时所采取的一个操作.分组入报文被用于向控制器发送这样的分组.      

>SDN是一种很有前景的技术,具体要看文档.   

### 11. ICMP：因特网控制报文协议    

ICMP最典型的用途是差错报告.   

从体系结构上讲,ICMP位于IP之上,因为ICMP是承载在IP分组中的,ICMP对应的IP上层协议编码为1.    

ICMP报文有一个类型和编码字段,并且包含引起该ICMP报文首次生成的IP数据报的首部和前8个字节.      

<table>
<tr><td align=center>ICMP类型</td><td align=center>编码</td><td align=center>描述</td></tr>
<tr><td align=center>0</td><td align=center>0</td><td align=center>回显回答(对ping的回答)</td></tr>
<tr><td align=center>3</td><td align=center>0</td><td align=center>目的网络不可达</td></tr>
<tr><td align=center>3</td><td align=center>1</td><td align=center>目的主机不可达</td></tr>
<tr><td align=center>3</td><td align=center>2</td><td align=center>目的协议不可达</td></tr>
<tr><td align=center>3</td><td align=center>3</td><td align=center>目的端口不可达</td></tr>
<tr><td align=center>3</td><td align=center>6</td><td align=center>目的网络未知</td></tr>
<tr><td align=center>3</td><td align=center>7</td><td align=center>目的主机未知</td></tr>
<tr><td align=center>4</td><td align=center>0</td><td align=center>源抑制(拥塞控制)</td></tr>
<tr><td align=center>8</td><td align=center>0</td><td align=center>回显请求</td></tr>
<tr><td align=center>9</td><td align=center>0</td><td align=center>路由器通告</td></tr>
<tr><td align=center>10</td><td align=center>0</td><td align=center>路由器发现</td></tr>
<tr><td align=center>11</td><td align=center>0</td><td align=center>TTL过期</td></tr>
<tr><td align=center>12</td><td align=center>0</td><td align=center>IP首部损坏</td></tr>
</table>

常见的ping命令就是发送一个ICMP类型8编码0的报文到指定主机.大多数TCP/IP实现直接在操作系统中支持ping服务.      

源抑制报文,实践中很少使用,其最初的目的是执行拥塞控制,即使得拥塞的路由器向一台主机发送一个ICMP源抑制报文,以强制该主机减少其发送速率.    

Traceroute向目的主机发送一系列普通的IP数据报,这些数据报都携带了一个具有不可达UDP端口号的UDP报文段.第一个数据报的TTL为1,第i个为i.当第i个数据报到达第i个路由器时,由于正好过期,要发送一个ICMP告警报文回去,源主机从而得到往返时延,从ICMP报文中得到第n台路由器的名字与IP地址.如何停止呢,收到目的主机发来的端口不可达的ICMP报文.标准实现中,用相同的TTL发送3个一组的分组,因此对每个TTL提供了3个结果.    

在RFC 4443中为IPv6定义了ICMP的新版本,除了重新组织现有的ICMP类型和编码定义,ICMPv6还增加了新型IPv6功能所需的新类型和编码.这些包括"分组太大"和一个"未被认可的IPv6选项"的差错编码.    

### 12. 广播和多播路由选择    

#### 12.1 广播路由选择(broadcast routing)   

完成广播通信的最直接的方式是由发送节点向每个目的地分别发送分组的副本.    

在给定N个目的结点的情况下,源结点只是产生该分组的N份副本,这对不同目的地的每个副本进行编址,并用单播路由选择向N个目的地传输这N份副本.    

这种用**N次单播(N-way-unicast)** 实现广播的方法简单,无需新的网络层路由选择协议以及分组复制或转发功能,但这种方法有几个缺点：  
- 效率低
	- 如果源结点经过单一链路与该网络其余部分相连的话,该分组的N份独立的副本将都经过该段链路传输
	- 显然更有效的方式是,经第一跳仅发送分组的单个副本,然后让第一跳后面其他端的结点生成并转发任何附加的所需副本,这就是说,让网络节点本身(而不只是源节点)生成分组的冗余副本将更加有效
- etc...

**1. 无控制的洪泛**   

实现广播的最显而易见的技术是**洪泛(flooding)**,该方法要求源结点向它的所有邻居发送分组的副本.   

当某结点接收到一个广播分组时,它复制该分组并向它所有邻居(除了入链路)转发之,显然如果图是相连的,这种方案将最终将广播分组的副本交付给该图中的所有结点.   

如果该图中有环,则每个广播分组的一个或多个分组副本将无休无止地循环,这种**广播风暴(broadcast storm)** 导致无休止的广播分组的复制,将最终导致在该网络中生成大量的广播分组,使得网络变的毫无用处.       

**2. 受控洪泛**   

在**序号控制洪泛(sequence-number-controlled flooding)** 中,源结点将其地址(或其他唯一的标识符)以及**广播序号(broadcast sequence number)** 放入广播分组,再向它的所有邻居发送该分组.    

每个结点维护它已经收到的,复制的和转发的源地址和每个广播分组的序号列表,当结点收到一个广播分组,首先检查该分组是否在列表中,如果在,丢弃,反之,向所有非入链路的邻居转发.   

还有第二种方法被称为**反向路径转发(Reverse Path Forwarding,RPF)**,有时也被称为反向路径广播(RPB),基本思想为,当一台路由器接收到具有给定源地址的广播分组时,仅当该分组到达链路正好是位于它自己的返回其源的最短单播路径上,它才向所有其出路经传输报文,否则,丢弃.因为路由器知道它在这样一条链路上将接收或者已经接收了该分组的一个副本,故这样的一个分组可以被丢弃.    

注意到RPF不使用单播路由选择以实际将分组交付给目的地,它也不要求路由器知道从它自己到源的完整路径,仅需要知道在它到发送方的单播最短路径上的下一个邻居.它仅使用这个邻居的身份以决定是否洪泛下个接收到的广播分组.   

**3. 生成树广播**   

虽然序号控制洪泛和RPF避免了广播风暴,但它们不能完全避免冗余广播分组的传输.   

如果每段链路具有相应的费用且一棵树的费用就是其链路费用之和,则在该图的所有生成树中费用最小的生成树被称为**最小生成树(minimum spanning tree)**.    

因此,提供广播的另一种方法是首先对网络结点构造出一颗生成树,当一个源结点要发送一个广播分组时,它向所有属于该生成树的特定链路发送分组.      

与生成树方法相关的复杂性主要是生成树的生成和维护,已经研制出了若干种分布式生成树算法.这里仅考虑一种简单的算法,采用**基于中心的方法(center-based approach)** 建立一颗生成树时,要定义一个中心节点(称之为**汇合点(rendezvous point)**,或**核(core)**).结点则向中心结点单播加入树报文,加入树报文使用单播路由选择朝着中心结点转发,直到它达到一个已经属于生成树的结点或到达中心.在任一种情况下,加入树报文经过的路径定义了发起加入树报文的边缘结点和中心之间的生成树分支.     

### 12.2 多播    

使用这种服务,多播分组仅被交付给网络结点的一个子集.    

在多播通信中,我们立即面临两个问题：
- 怎样标识多播分组的接收方
- 怎样为发送到这些接收方的分组编址

在单播的情况下,接收方的IP地址承载在每个IP单播数据报中并标识了单个接收方,在广播的情况下,所有节点需要接收广播分组,因此不需要目的地址,但在多个情况下,我们目前面对多个接收方.每个多播分组都携带所有接收方的IP地址,这合理吗?虽然这种方法对于少量的接收方可能行得通的,但它不能很好地扩展到数以百计或数以千计的接收方场合,在数据报中编制信息的量将充斥该分组中有效载荷字段中实际可携带的数据量,还需要由发送方给出接收方的明确标识,使得发送方知道所有接收方的标识与地址.      

在因特网体系结构中,多播数据报使用**间接地址(address indireection)** 来编址,这就是说,用一个标识来表示一组接收方,寻址到该组的分组副本被交付给所有与该组相关联的多播接收方,且该组使用这个单一标识符.    

在因特网中,这种表示一组接收方的单一标识就是一个D类多播地址,于一个D类地址相关联的接收方小组被称为一个**多播组(multicast group)**.       

为了解决种种问题提出了：   

**1. 因特网组管理协议(IGMP)**   

IGMP版本3运行在一台主机与其直接相连的路由器之间.   

IGMP为一台主机提供了手段,让它通知与其直接相连的路由器：在本主机上运行的一个应用程序想加入一个特定的多播组.由于IGMP的交互范围被局限在主机与其相连的路由器之间,显然需要另一种协议来协调遍及因特网内的多播路由器,以便多播数据报能路由到其最终目的地.   

因此因特网中的网络层多播是由两个互补的组件组成的：
- IGMP
- 多播路由选择协议

IGMP只有三种报文类型,与ICMP类似,IGMP报文也是承载在一个IP数据报中,使用的IP协议号为2.    

报文类型：
- membership_query：确定该接口上主机以加入的所有多播组集合
- membership_report：响应membership_query
	- 当一个应用程序首次加入一个多播组时,也可由主机产生membership_report,而不用等待来自路由器的membership_query
- leave_group：它是可选的
	- 如果是可选的,它是怎么离开的?
		- 使用membership_query报文,当无主机响应一个具有给定组地址的membership_query报文时,路由器就推断出已没有主机在这个多播组了
	- 这是因特网协议中有时被称为**软状态(soft state)** 机制的例子

**2.多播路由选择算法**   

多播路由的目标就是发现一颗链路的树,这些链路连接了所有具有属于该多播组的相连主机的路由器.于是多播分组将能够沿着这棵树从发送方路由到所有属于该多播树的主机.当然,也许会包含一些没有属于该多播组的相连主机的路由器.        

在实践中,采用两种方法来确定多播路由选择树：
- 使用一颗组共享树的多播路由选择：
	- 使用基于中心的方法来构造
	- 关键问题在于选择树的中心,在Wall 1980 Thaler 1997 Estrin 1997中有讨论
- 使用一棵基于源的树的多播路由选择：
	- 为多播组的每个源构建一颗多播路由选择树
	- 实践中,使用RPF算法来构造一颗多播转发树,以用于源于源点x的多播数据报
	- 这里的RPF算法在用于多播环境下时的要求不同
	- 采用**剪枝(pruning)** 的方法,一台接收到多播分组的路由器,如无加入该组的相连主机,则向上游路由器发送一个剪枝报文,如果一台路由器从它的每一个下游路由器都收到报文,则它也向上游发送

**3. 在因特网中的多播路由选择**   

第一个用于因特网中的多播路由选择协议是**距离向量多播路由选择协议(Distance Vector Multicast Routing Protocol,DVMRP)**,DVMRP实现了具有反向路径转发与剪枝算法的基于源的树.   

也许使用最为广泛的因特网多播路由选择协议是**协议无关的多播(Protocol Independent Multicaast,PIM)** 路由选择协议,该协议明确辨识两种多播分布情形：  
- 在**稠密模式(dense mode)** 下,多播组成员位置分布稠密,在该区域内的许多或大多数路由器需要参与到多播数据报路由选择过程之中,是一种洪泛与剪枝反向路径转发技术,类似DVMRP
- 在**稀疏模式(spare mode)** 下,具有相连组成员的路由器数量相对于路由器总数来说很少,组成员极为分散,使用聚集点来建立多播分发树,在**源特定多播(Source-Specific Multicast,SSM)** 中,仅允许单一发送方向多播树中发送流量,大大简化了树的构造和维护

在RFC 4271中定义了对BGP的多协议扩展,使得BGP能够为其他协议承载路由选择信息,包括多播信息.    

使用**多播源发现协议(Multicast Source Discovery Protocol,MSDP)** 能够将不同PIM稀疏模式域中的聚集点连接到一起.    

## 链路层和局域网   

在链路层,会有两种截然不同类型的链路层信道：
- 广播信道：
	- 用于连接无线局域网,卫星网和混合光纤同轴电缆(HFC)接入网中的多台主机
	- 需要所谓的介质访问协议来协调帧传输
	- 在某些场合中,可以使用中心控制器来协调传输,在其他场合中,主机自己协同传输
- 点对点信道：
	- 经常出现在长距离链路连接的两台路由器之间,或用户办公室计算机与它们所连接的邻近以太网交换机之间等场合
	- 采用PPP(Point-to-Point protocol)协议,该协议适用范围从经电话线的拨号服务到经光纤链路的高速点到点帧传输

- WAN：网络形式采用点到点链路
	- 带宽大,距离大(延迟大)>时延带宽积大
	- 如果采用多点连接方式：
		- 竞争方式：一旦冲突,代价大
		- 令牌等协调方式：在其中协调节点的发送代价大
	- 点到点链路的链路层服务实现非常简单,封装和解封装
- LAN：一般采用多点连接方式
	- 连接节点非常方便
	- 接到共享型介质上(或网络交换机),就可以连接到所有其他节点
	- 多点连接方式网络的链路层功能实现相当复杂：
		- 多点接入：协调各节点对共享性介质的访问和使用
		- 竞争方式：冲突之后的协调
		- 令牌方式：令牌产生,占有和释放等

### 1. 链路层概述   

在本章,将运行链路层协议的任何设备均称为**节点(node)**.把沿着通信路径连接的相邻节点的通信信道称为**链路(link)**.    

#### 1.1 链路层提供的服务   

以下为链路层能提供的服务的总和,在实践中实现的是以下的子集：
- 成帧：
	- 在每个网络数据报经链路传送之前,几乎所有的链路层协议都要将其用链路层帧封装起来,加上帧头,帧尾
	- 一个帧(framing)由一个数据字段和若干首部字段组成,其中网络层数据报就插在数据字段中,帧的格式由链路层协议规定
- 链路接入：
	- **介质访问控制(Medium Access Control,MAC)** 协议规定了帧在链路上传输的规则
	- 如果采用的是共享性介质,信道接入获得信道访问权
	- 在帧头部使用MAC地址来标示源和目的
		- 不同于IP地址
	- 对于点对点链路,MAC协议比较简单(或者不存在),即无论何时,发送方都能发送帧
	- 当多个节点共享单个广播链路时,即所谓的多路访问问题.这里,MAC协议用于协调多个节点的帧传输
- 可靠交付：
	- 在低差错的链路上(光纤,同轴电缆,许多双绞铜线链路)很少使用
		- 出错率低,没必要在每个帧中做差错控制的工作,协议复杂
			- 发送端对每一帧进行差错控制编码,根据反馈做相应的动作
			- 接收端进行差错控制解码,反馈给发送端(ACK,NAK)
		- 在本层放弃可靠控制的工作,在网络层或传输层做可靠控制的工作,或者根本就不做可靠控制的工作
	- 在高差错链路上需要进行可靠的数据传送
		- 高差错链路：无线链路
		- 其目的是本地纠正一个差错,而不是通过运输层或应用层协议迫使进行端到端的数据重传
		- 出错率高,如果在链路层上不做差错控制工作,漏出去的错误比较高,到了上层如果需要可靠控制的数据传输代价会很大
- 流量控制：
	- 使得相邻的发送和接收方节点的速度匹配
- 差错检验和纠正：
	- 差错由信号衰减和电磁噪声导致
	- 接收方检测出的错误
		- 通知发送方进行重传或丢弃帧
	- 链路层的差错检测通常更复杂,并且用硬件实现
	- 差错纠正：
		- 接收方不仅能检测帧中出现的比特差错,而且能够准确地确定帧中的差错出现的位置并因此纠正这些差错
- 半双工和全双工：
	- 半双工：
		- 链路可以双向传输,但一次只有一个方向
	- 全双工：
		- 可以同时接收和发送

#### 1.2 链路层在何处实现

- 在每一个主机上
	- 也在每个路由器上
	- 交换机的每个端口上
- 链路层是在称为**网络适配器(有时也叫网络接口卡(network interface card,NIF))**或在一个芯片组上实现的
	- 以太网卡,802.11网卡,以太网芯片组
	- 实现了链路层和相应的物理层功能
	- 大部分功能是在硬件上实现的,但部分链路层是在运行于主机CPU上的软件中实现的(驱动),软件组件实现了高层链路层功能,如组转链路层寻址信息和激活控制器硬件,在接收端,响应控制器中断,处理差错条件和将数据报向上传递给网络层.所以链路层是软件与硬件交接的地方
- 接到主机的系统总线上
- 硬件,软件和固件的综合体

### 2. 差错检验和纠正技术   

差错检验和纠正技术使接收方有时但并不总是检测出已经出现的比特差错,即使采用差错检测比特,也还是可能有**未检出比特差错(undetected bit error)**.   

一般而言,差错检测和纠错技术越复杂,导致的开销就越大,意味着需要更多的计算量及更多的差错检测和纠错比特.    

#### 2.1 奇偶校验    

采用单个**奇偶校验位(parity bit)**,即假设传送d比特的数据,发送方只需包含一个附加比特,对奇校验而言,使d+1的比特中1的总数为奇数,偶校验而言,为偶数,单个校验比特被存放在一个单独的字段中.    

可以检测出奇数个比特差错,但不能检测出偶数个比特差错.    

奇偶校验为了更加健壮,还有个二维一般化方案,这里将数据的d个比特划分为i行j列,对每行每列计算奇偶值,产生的i+j+1奇偶比特构成了链路层帧的差错检测比特.    

使用这种**二维奇偶教研(two-dimensional parity)** 方案,包含比特值改变的列和行的校验值都将会出现差错,因此接收方不仅可以检测到出现了单个比特差错的事实,而且还可以利用存在奇偶校验差错的列和行的索引来实际识别发生差错的比特并纠正它.校验比特本身的单个错误也是可检测和可纠正的.       

二维奇偶校验也能够检测(但不能纠正)一个分组中两个比特差错的任何组合.    

接收方检测和纠正差错的能力被称为**前向纠错(Forward Error Correction,FEC)**.这些技术通常用于如音频CD这样的音频存储和回放设备中.   

在网络环境中,FEC技术可以单独应用,或与链路层ARQ技术一起应用.   

#### 2.2 检验和方法   

在检验和技术中,d比特数据被作为一个k比特整数的序列处理,一个简单检验和方法就是将这k比特整数加起来,并且用得到的和作为差错检测比特,**因特网检验和(Internet checksum)** 就是基于这种方法,即数据的字节作为16比特的整数对待并求和,这个和的反码形成了携带在报文段首部的因特网检验和.   

检验和方法需要相对小的分组开销.   

#### 2.3 循环冗余检测     

现如今的计算机网络中广泛应用的差错检测技术基于**循环冗余检测(Cyclic Redundancy Check,CRC)** 编码,其也称为**多项式编码(polynomial code)**,因为该编码能够将要发送的比特看作为系数是0和1一个多项式,对比特串的操作被解释为多项式算术.如X<sup>3</sup>+1 = 1001     

CRC编码操作如下：
- 考虑d比特的数据D,发送节点要将它发送给接收节点,发送方和接收方首先必须协商一个r+1比特模式,称为**生成多项式(generator)**,将其表示为G,要求其最高有效比特位是1
- 对于给定的数据段D,发送方要选择r个附加比特R,并将它们附加到D上,使得得到的d+r比特模式用**模2算术(跟XOR操作一样)** 恰好能被G整除
- 如果出现了余数,即出现了差错

在模2算术中,加法和减法是相同的,等价于XOR操作.   

因为在二进制算术中,乘以2<sup>k</sup>就是以一种比特模式左移k个位置,因此,通过D \* 2<sup>r</sup> XOR R 产生d+r比特模式.    

D \* 2<sup>r</sup> XOR R = nG

对两边都用R异或

D \* 2<sup>r</sup> = nG XOR R

可知,R = remainder(余数) (D \* 2<sup>r</sup> )/ G

CRC性能分析   
- 每个CRC标准都能检测小于r+1比特的突发差错
- 出现长度等于r+1的突发错误,检查到的概率为1-0.5<sup>r-1</sup>
- 出现大于r+1比特的突发差错以概率1-0.5<sup>r</sup>被检测到
- 也都能检测任何奇数个比特的错误

这里更多的讨论可以看计算机网络 特南鲍姆写的.    

### 3. 多路访问链路和协议   

在实践中,数以百计或者数以千计个节点能够通过一个广播信道直接通信,因为所有的节点都能够传输帧,所以多个节点可能会同时传输帧,当发生这种情况时,所有节点同时接到多个帧,也就是说,传输的帧在所有接收方处**碰撞(collide)**.    

发生碰撞时,没有一个接收节点能够有效地获得任何传输的帧,在某种意义下,碰撞帧的信号纠缠在一起,因此,涉及此次碰撞的所有帧都丢失了,在碰撞时间间隔中的广播信道被浪费了.     

为此需要**多路访问协议(multiple access protocol)**,将其分为以下3种类型：
- 信道划分协议(channel partitioning protocol)
- 随机接入协议(random access protocol)
- 轮流协议(taking-turns protocol)

在理想情况下,对于速率为Rbps的广播信道,多路访问协议应该具有以下所希望的特性：
- 当仅有一个节点发送数据时,该节点具有Rbps的吞吐量
- 当有M个节点发送数据时,每个节点吞吐量为R/Mbps,不必要求M个节点中的每一个节点总是有R/M的瞬间速率,而是每个节点在一些适当定义的时间间隔内应该有R/M的平均传输速率
- 协议是去中心化的,这就是说不会因某主节点故障而使整个系统崩溃
- 协议是简单的,使实现不昂贵

#### 3.1 信道划分协议    

时分多路复用和频分多路复用是两种能够用于在所有共享节点之间划分广播信道带宽的技术.    

TDM将时间划分为**时间帧(time frame)**,并进一步划分每个时间帧为N个**时隙(slot)**.然后把每个时隙分配给N个节点中的一个,无论何时某个节点在有分组要发送的时候,它在循环的TDM帧中指派给它的时隙内传输分组比特.通常,选择的时隙长度应使一个时隙内能够传输单个分组.    

TDM是有吸引力的,它消除了碰撞而且非常公平,然而它有两个主要缺陷：
- 节点被限制于R/Nbps的平均速率,即使当它是唯一有分组要发送的节点时
- 节点必须总是等待它在传输序列中的轮次

FDM将Rbps信道划分为不同的频段,并把每个频率分配给N个节点中的一个,因此FDM在单个较大的Rbps信道中创建了N个较小的R/Nbps信道.FDM也有TDM同样的优点和缺点.    

**码分多址(Code Division Multiple Access,CDMA)**    

TDM和FDM分别为节点分配时隙和频率,而CDMA对每个节点分配一种不同的编码.然后每个节点用它唯一的编码来对它发送的数据进行编码,如果精心选择这些编码,CDMA网络具有一种奇妙的特性,即不同的节点能够同时传输,并且它们各自相应的接收方仍能正确接收发送方编码的数据比特,而不在乎其他节点的干扰传输.    

具体看[无线网络和移动网络](#2.无线链路和网络特征)那里.

#### 3.2 随机接入协议    

在随机接入协议中,一个传输节点总是以信道的全部速率进行发送,当有碰撞时,涉及碰撞的每个节点反复地重发它的帧,到该帧无碰撞地通过为止.   

但是当一个节点经历一次碰撞时,它不必立刻重发该帧,相反,它在重发该帧之前等待一个随机时延,涉及碰撞的每个节点独立地选择随机时延.    

##### 3.2.1 时隙ALOHA   

在对时隙ALOHA的描述中,做以下假设：
- 所有帧由L比特组成
- 时间被划分成长度为L/R秒的时隙
- 节点只在时隙起点开始传输帧
- 节点是同步的,每个节点都知道时隙何时开始
- 如果在一个时隙中有两个或者更多个帧碰撞,则所有节点在该时隙结束之前检测到该碰撞

在每个节点中,时隙ALOHA的操作是简单的：
- 当节点有一个新帧要发送时,它等到下一个时隙开始并传输整个帧
- 如果没有碰撞,该节点成功地传输它的帧,从而不需要重新考虑重传该帧
- 如果有碰撞,该节点在时隙结束之前检测到这次碰撞,以概率p在后续的每个时隙中重传它的帧,直到该帧被无碰撞地传输出去

当只有一个活跃节点时,工作很出色,但多个活跃节点时,效率为37%,具体见书(自顶向下 8 ed.).    

##### 3.2.2 ALOHA    

第一个ALOHA协议.    

是一个非时隙,完全分散的协议.   

在纯ALOHA中,当一帧首次到达,节点立刻将该帧完整地传输进广播信道,如果经历碰撞,立即(在完全传输完它的碰撞帧之后)以概率p重传该帧,否则,等待一个帧传输时间.以此重复.    

最大效率为17.5%.   

> 无论是时隙还是纯ALOHA,都发送时必须传输完整个帧,无论是否碰撞,因为其不包含实时碰撞检测,无法中途感知.碰撞发现依赖于ACK.   

##### 3.2.3 载波侦听多路访问(CSMA)   

**载波侦听(carrier sensing)**：即一个节点在传输前先听信道.如果来自另一个节点的帧正向信道上发送,节点则等待直到检测到一小段时间没有传输,然后开始传输.    

**碰撞检测(collision detection)**：即当一个传输节点在传输时一直在侦听此信道.如果检测到另一个节点正在传输干扰帧,它就立即停止传输,在重复"侦听-当空闲开始时传输"循环之前等待一段随机时间.    

这两个规则包含在**载波侦听多路访问(Carrier Sense Multiple Access,CSMA)** 和**具有碰撞检测的CSMA(CSMA with Collision Detection,CSMA/CD)** 协议簇中.    

>为什么所有节点都进行了载波侦听,仍旧发生了碰撞?    
>因为数据传输存在端到端的时延,该时延越大,载波侦听节点不能侦听到网络中另一个节点已经开始传输的概率就越大.    

##### 3.2.4 具有碰撞检测的载波侦听多路访问(CSMA/CD)    

在多路访问协议中加入碰撞检测,通过不传输一个无用的,损坏的帧,将有助于改善协议的性能.    

>因为发生了碰撞还接着传输白白浪费资源.    

众所周知,CSMA/CD终止传输后要等待一个随机时间量后再发送,其采用用于以太网以及DOCSIS电缆网络多路访问协议中的**二进制指数后退(binary exponential backoff)** 算法.   

当一个帧的传输经历了一连串的n次碰撞,节点随机地从{0,1,2,...,2<sup>n</sup>-1}中选择一个K值.因此一个帧经历的碰撞越多,K选择的间隔越大.对于以太网,一个节点等待的实际时间量是K\*512比特时间.       

CSMA/CD算法,不考虑近期过去的时间内可能已经发生的任何碰撞.因此,当几个其他适配器处于指数后退状态时,有可能一个具有新帧的节点能够立刻插入一次成功的传输.     

其效率见书(自顶向下 8 ed. P309),或(Lam 1980 | Bertsekas 1991).    

#### 3.3 轮流协议    

前面的多路访问协议的两个理想特性是：
- 当只有一个节点活跃时,该活跃节点具有Rbps的吞吐量
- 当有M个节点活跃时,每个活跃节点的吞吐量接近R/M bps

ALOHA和CSMA协议只具有前者.为此创造出了另一类协议,也就是**轮流协议(taking-turns protocol)**.     

##### 3.3.1 轮询协议(polling protocol)   

要求使用协议的这些节点之一要被指定为主节点,主节点以循环的方式**轮询(poll)** 每个节点.    

特别是,主节点首先向节点1发送一个报文,告述它能够传输的帧的最多数量,在节点1传输了某些帧后,主节点告诉节点2它能够传输的帧的最多数量.(主节点能够通过观察在信道上是否缺乏信号,来决定一个节点何时完成了帧的发送),就这样loop下去.    

**优点**：
- 消除了困扰随机接入协议的碰撞和空时隙

**缺点**：
- 引入了轮询时延,轮询本身消耗信道带宽
- 等待时间：每个节点需等待主节点轮询后开始传输,即使只有一个节点,也需要等待轮询一周后才能够发送
- 单点故障：主节点发生故障时.整个信道无法工作

##### 3.3.2 令牌传递协议(token-passing protocol)    

没有主节点,采用一个称为**令牌(token)** 的小的特殊帧在节点之间以某种固定的次序进行交换.   

令牌有个相应的标志位,1的话是令牌,0的话是数据.      

令牌绕了一周后,由发送方吸收.因为可能由多个接收方,因此不能由接收方吸收,接收方也会在相应的标志位进行置位,代表收到了.     

低负载效率高不过随机接入,高负载效率高不过信道划分.   

**缺点**：
- 令牌开销：本身消耗带宽
- 延迟：只有等待抓住token,才可以传输
- 单点故障：
	- 令牌丢失系统级故障,整个系统无法传输
	- 复杂机制重新生成令牌

>轮流协议的实现比较复杂,因此没有大规模应用.    


### 4. 交换局域网    

#### 4.1 链路层寻址和ARP    

##### 4.1.1 MAC地址   

链路层地址有各种不同的称呼：
- LAN地址(LAN address)
- 物理地址(physical address)
- MAC地址(MAC address)

MAC地址的称呼最为流行.    

对于大多数局域网(包括以太网和802.11WLAN)而言,MAC地址长度为6字节,共有2<sup>48</sup>个可能的MAC地址.这些地址通常采用十六进制表示法,地址的每个字节被表示为一对十六进制数.     

>尽管MAC地址被设计为永久的,但用软件改变一块适配器的MAC地址现在是可能的.    

通过IEEE的分配,来保证世界上没有两块相同地址的网卡,也可以不交钱,不过要把象征全球的标志位改成本地的.     

MAC地址具有扁平结构,而且不论适配器到哪里都不会变化.    

IP地址具有层次结构(即一个网络部分和一个主机部分),当发生移动时,主机的IP地址需要改变.   

> [!question] 为什么主机和路由器接口除了网络层地址之外还有MAC地址？

IP地址和MAC地址的作用不同：
- IP地址是分层的
	- 一个子网所有站点网络号一致,路由聚集,减少路由表
		- 需要一个网络中的站点地址网络号一致,如果捆绑需要定制网卡非常麻烦
	- 希望网络层地址配置的,IP地址完成网络到网络的交付
- MAC地址是一个平面的
	- 网卡在生产时不知道被用于哪个网络,因此给网卡一个唯一的标示,用于区分一个网络内部不同的网卡即可
	- 可以完成一个物理网络内部的节点到节点的数据交付

分离好处：
- 网卡坏了,IP不变,可以捆绑到另外一张网卡的MAC上
- 物理网络还可以除IP之外支持其他网络层协议,链路协议为任意上层网络协议,如IPX等

捆绑问题：
- 如果仅仅使用IP地址,不用MAC地址,那么它仅支持IP协议
- 每次上电都要重新写入网卡IP地址
- 另外一个选择就是不使用任何地址,不用MAC地址,则每到来一个帧都要上传到IP层次,由它判断是不是需要接受,干扰一次

> [!question] end

当发送一个帧时,发送适配器将目的适配器的MAC地址插入到该帧中,并将该帧发送到局域网上.    

如果要进行广播,将帧的目的地址字段中插入一个特殊的**MAC广播地址(MAC broadcast address)**,对于使用6字节地址的局域网来说,广播地址是48个连续的1组成的字符串(FF-FF-FF-FF-FF-FF).    


##### 4.1.2 地址解析协议    

因为存在网络层地址和链路层地址,所以需要在它们之间进行转换,对于因特网而言,这是**地址解析协议(Address Resolution Protocol,ARP)**.    

它在很多方面和DNS类似,但不同的是,DNS为在因特网的**任何地方**的主机解析为IP地址,而ARP只为在同一个子网上的主机和路由器接口解析IP地址.    

每台主机或路由器在其内存中具有一个**ARP表(ARP table)**.这张表包含IP地址到MAC地址的映射关系.还有个TTL值,其指示了从表中删除每个映射的时间,通常有效时间为20min.     

工作过程：
1. 通过查找ARP表找到对应表项,发送帧
2. 找不到,构造一个称为**ARP分组(ARP packet)** 的特殊分组,一个ARP分组有几个字段,包括发送和接收IP地址及MAC地址.ARP查询分组和响应分组都具有相同格式
3. 查询分组的目的是询问子网上所有其他主机和路由器,以确定对应于要解析的IP地址的那个MAC地址,即用MAC广播地址发送查询报文
4. 匹配的主机或路由器发送回一个带有所希望映射的响应ARP分组
5. 查询主机能够更新它的ARP表,并发送它的IP报文

ARP是即插即用的.并且如果某主机与子网断开连接,它的表项最终会从留在子网中的节点表中删除.    

ARP分组封装在链路层帧中,因而在体系结构上位于链路层之上,然而,一个ARP分组具有包含链路层地址的字段,因而可认为是链路层协议,但它也包含网络层地址,因而也可认为是网络层协议,所以最好把ARP协议看成是跨越链路层和网络层边界两边的协议.     

#### 4.2 以太网    

以太网几乎占领着现有的有限局域网市场,在20世纪80到90年代早期,其面临着诸多挑战,但最终结果是以太网保持了其支配地位.     

Bob Metcalf和David Boggs在20世纪70年代中期发明初始的以太局域网,初始的以太局域网使用**同轴电缆**来互联节点,以太网的总线拓扑实际上从20世纪80年代到90年代中期一直保持不变.    

使用总线拓扑的以太网是一种广播局域网,即所有传输的帧传送到与该总线连接的所有适配器并被处理.    

到了20世纪90年代后期,大多数公司和大学使用了一种基于**集线器**的星形拓扑以太网安装代替了它们的局域网.因为使用同轴电缆容易出现故障.    

在这种安转中,主机或路由器直接用双绞对铜线与一台集线器相连.     

**集线器(hub)** 是一种物理层设备,作用于各比特而不是作用于帧,当表示一个0或一个1的比特到达一个接口时,集线器只是重新生成这个比特,将其能量强度放大,并将该比特向其他所有接口传输出去.因此,采用基于集线器的星形拓扑的以太网也是一个广播局域网.特别是,如果某集线器同时从两个不同的接口接收到帧,将出现一次碰撞,生成该帧的节点必须重新传输.    

Hubs本质上是物理层的中继器：
- 从一个端口收,转发到所有其他端口
- 速率一致
- 没有帧的缓存
- 在hub端口上没有CSMA/CD机制：适配器检测冲突
- 提供网络管理功能
- 网段(LAN segmets)：可以允许一个站点发送的网络范围
	- 在一个碰撞域,同时只允许一个站点在发送
	- 如果有两个节点同时发送,则会碰撞
	- 通常拥有相同的前缀,比IP子网更详细的前缀
- 所有以hub连到一起的站点处在同一个网段,处在一个碰撞域
	- 骨干hub将所有网段连到一起
- 通过hub可扩展节点之间的最大距离
- 通过hub,不能将10BaseT和100BaseT的网络连接到一起


>称为物理上是星形,逻辑上是总线形.   

之后被**交换机(switch)** 所替代.   

##### 4.2.1 以太网帧结构   

<table><tr><td align=center>前同步码</td><td align=center>目的地址</td><td align =center>源地址</td><td align=center>类型</td><td align=center>数据</td><td align=center>CRC</td></tr></table>

其六个字段：
- 前同步码：
	- 8字节,前7字节的值都是10101010,最后一个字节是10101011.其前7字节用于唤醒接收适配器,并且将它们的时钟和发送方的时钟同步,第8个字节的最后两个比特警告接收方,重要的内容要来了
	- 为什么要同步?
		- 因为发送速率的不同,发送方也不会以精确的额定速率发送,会产生一定的漂移
- 目的地址：
	- 6字节
	- 包含目的适配器的MAC地址
	- 但匹配到是自己的MAC地址时或者是一个广播MAC地址时接收,当然,如果网卡开了混杂模式,通通接收
	- 其他丢弃
- 源地址：
	- 6字节
	- 包含了传输该帧到局域网上的适配器的MAC地址
- 类型：
	- 2字节
	- 允许以太网复用多种网络层协议
	- IP和其他网络层协议(Novell IPX或AppleTalk)都有自己的标准化的类型编号,ARP也有,为0806
- 数据：
	- 46~1500字节
	- 承载了IP数据报
	- 以太网的MTU是1500字节,如果IP数据报超过了1500字节,则主机必须将该数据报分片
	- 最小为46字节,如果小于46字节,数据报必须被填充到46字节,当采用填充时,传递的数据包括IP数据报和填充部分,网络层使用IP数据报首部中的长度字段来去除填充部分
- CRC：
	- 4字节
	- 检测帧中是否引入了差错

所有的以太网技术都向网络层提供**无连接的服务**.帧传输前,发送方和接收方之间没有握手.    

以太网技术都向网络层提供**不可靠的服务**.接收方适配器不发送ACK或NAKs给发送方.   
- 递交给网络层的数据报流可能有gap(间隙)
- 如上层使用像传输层TCP协议这样的rdt,gap会被补上
- 否则,应用层就会看到gap

以太网的MAC协议：采用二进制退避的CSMA/CD介质访问控制形式.    

##### 4.2.2 以太网技术    

以太网具有许多不同的特色,还有一些令人困惑的首字母缩写词：
- 10BASE-T
- 10BASE-2
- 100BASE-T
- 1000BASE-LX
- 10GBASE-T
- 40GBASE-T

这些以及许多其他的以太网技术在多年中已经被IEEE 802.3 Ethernet工作组中标准化了.其首字母缩写词的第一部分指该标准的速率,BASE指基带以太网,这意味这该物理媒介仅承载以太网流量.最后是使用的物理媒介,T是双绞线.     

早期的10BASE-2/5标准规定了在两种类型的同轴电缆之上的10Mbps以太网,每种标准都限制在500米长度之内,通过**转发器(repeater)** 能够得到更长的运行距离.     

转发器是一种物理层设备,能在输入端接收信号,并在输出端再生该信号.     

**Manchester编码**   

- 在10BaseT中使用
- 每一个bit的位时中间有一个信号跳变
- 允许在接收方和发送方节点之间进行时钟同步
	- 节点间不需要集中的和全局的时钟
- 10Mbps,使用20M带宽,效率50%
- 这是物理层的内容

局域网的演化和发展看书吧(自顶向下 8 ed. P321).   

对于现在使用交换机的星形拓扑,其实不需要MAC协议了(Media Access Control protocol).但以太网帧格式还是在用.    

>这里MAC协议指的是多点接入访问的协议,因为交换机隔离了碰撞域,基本不会发生碰撞了,所以不需要使用了.    

#### 4.3 链路层交换机    

交换机：   
- 链路层设备：扮演主动角色(端口执行以太网协议)
	- 对帧进行转发和存储
	- 对于到来的帧,检查帧头,根据目标MAC地址进行选择性转发
	- 当帧需要向某个网段进行转发,需要使用CSMA/CD进行接入控制
	- 通常一个交换机端口一个独立网段
- 透明(transparent)：主机对交换机的存在可以不关心
	- 通过交换机相连的各节点好像这些站点是直接相连的一样
	- 有MAC地址,无IP地址
- 即插即用,自学习
	- 交换机无须配置

##### 4.3.1 转发和过滤   

**过滤(filtering)** 是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能.    

**转发(forwarding)** 是决定一个帧因该被导向哪个接口,并把该帧移动到那些接口的交换机功能.     

转发和过滤都借助于**交换机表(switch table)** 完成.   

表中的一个表项包含：
- 一个MAC地址
- 通向MAC地址的交换机接口
- 表项放置在表中的时间

如果一个frame到达的接口与其目的地址在表中匹配的接口一致,执行过滤功能将其丢弃.否则转发.表中没有就广播.   

##### 4.3.2 自学习   

交换机是**自学习(self-learning)** 的.其工作流程：
1. 交换表初始为空
2. 对于每个接收到的入frame,在表中存储：
	1. 该帧源地址MAC
	2. 该帧到达的接口
	3. 当前时间
3. 如果在一段时间(称为老化期(aging time))后,没有收到以该地址作为源地址的帧,就在表中删除这个地址

交换机是**即插即用设别(plug-and-play device)**,因为其不需要人工配置.     

交换机也是双工的,任何交换机接口能同时收发.    

##### 4.3.3 链路层交换机的性质    

- 消除碰撞：
	- 在使用交换机构建的局域网中,没有因碰撞而浪费的带宽,交换机缓存帧并且绝不会在网段上同时传输多于一个帧
	- 交换机的最大聚合带宽是该交换机所有接口速率之和
- 异质的链路：
	- 将链路彼此隔离,因此局域网中的不同链路能够以不同的速率运行并且能够在不同的媒介上运行
- 管理：
	- 如果一个适配器工作异常并持续发出以太网帧,交换机能够检测到该问题,并在内部断开异常适配器,不用像使用同轴电缆那样慢慢找
	- 收集带宽使用的统计数据,碰撞率和流量类型
	- etc...

>交换机毒化    
>把交换机表用伪造的表项填满,迫使正常用户进行广播从而被监听者监听.    

##### 4.3.4 交换机和路由器对比    

交换机：
- 优点：
	- 即插即用
	- 具有相对高的分组过滤和转发速率
	- 必须处理高至第二层的帧
- 缺点：
	- 为了防止广播风暴,交换机的活跃拓扑限制为一颗生成树
	- 对广播风暴不提供任何保护措施
	- 一个大型交换网络将要求在主机和路由器中有大的ARP表,这将产生可观的ARP流量和处理量

路由器：
- 优点：
	- 即使存在冗余路径,通常也不会通过路由器循环,路由表如果被误配置时,可能循环,所以分组不会被限制到一一颗生成树上,并可以使用源和目的地之间的最佳路径
	- 允许以丰富的拓扑结构构建以太网
- 缺点：
	- 非即插即用
	- 每个分组的处理时间通常比交换机更长
	- 必须处理高达第三层的字段

通常,对于小网络,交换机就足够了,但是由几千台主机组成的大网络里,通常都使用,路由器提供了更健壮的流量隔离方式和对广播风暴的控制,并在网络的主机之间使用更"智能"的路由.    

#### 4.4 虚拟局域网   

通过**虚拟局域网(Virtual Local Network,VLAN)** 的交换机来处理：
- 缺乏流量隔离
- 交换机的无效使用
- 管理用户

支持VLAN的交换机允许经一个单一的物理局域网基础设施定义多个虚拟局域网.在一个VLAN内的主机彼此通信,仿佛并没有其他主机与交换机连接.     

在一个基于端口的VLAN中,交换机端口由网络管理员划分为组,每个组构成一个VLAN,在每个VLAN中的端口形成一个广播域.    

如果一个VLAN要与另一个VLAN通信,解决的方法：
- 将VLAN交换机的一个端口与一台外部的路由器相连,并且将该端口配置为属于两个VLAN

如果两个分离的交换机要将同名的VLAN合并：
- 使用**VLAN干线连接(VLAN trunking)**
	- 在每台交换机上的一个特殊端口被配置为干线端口,以互联这两台VLAN交换机,干线端口属于所有的VLAN,发送到任何VLAN的帧经过干线转发到其他交换机
	- 通过扩展的以太网帧格式——802.1Q,用于跨越VLAN干线的帧,就可以区分不同的VLAN
	- 802.1Q帧由标准以太网帧与加进首部的4字节**VLAN标签(VLAN tag)** 组成,而VLAN标签承载着该帧所属的VLAN标识符
	- VLAN tag由发送侧的交换机加进帧中,解析后由接收侧删除
	- VLAN tag自身由一个2字节的**标签协议标识符(Tag Protocol Identifier,TPID)** 字段,一个2字节的标签控制信息字段(包含一个12比特的VLAN标识符字段和一个3比特优先权字段(具有类似于IP数据报TOS字段的目的)组成)

VLAN不止能基于端口,也能基于MAC,网络层协议和其他准则.也能跨越IP路由器扩展.       

### 5. 链路虚拟化：网络作为链路层   

**多协议标签交换(Multiprotocol Label Switching,MPLS)**,知道它是基于标签来转发的就行了,很复杂QAQ.    

### 6. 数据中心网络   

看书吧

## 无线网络和移动网络

### 1. 概述     

无线网络中的要素：
- 无线主机(wireless host)：
	- 运行应用程序的端系统设备
- 无线链路：
	- 主机通过**无线通信链路(wireless communication link)** 连接到一个基站或另一台无线主机
	- 两种主要特性：
		- 链路速率
		- 覆盖区域
- 基站(base station)：
	- 负责向与之关联的无线主机发送数据并从主机那里接收数据
	- 负责协调与之相关联的多个无线主机的传输
	- 当一台无线主机与某基站相关联时,指：
		- 该主机位于该基站的无线通信覆盖范围内
		- 该主机使用该基站中继主机和更大网络之间的数据
	- 与基站关联的主机通常被称为以**基础设施模式(infrastructure mode)** 运行,所有传统的网络服务都由网络向通过基站相连的主机提供
	- 在**自组织网络(ad hoc network)** 中,无线主机没有这样的基础设施与之相连,为此,主机本身必须提供诸如路由选择,地址分配以及类似于DNS的名字转换等服务
	- 当一台移动主机超出一个基站的覆盖范围而到达另一个基站的覆盖范围后,它将接入更大网络的连接点,这一过程称作**切换(handoff 或者 handover)**
- 网络基础设施：
	- 这是无线主机希望与之进行通信的更大网络

在最高层次,能够根据两个准则来对无线网络进行分类：
1. 在该无线网络中的分组是否跨越了一个无线跳或多个无线跳
2. 网络中是否有诸如基站这样的基础设施

- 单跳,基于基础设施：
	- 这些网络具有与较大的有线网络连接的基站
		- 该基站与无线主机之间的所有通信都经过一个无线跳
- 单跳,无基础设施：
	- 在这些网络中,不存在与无线网络相连的基站
		- 在这种单跳网络中的节点之一可以协调其他节点的传输
- 多跳,基于基础设施：
	- 一个基站表现为以有线方式与较大网络相连
		- 某些无线节点为了经该基站通信,可能不得不通过其他无线节点中继它们的通信
- 多跳,无基础设施：
	- 没有基站,节点为了到达目的地可能必须在几个其他无线节点之间中继报文
	- 节点也可能是移动的,在多个节点中改变连接关系,这类网络被称为**移动自组织网络(Mobile Ad hoc NETwork,MANET)**
	- 如果移动节点是车载的,则该网络是**车载自组织网络(Vehicular Ad hoc NETwork,VANET)**

### 2. 无线链路和网络特征    

有线链路与无线链路在许多重要的方面有所不同：
- 递减的信号强度：
	- 电磁波在穿过物体时强度将减弱
	- 即使在自由空间中,信号仍将扩散,这使得信号强度随着发送方和接收方距离的增加而减弱,有时称其为**路径损耗(path loss)**
- 来自其他源的干扰：
	- 在同一频段发送信号的电波源将相互干扰
	- 除了发送源的干扰,环境中的电磁噪声也能形成干扰
- 多路径传播：
	- 当电磁波的一部分受物体和地面反射,在发送方和接收方之间走了不同长度的路径时,则会出现**多经传播(multipath propagation)**,这使得接收方收到的信号变得模糊,位于发送方和接收方之间的移动物体可导致多路径传播时间而改变

因此无线链路协议不仅采用CRC错误检测码,还采用了链路层可靠的数据传送协议来重传受损的帧.   

**CDMA**    

在CDMA中,使用CDMA的每一个站被指派一个唯一的**m bit码片序列(chip sequence)**.    

在每一个比特时间再划分为m个短的间隔,称为**码片(chip)**,m的值通常为64或128.    

要发送的每个比特都乘以被指派的码片序列,得到要发送的码片.    

接收方接收到码片序列后乘以发送方的指派的码片序列,除以m个间隔得到最初的比特.   

>假设初始的比特为B,发送后为BS,S为发送方的码片序列,之后接收方再乘以S得到,BSS,因为正交的关系,自己跟自己正交等于1,得到原有的码片,但由于被分成了m位,所以重复加了m次,为此除以m.     

>假设有干扰,BS+CT,C为别人发送的原数据,T为别人的码片序列.接收方收到之后S(BS+CT),得到BSS+CTS,因为正交后面为0,则得到B.    

CDMA系统的一个重要特点就是这种体制给每一个站分配的码片序列不仅必须各不相同,并且还必须相互**正交(orthogonal)**,在实用的系统中是使用**伪随机码序列**.   

### 3. WiFi：802.11 无线局域网    

#### 3.1 802.11 无线局域网体系结构   

802.11体系结构的基本构建模块是**基本服务集(Basic Service Set,BSS)**.其包含了一个或多个无线站点以及一个在802.11术语中称为**接入点(Access Point,AP)** 的中央**基站(base station)**.   

每一个AP的无线接口也具有一个MAC地址,与以太网类似,这些MAC地址由IEEE管理.    

部署AP的无线局域网经常被称作**基础设施无线局域网(infrastructure wireless LAN)**.其中的基础设施是指AP连同互联AP和一台路由器的有线以太网.   

**信道与关联**   

在802.11中,每个无线站点在能够发送或者接收网络层数据之前,必须与一个AP相关联.     

当安装一个AP时,必须为该AP分配一个单字或双字的**服务集标志符(Service Set Idetifier,SSID)**.还必须为AP分配一个信道号.     

**WIFI丛林(jungle)** 是一个任意物理位置,无线站点能从两个或多个AP中收到很强的信号,这些AP中的每一个都可能位于不同的子网中,并被独立分配一个信道.   

802.11标准要求每个AP周期性地发送信标帧,每个信标帧包括该AP的SSID和MAC地址,通过信标帧了解到可用AP后,选择一个AP用于关联.   

扫描信道和监听信标帧的过程被称为**被动扫描(passive scanning)**.无线主机也能够执行**主动扫描(active scanning)**,这是通过向位于无线主机范围内的所有AP广播探测帧完成的.    

为了与特定的AP创建关联,某无线站点可能要向该AP鉴别它自身,802.11无线局域网提供了几种不同的鉴别和接入方法：
- 基于站点MAC地址接入,许多公司使用
- 使用用户名和口令,许多咖啡屋使用

在这两种情况下,AP通常与一个鉴别服务器进行通信,使用诸如RADIUS和DIAMETER等协议,在无线终端站和鉴别服务器之间中继信息.    

#### 3.2 802.11 MAC协议    

因为许多无线设备或AP自身可能希望同时经过相同信道传输数据帧,所以需要一个多路访问协议来协调传输.    

802.11的设计者为802.11无线局域网选择了一种随机接入协议,这个随机接入协议称作**带碰撞避免的CSMA(CSMA with collision avoidance)**,简称CSMA/CA.   

尽管以太网和802.11都使用载波侦听多址介入,但这种MAC协议有重要的区别：
- 802.11使用碰撞避免技术而非碰撞检测
- 由于无线信道相对较高的比特差错率,802.11使用链路层确认/重传(ARQ)方案

802.11MAC协议并未实现碰撞检测,主要原因：
- 检测碰撞的能力要求站点具有同时发送自己站点的信号和接收的能力检测其他站点是否也在发送的能力,在802.11适配器上,接收信号的强度通常远远小于发送信号的强度,构建具有检测碰撞能力多的硬件代价较大
- 即使适配器可以同时发送和监听信号,也会由于隐藏终端问题和衰减问题而无法检测到所有的碰撞

由于其不使用碰撞检测,一旦站点开始发送一个帧,它就完全地发送该帧,这会严重降低多路访问协议的性能.     

为了处理一个帧不能无损地达到目的站点,802.11MAC使用链路层确认.目的站点收到一个通过CRC校验的帧后,等待一个被称作**短帧间间隔(Short Inter-frame Spacing,SIFS)** 的一小段时间,然后发回一个确认帧.如果发送站点在给定时间内为收到确认帧,它假定出现了错误并重传该帧,使用CSMA/CA协议访问该信道,传输站将放弃发送并丢弃该帧.    

CSMA/CA过程：
1. 如果某站点最初监听到信道空闲,将在一个被称作**分布式帧间间隔(Distributed Inter-frame Space,DIFS)** 的短时间段后发送该帧
2. 否则,该站点选取一个随机回退值并且在侦听到信道空闲时递减该值,当侦听到信道忙时,计数值保持不变
3. 当计数值减为0时,该站点发送整个数据帧并等待确认
4. 如果收到确认,传输站知道它的帧已被目的站正确接收了,如果要继续发送,从第2步开始执行CSMA/CA协议.如果未收到,重新进入第2步中的回退阶段,并从一个更大的范围内选取随机值

802.11并不检测检测碰撞和放弃发送,因此其目标是无论如何都要尽可能地避免碰撞.所以通过这种方式来避免碰撞,但也还是可能会有碰撞.     

##### 3.2.1 处理隐藏终端：RTS和CTS    

802.11MAC协议也包括一个不错的(但为可选项)预约方案,以帮助在出现隐藏终端的情况下避免碰撞.     

IEEE802.11协议允许站点使用短**请求发送(Request to Send,RTS)** 控制帧和**允许发送(Clear to Send,CTS)** 控制帧来预约对信道的访问.    

当发送方要发送一个DATA frame时,它能够首先向AP发送一个RTS frame,指示传输DATA frame和确认帧需要的总时间.   

当AP收到RTS frame后,它广播一个CTS帧作为响应,该CTS frame有两个目的：
- 给发送方明确的发送许可
- 指示其他站点在预约期内不要发送

RTS和CTS frame的使用能够以两种重要方式来提高性能：
- 隐藏终端问题被缓解了,因为长DATA只有在信道预约后才被传输
- 因为RTS和CTS frame较短,涉及RTS和CTS frame的碰撞将仅持续短RTS和CTS frame的持续期,一旦RTS和CTS frame被正确传输,后续的DATA和ACK frame应当能无碰撞地发送

尽管RTS/CTS交换有助于减少碰撞,但它同样引入了时延并消耗了信道资源,因此,RTS/CTS交换仅仅用于为长数据 frame 预约信道.在实际中,每个无线站点可以设置一个RTS阈值,仅当超过阈值时,才使用RTS/CTS序列.对于许多无线站点而言,阈值大于最大帧长,因此不执行该方法.    

##### 3.2.2 使用802.11作为一个点对点链路   

如果两个节点每个都具有一个定向天线,它们可以将其定向天线指向对方,并基本上是在一个点对点的链路上运行802.11协议.   

由于商用802.11硬件产品价格不高,使用定向天线以及增加的传输功率使得802.11成为一个在数十千米距离中提供无线点对点连接的连接的廉价手段.    

#### 3.3 IEEE 802.11帧    

帧(字节长度)    
<table><tr><td align=center>帧控制</td><td align=center>持续期</td><td align=center>地址1</td><td align=center>地址2</td><td align=center>地址3</td><td align=center>序号控制</td><td align=center>地址4</td><td align=center>有效载荷</td><td align=center>CRC</td></tr></table>

帧控制字段扩展(比特长度)    
<table><tr><td align=center>协议版本</td><td align=center>类型</td><td align=center>子类</td><td align=center>到AP</td><td align=center>从(from)AP</td><td align=center>更多标识</td><td align=center>重试</td><td align=center>功率管理</td><td align=center>更多数据</td><td align=center>WEP</td><td align=center>Rsvd</td></tr></table>

- 有效载荷与CRC字段：
	- 帧的核心是有效载荷字段
	- 通常由IP数据报或者ARP分组组成
	- 尽管这一字段允许最大长度为2312字节,但它通常小于1500字节,可放置一个IP数据报或一个ARP分组
	- 802.11帧包括一个32比特的循环冗余检验(CRC),从而接收方可以检测收到帧中的比特错误
- 地址字段：
	- 其有4个地址字段,其中每个都可以包含一个6字节的MAC地址
	- 出于互联目的需要3个地址字段,特别是将网络数据报从一个无线站点通过AP送到路由器接口
	- 当AP在自组织模式中互相转发时使用第四个地址
	- 这里仅考虑基础设施网络,所以只关注前3个地址字段：
		- 地址1是要接收该帧的无线站点的MAC地址,因此,如果一个移动无线站点传输该帧,地址1将包含该目的AP的MAC地址.类似地,如果一个AP传输该帧,地址1将包含该目的无线站点的MAC地址
		- 地址2是传输该帧的站点的MAC地址,因此,如果一个无线站点传输该帧,该站点的MAC地址就被插入地址2字段中,类似地,如果一个AP传输该帧,该AP的MAC地址也被插入地址2字段中
		- 地址3,是包含这个路由器接口的MAC地址,因为AP连接着路由器,路由器与移动主机之间通信不知道隔着AP,所以路由器发送的是标准以太网帧,之后AP将该帧进行转换,1填主机MAC,2填APMAC,3填路由器MAC,发送时,利用Address2,3进行转换
- 序号,持续期和帧控制字段    
	- 使用序号可以使接收方区分新传输的帧和以前帧的重传
	- 传输节点的预约,包括传输其数据帧的时间和传输确认的时间,这个持续期被包括在该帧的持续期字段中(在数据帧和RTS及CTS帧中均存在)
	- 帧控制字段包括许多子字段,其中比较重要的：
		- 类型和子类型字段用于区分关联,RTS,CTS,ACK和数据帧
		- to和from字段用于定义不同地址字段的含义(这些含义因是否使用自组织模式或者基础设施模式而改变,在使用基础设施模式时,也因无线站点或AP是否在发送帧而变化)
		- WEP字段指示了是否使用加密

#### 3.4 在相同的IP子网中的移动性    

为了增加无线局域网的物理范围,公司和大学经常会在同一个IP子网中部署多个BSS.当这些BSS属于同一子网时,移动性可以用一种相对直接的方式解决.当站点在不同子网间移动时,就需要更为复杂的移动性管理协议.     

对于交换机而言,移动主机迁移BBS,不会导致移动主机的IP地址的丢失与TCP连接的失效.但路由器会.    

在交换机中,移动主机迁移BBS,会导致移动主机原本端口的失效,为此,在移动主机与新的AP建立关联时,新AP以移动主机的源地址向交换机发送一以太网广播帧.交换机收到该帧后更新其转发表.      

VLAN也以相同的方式处理.      

#### 3.5 802.11中的高级特色    

##### 3.5.1 802.11速率适应     

当离AP原来越远时,SNR(信噪比)越大越小,如果以相同的高速率

如果一个节点连续发送两个帧而没有收到确认(信道上出现比特差错的隐式指示),该传输速率将降低到前一个较低速率.如果10个帧连续得到确认,或自上次降速以来时间的定时器期满,该传输速率又将提高到上一个较高速率.这种自适应机制与TCP的拥塞控制机制具有相同的"探测"原理,即当条件好时增加传输速率,除非某件坏事发生了,当坏事发生时,则减小传输速率.    

##### 3.5.2 功率管理    

功率是移动设备的宝贵资源,因此802.11标准提供了攻略管理能力,以使802.11节点的侦听,传输,接收功能和其他需要打开电路的时间量最小化.   

运行流程：
- 一个节点能够明确地在睡眠和唤醒状态之间交替,通过将802.11帧首部的功率管理比特设置为1,某节点向接入点指示它打算睡眠
- 设置节点中的一个定时器,以实现正好在AP计划发送它的信标帧前唤醒节点,因为AP从所设置的功率传输比特知道那个节点打算睡眠,所以该AP知道它不应该向这个节点发送任何帧,而是先缓存目的地为睡眠主机的任何帧,待以后再传输
- 在AP发送信标帧前,恰好唤醒节点,并迅速进入全面活跃状态,由AP发送的信标帧包含帧被缓存在AP中的节点的列表
- 如果节点中没有缓存的帧,它能够返回睡眠状态,否则,该节点能够通过向AP发送一个探询报文,明确地请求发送缓存的帧
- 通过250微秒的唤醒时间和类似长度的接收信标帧及检查的时间来确保不存在缓存帧没有帧要发送和接收的节点能够睡眠99%的时间,从而大大节省了能源

#### 3.6 个人域网络：蓝牙   

**蓝牙(Bluetooth)** 的工作距离很短,功耗低且成本低.由于这个原因,蓝牙网络有时被称为**无线个人区域网络(WPAN)** 或者**微微网(piconet)**.   

尽管蓝牙网络设计得比较小而且相对简单,但它们包含了我们之前研究过的许多链路网络技术,包括时分复用(TDM)和频分,随机回退,轮询,错误检测和纠正,以及借助ACK和NAKS的可靠数据传输.这还只是考虑到蓝牙的链路层.     

蓝牙网络运行在不需要执照的2.4Ghz工业,科学和医疗(ISM)无线电波段,与其他家用电器(如微波炉,车库门和无绳电话)一起工作,因此,蓝牙网络在设计时明确考虑了噪声和干扰.    

蓝牙无线信道采用时分复用方式,时隙为625微秒,在每个时隙期间,发送方在79个信道之一中传输,信道(频率)以已知但伪随机的方式从一个时隙改变到另一个时隙.       

这种信道的跳频的形式被称为**跳频扩频(Frequency-Hopping Spread Spectrum,FHSS)**,它的使用是因为来自在ISM频段内操作的其他设备或应用的干扰最多只会干扰这些时隙的一个子集内的蓝牙通信.      

蓝牙数据速率可达3Mbps.    

蓝牙网络是自组织网络,不需要网络基础设施.蓝牙设备必须将自己组织成一个最多有8个活动设备的微微网.将其中一个设备指定为主控设备,其余设备充当客户机.    

主节点真正控制着微微网,它的时钟决定微微网中的时间,它决定时隙到时隙的跳频序列,控制客户设备进入到微微网,控制客户设备的传输功率(100mW,2.5mW或1mW),并在允许客户进入网络后使用轮询来授予客户传输权限.    

除了有源器件,在微微网中还可以有多达255个寄放设备,这些寄放的设备通常处于某种形式的睡眠状态以节省能源,并将根据主服务器的时间表周期性地唤醒,以接收来自主服务器的信标信息.直到寄放设备的状态由主节点从寄放改为活动,它才能通信.

因为蓝牙自组织网络必须是**自组织**的,所以有必要研究它们是如何引导自己的网络结构的：
- 当主节点想要组成蓝牙网络时,必须首先确定哪些蓝牙设备在其覆盖范围内——这是邻居发现问题
- 主节点广播32条询问信息,每条都在不同的频道上,并重复传输序列多达128次
- 客户设备在它选择的频率上监听,希望在这个频率上听到主节点的查询消息
- 当它听到查询消息时,会在0~0.3s之间返回一个随机的时间量(以避免与其他响应节点发生冲突)
- 然后用包含其设备ID的报文来响应主节点
- 一旦主节点发现了范围内的所有潜在客户,就会邀请那些它希望加入微微网的客户
第二个阶段称为**蓝牙寻呼**
- 通过寻呼过程,主机将通知客户要使用跳频模式,以及发送方的时钟
- 主机通过再次发送32条相同的寻呼邀请报文开始寻呼过程,每条报文现在都指向一个特定的客户,但再次使用不同的频率,因为客户还没有学会跳频模式
- 一旦客户回复ACK报文寻呼的邀请报文,主节点就发送跳频信息,时钟同步信息和活跃成员地址给客户
- 最后轮询该客户,此时使用跳频模式,以确保客户与网络连接

更多请看文献.      

### 4. 蜂窝网络：4G和5G    

AP的覆盖范围很小,主机当然不能与它遇到的每一个AP关联,因此,WIFI对于移动用户来说并不是无处不在的.     

相比之下,4G蜂窝网络接入已迅速普及.   

4G互联网接入的普及也催生了无数新的物联网应用,如联网共享自行车和滑板车系统,以及移动支付和基于互联网的消息传递等智能手机应用.     

蜂窝网络一词指的是蜂窝网络覆盖的区域被划分成许多地理覆盖区域,称为**小区**.每个小区都有一个**基站**,向小区内的移动设备发送信号,并从其接收信号.小区的覆盖面积取决于很多因素,包括基站的发射功率,设备的发射功率,小区内的障碍物以及基站天线的高度和类型.    

这里讨论相对简短,更多阅读书上给出的几个东西和文档(自顶向下 8 ed. P 370).   

#### 4.1 4G LTE蜂窝网络：架构和部件    

4G网络将普遍采用4G长期演化(Long-Term Evolution)标准.或更简洁地称为**4GLTE**.     

无线网络大致分为位于蜂窝网络边缘的无线网络和核心网络.所有网络部件之间使用IP协议进行通信.    

4GLTE的各个部件：
- 移动设备：
	- 这是连接到蜂窝运营商网络的智能手机,平板电脑,笔记本电脑或物联网设备
	- 各种应用与服务都在这里运行
	- 通常实现完整的5层协议栈
	- 移动设备是一个网络端点,有一个IP地址(通过NAT获取,如我们后面将看到的那样)
	- 该移动设备还具有全球唯一的64位标识符,称为**国际移动用户身份(IMSI)**,存储在其**SIM(用户身份模块)** 卡上
		- IMSI在全球蜂窝网络系统中识别用户,包括用户所属的国家和归属蜂窝网络
		- 在某些方面,IMSI类似于MAC地址
		- SIM卡还存储有关用户能够访问的服务的信息,并为该用户加密密钥信息
	- 在4GLTE的官方术语中,这种移动设备被称为**用户设备(UE)**
	- 移动设备也可能并不总是移动的,如可能是一个固定的温度传感器,或监控摄像头
- 基站：
	- 位于运营商网络的边缘,负责管理无线电资源和其覆盖区域内的移动设备
	- 移动设备将于连接到运营商网络的基站交互,基站协调无线电接入网中的设备认证和资源分配
		- 从这个意义上说,蜂窝基站功能与无线局域网中的AP具有可比性(但不等同)
		- 蜂窝基站还有一些在无线局域网中没有重要作用
	- 基站创建从移动设备到网关的特定设备的IP隧道,并在它们之间进行交换,以处理小区之间的设备移动性
	- 附近的基站也相互协调,以管理无线电频谱,尽量减少各小区之间的干扰
	- 在4GTLE的官方术语中,该基站被称为eNode-B,这是相当不透明和非描述性的,eNode-B来自早期3G的术语,其中网络功能点被成为节点,B可追溯到更早的1G术语基站(BS)或2G术语收发基站(BTS),4GTLE是对3G的演化,因此,在4GLTE术语中,演化(e)现在位于Node-B之前,在5G,称为ng-eNB
- 归属用户服务器(HSS)：
	- HSS是一个控制平面部件
	- HSS是一个数据库,存储关于移动设备的信息
	- HSS的网络是它们的归属网络
	- 与MME一起用于设备身份验证
- 服务网关(S-GW),PDN网关(P-GW)等其他网络路由器：
	- 服务网关(Services Gateway)和分组数据网络网关(Packet Data Network Gateway)是位于移动设备与因特网之间的数据路径上的两台路由器(在实际应用中通常是并列的)
	- PDN网关还为移动设备提供NAT IP地址,实现NAT功能
	- PDN网关是来自移动设备的数据报在进入更大的因特网之前遇到的最后一个LTE部件
	- 在外界看来,P-GW看起来和其他任何网关路由器没什么两样
	- 移动通信公司LTE网络内移动节点的移动性被隐藏在P-GW之后
	- 除了这些网关路由器,蜂窝网络运营商的全IP核心还会有额外的路由器,其作用与传统的IP路由器类似,即在它们之间沿着路径转发IP数据报,该路径将通常终止于LTE核心网络的部件
- 移动性管理实体(MME)：
	- MME是一个控制平面的部件
	- 与HSS一起,它在验证想要连接到其网络的设备方面起着重要作用
	- 还在从设备到PDN因特网网关路由器的数据路径上建立隧道,并维护有关移动设备在运营商蜂窝网络中的小区位置的信息
	- 不在移动设备收发因特网数据报的转发路径中
	- 身份验证：
		- 连接在网络中的网络和移动设备的相互验证是很重要的：网络知道所连接的设备确实与一个给定的IMSI相关联,移动设备知道它所连接的网络是一个合法的蜂窝运营网络
		- MME在移动归属网络中的移动设备和归属用户服务(HSS)之间起着中间人的作用
			- 在收到来自移动设备的附加请求后,本地MME与移动设备归属网络中的HSS联系
			- 移动设备的归属HSS向本地MME返回足够的加密信息,以向移动设备证明归属网络HSS通过该MME执行真实性,并让移动设备向MME证明确实是与该IMSI关联的移动设备
			- 当移动设备连接到其归属网络时,在身份验证期间要接触的HSS位于同一归属网络中
			- 当移动设备在由不同的蜂窝网络运营商运营的被访网络上漫游时,在漫游网络中的MME将需要与移动设备归属的网络中的HSS联系
	- 路径设置：
		- 从移动设备到运营商网关路由器的数据路径是由移动设备与基站之间的无线第一跳路由器组成的,基站与服务网关以及服务网关与PDN网关串接着IP隧道
		- 在MME的控制之下设置隧道并且用于数据转发
		- 这是为了更好地支持设备移动性,即当设备移动时,只有在基站终止的隧道端点需要更改,而其他隧道端点和服务质量相关的隧道保持不变
	- 小区位置跟踪：
		- 当设备在蜂窝小区间移动时,基站将更新设别位置的MME
		- 如果移动设备处于睡眠模式,但仍然在蜂窝小区间移动,基站就无法追踪设备的位置,这种情况下,MME将负责通过一个称为分页的进程定位用于唤醒的设备

#### 4.2 LTE协议栈   

LTE将移动设备的链路层分为三个子层：
- 分组链路汇聚：
	- 分组数据汇聚协议(PDCP)执行IP首部/压缩,以减少通过无线链路发送的比特数
	- 当移动设备第一次连接到网络时,LTE移动设备和移动性管理实体之间通过信令报文建立的密钥对IP数据报进行加密/解密
- 无线链路控制：
	- 无线链路协议执行两个重要功能：
		- 拆分和重新组转太大的IP数据报,以适合底层链路层帧
		- 通过使用某种基于ACK/NAK的ARQ(自动请求重传)协议,在链路层进行可靠数据传输
- 介质访问控制(MAC)：
	- MAC层执行传输调度
	- 还执行额外的错误检测/校正功能,包括使用冗余位传输作为前向纠错技术,冗余量可以根据信道条件进行调整

#### 4.3 LTE无线电接入网    

LTE在下行信道上使用频分复用和时分复用的组合,称为**正交频分复用(OFDM)**.     

术语正交来自这样一个事实：在不同频率的信道上发送的信号,即使信道频率间隔很紧,它们彼此之间的干扰也很小.     

在LTE中,每个主动移动设备在一个或多个信道频率中被分配一个或多个0.5ms的时隙.     

通过分配越来越多的时隙(无论是在同一频率上还是在不同频率上),移动设备能够实现越来越高的传输速率.      

LTE标准并没有强制规定移动设备的时隙分配,相反,由LTE设备提供商或网络运营商提供的调度算法决定,哪些移动设备将被允许在给定的时隙,给定的频率上进行传输.      

机会主义调度将物理层协议与优先级和合约服务级别之间的通道条件匹配,可用于调度下行分组传输.      

除了上述的LTE能力,高级的LTE通过向移动设备分配聚合通道,允许数百Mbps的下行带宽.        

#### 4.4 LTE附加功能：网络连接和功率管理    

##### 4.4.1 网络连接  

移动设备连接到蜂窝运营商网络的过程大致分为三个阶段：
- 连接到基站
	- 移动设备首先在所有频段的所有信道中搜索主同步信号,该主同步信号由基站每5ms定期广播一次
	- 一旦找到这个信号,移动设备就保持在这个频率上并定位次级同步信号
	- 有了在第二信号中找到的信息,设备可以定位附加信息,如信道带宽,信道配置和该基站的蜂窝载波信息
	- 有了这些信息,移动设备可以选择一个要关联的基站,并通过无线跳与该基站建立一个控制平面信号连接
	- 这个移动节点到基站的通道将在网络连接过程的其余部分中使用
- 相互鉴别：
	- 这是网络连接的第二阶段,允许网络知道所连接的设备确实是与给定的IMSI相关联的设备,并且移动设备知道它所连接的网络也是一个合法的蜂窝移动运营商网络
	- 一旦网络连接的第二阶段完成,MME和移动设备相互鉴别,MME也知道移动设备所连接的基站的身份
	- 有了这些信息,MME现在就可以配置设备到PDN网关
- 移动设备到PDN网关的数据路径配置：
	- MME联系PDN网关,服务网关和基站,以建立数据信道
	- 这个阶段完成,移动设备就能够通过这些信道并通过基站发送/接收IP数据报到互联网

##### 4.2 功率管理：睡眠模式   

在4GLTE中,移动设备可能处于两种不同的睡眠状态之一.     

在不连续的接收状态下,通常在数百毫秒的不活动后进入睡眠状态,移动设备和基站将提前安排周期时间(通常间隔几百毫秒),在此时间移动设备将唤醒并主动监控下行(基站到移动设备)传输的通道,然而,除了这些预定的时间,移动设备的无线电将处于睡眠状态.    

如果不连续的接收状态可以被认为是"浅睡眠",那么第二种睡眠状态即空闲状态可能被认为是"深度睡眠".    

空闲状态的持续更长,为5~10s.    

在这种深度睡眠中,移动设备的无线电会醒来,监听频道的频率会更低.以至于如果移动设备在休眠时移动到运营商网络中的一个新蜂窝,它不需要通知之前与其关联的基站.    

当从这个深度睡眠中周期性地醒来时,移动设备将需要重新建立与基站的关联,以检查MME向该移动设备上次关联的基站附近的基站广播的寻呼报文.    

这些控制平面寻呼报文,由这些基站广播到其小区内的所有移动设备,指示哪些移动设备应该完全苏醒并重新建立到基站的新数据平面连接,以便接收到来的分组.    

#### 4.5 全球蜂窝网络：网络的网络   

用户的归属网络通过归属网络中的一个或多个网关路由器连接到其他蜂窝运营商的网络和全球互联网,移动网络本身通过公共因特网或互联网协议分组交换(IPX)网络互连.IPX是一种专门用于互连蜂窝网络运营商的被管网络,类似于因特网交换点用于ISP之间的对等.      

#### 4.6 5G蜂窝网络     

5G主要是指3GPP采用的"5GNR(新无线电)"标准.然而,除了NR之外,其他5G技术也确实存在.     

5G标准将频率分为两组：
- FR1(450MHz~6GHz)
- FR2(24GHz~52GHz)

5G的物理层(即无线)方面与LTE等4G移动通信系统不向后兼容,特别是不能通过部署基站升级或软件更新来过渡到现有的智能手机.    

FR2频率也被称为毫米波频率.虽然毫米波频率支持更快的数据传输速度,但也有两个主要缺点：
- 毫米波频率使得从基站到接收器的范围要短得多,表明毫米波技术不适用于农村地区,需要在城市地区密集部署基站
- 毫米波通信非常容易受到大气干扰,附近的树叶和雨水会给户外使用带来问题

5G不是一个密切结合的标准,而是由三个共存的标准组合：
- eMBB(增强型移动带宽)：
	- 5GNR的初始部署主要集中在eMBB上,与4GLTE相比,eMBB可以为更高的下载和上传速度提供更高的带宽,并适度降低时延
	- eMBB支持丰富的媒体应用程序,如移动增强现实和虚拟现实,以及移动4K分辨率和360度视频流
- URLLC(极可靠低时延通信)：
	- 目标是满足时延高度敏感的应用程序,如工厂自动化和自动驾驶
	- 目标时延为1ms
- mMTC(大规模机器类型通信)：
	- 是一种窄带接入类型,用于传感,测量和监控应用

5G网络设计的一个优先事项是降低物联网设备的网络连接障碍,除了降低时延外,5G网的新兴技术正专注于降低能源需求,是物联网设备的使用比4GLTE更加普及.        

##### 4.6.1 5G和毫米波频率   

许多5G创新将是在24GHz~52GHz频段的毫米波频率下工作的直接结果.     

这些频率提供了比4G容量增加100倍的潜力.    

将容量定义为：    
容量=小区密度\*可用频谱\*频谱效率    

其中小区密度以小区/km<sup>2</sup>为单位,可用频谱以Hz为单位,频谱效率是衡量每个基站与用户通信效率的指标,以bps/Hz/小区为单位.可得容量的单位是bps/km<sup>2</sup>.   

对于这三个术语中的每一个,5G的值都会比4G大：
- 由于毫米波的频率范围比4GLTE的频率范围小得多,因此需要更多的基站,从而使小区密度变大
- 由于5GFR2(52-24=28GHz)运行在比4GLTE(最高2GHz)更大的频段内,因此可用频谱更多
- 关于频谱效率,信息理论认为,如果想要将频谱效率提高一倍,需要将功率提高17倍.5G没有增加功率,而是使用MIMO技术,该技术在每个基站使用多个天线,每个MIMO天线采用**波束成形**并将信号指向用户,而不是向所有方向广播信号.MIMO技术允许基站在同一频带内同时向10~20个用户发送信号

通过增加容量方程中的所有三项,5G预计将为城市地区提供100倍的容量增长.同样,由于更宽的频带,5G有望提供1Gbps或更高的峰值下载速率.    

然而,毫米波信号很容易被建筑物和树木阻挡,需要小型蜂窝基站来填补基站和用户之间的覆盖缺口.在人口密集地区,两个小区之间的距离可能从10米到100米不等.    

##### 4.6.2 5G核心网络    

**5G核心网络**是管理所有5G移动语音,数据和因特网连接的数据网络.    

5G核心网络中继来自端设备的数据流量,鉴别设备,小区,基站和移动性.    

5G核心网络是为完全分离控制平面和用户平面而设计.完全基于虚拟软件的网络功能组成.这种新架构将为运营商提供灵活性,以满足不同5G应用的不同需要.     

一些5G核心网络功能：
- 用户平面功能(UPF)：
	- 控制平面和用户平面分离允许分组处理进行分布并推到网络边缘
- 5G核心网络实质上将4G移动性管理实体(MME)分解为两个功能元素：
	- 接入和移动性管理功能(AMF)：
		- 接收来自端用户设备的所有连接和会话信息,但只处理连接和移动性管理任务
	- 会话管理功能(SMF)：
		- 负责与解耦的数据平面进行交互
		- 还可以进行IP地址管理,起到DHCP的作用

### 5. 移动性管理原理    

#### 5.1 设备移动性：网络层视角    

从网络层的视角看,发生：    

设备在继续发送和接收IP数据报,并维持更高级别(如TCP)连接的同时改变其接入网.      

设备是移动的.    

在这里,当设备在WLAN或LTE小区之间移动时,网络将需要提供切换,即将数据报转发到AP,从AP转发数据报或基站到移动设备的责任转移.     

如果切换在属于单一网络提供商的接入网中,则该提供者可以自行协调切换.当一个移动设备在多个提供商网络之间漫游时,提供商必须协调切换.    

#### 5.2 归属网络和在被访网络漫游    

当一个设备连接到蜂窝网络但未连接到它的**归属网络(home network)** 时,这个设备被认为是在**被访网络(visited network)漫游(roaming)**.     

当移动设备连接到被访网络并在其上漫游时,归属网络和被访网络之间就需要进行协调.     

在因特网的架构中并没有归属/被访网络的概念.    

移动IP协议是一个综合密切归属/被访网络的建议,在实践中,移动IP的部署/使用非常有限.      

移动设备的归属网络这一概念提供了两个重要的优点：
- 归属网络提供了可以找到该设备信息的单一位置
- 可以作为与漫游的移动设备通信的协调点

#### 5.3 去往/来自移动设备的直接和间接路由   

在移动网络架构中可以使用三种基本方法来使通信方发送的数据报到达移动设备,后两者在实践中得到了采用：
1. 利用现有IP地址的基础设施：
	- 在被访网络中路由到移动设备的最简单方法可能是,简单地使用现有的IP寻址基础设施,即不向其架构添加任何新内容
	- 优点：
		- 不需要改变网络层基础设施
		- 很容易将数据报路由到移动设备
	- 缺点：
		- 可扩展性很差,即网络路由器必须维护数十亿移动设备的转发表象,并在每次设备漫游到不同的网络时更新它的转发表项
2. 到移动设备的间接路由：
	- 在间接路由中,通信方简单地将数据报定位到移动设备的永久地址,并将数据报发送到网络中,不需要知道移动设备是在其归属网络中,还是在被访网络中
3. 到移动设备的直接路由：
	- 直接路由(direct routing)克服了三角路由选择的低效问题,但却是以增加复杂性为代价的
	- 通信方通过在移动设备的归属网络中查询HSS来首先发现移动设备所在的被访网络,然后通信者将数据报从其网络直接通过隧道发送到移动设备的被访网络的网关路由器
	- 尽管直接路由克服了三角路由选择问题,但它引入了两个重要的其他挑战：
		- 通信者需要一个移动用户定位协议来查询HSS,以获得移动设备的被访网络.这是移动设备向其HSS注册位置所需的协议之外的附加协议
		- 当移动节点从一个外部网络移到另一个外部网络时,在直接路由中,不容易处理,因为HSS只在会话开始时由通信者查询,因此需要额外的协议机制在每次移动设备移动时主动更新相应的协议

详细请看书.     

### 6. 实践中的移动性管理     

#### 6.1 4G/5G网络的移动性    

该技术源自早期的3G蜂窝语音和数据网络,甚至更早的2G纯语音网络.   

当移动用户访问网络时：
1. 移动设备和基站关联,移动设备与被访网络中的某基站相关联
2. 移动设备的网元控制平面配置,被访网络和归属网络建立控制平面状态,指示移动设备驻留在被访网络中
3. 移动设备转发隧道的数据平面配置,被访网络和归属网络建立隧道,移动设备和流媒体服务器可以通过归属网络的分组数据网络网关使用间接路由发送/接收IP数据报
4. 移动设备从一个基站切换到另一个基站,移动设备通过从一个基站切换到另一个基站来改变它与被访网络的连接点

更加详细的步骤：
- 基站关联：
	- 通过基站发出的信号,移动设备逐步获取关于这些基站的更多信息,最终选择与之关联的基站m并自举该基站的控制信令通道.作为这种关联的一部分,移动设备向基站提供其国际移动用户标识(IMSI),该标识唯一地标识移动设备及其归属网络和其他附加的用户信息
- 移动设备的LTE网元的控制平面配置：
	- 一旦建立了移动设备到基站的信令通道,基站就可以与被访网络中的MME联系.MME将在归属和被访网络中查阅并配置一些4G/5G元素,以代表移动节点建立状态：
		- MME将使用IMSI和移动设备提供的其他信息,以为该用户检索认证,加密和可用的网络服务信息.该信息可能在MME的本地缓存中,从移动设备最近接触的另一个MME检索,或从移动设备归属网络的HSS检索.相互鉴别过程确保被访网络确定移动设备的身份,并且该设备可以验证它所连接的网络
		- MME通知移动设备归属网络中的HSS,移动设备现在驻留在被访网络中,HSS更新其数据库
		- 基站和移动设备为要在移动设备和基站之间建立的数据平面通道选择参数
- 移动设备转发隧道的数据平面配置：
	- MME接下来为移动设备配置数据平面,有两条隧道：
		- 一条位于基站和被访网络中的服务网关之间
		- 一条在服务网关和移动设备归属网络中的PDN网关路由器之间
		- 4GTLE实现了这种形式的对称间接路由,即所有进出移动设备的流量都将通过设备的归属网络进行隧道传输
		- 4G/5G隧道使用的GPRS隧道协议(GTP)在\[3GPP GTPv1-U 2019]中定义
		- GTP报头中的隧道端点ID(Tunnel Endpoint ID,TEID)指示数据报属于哪个隧道,允许多个流在隧道端点之间通过GTP进行多路复用和多路分解
			- 上面是间接路由的方案,还有一种是其替代方案,叫**本地突围**,只用建立PDN网关和服务网关之间的隧道
		- 一旦隧道已经配置和激活,移动设备就可以通过PDN网关在其归属网络和互联网之间转发分组
- 切换管理：
	- 发生切换的原因：
		- 当前基站和手机之间的信号可能恶化到严重损害通信的程度
		- 一个小区因处理大量的通信而超载,将移动设备移交给附近不那么拥挤的小区可能会缓解拥挤
	- 移动设备周期性地测量当前基站的信标信号以及它能听到的附近基站信号的特征,这些测量每秒钟向移动设备的当前基站报告一两次,根据这些测量结果,附近小区内移动设备的当前载荷以及其他因素,源基站可以选择发起切换
	- 步骤：
		1. 当前基站选择目标基站,并向目标基站发送切换请求消息
		2. 目标基站检查自己是否有资源来支持移动设备及其业务质量要求
			- 如果是,则在其无线电接入网上为该设备预分配信道资源(如,时隙)和其他资源,这种资源预分配将移动设备从耗时基站关联协议中解放出来,允许仅可能快地执行切换.目标基向源基站确认一个切换请求报文,该报文包含移动设备需要与新基站关联的目标基站的所有信息
		3. 源基站接收到切换请求确认报文,并将目标基站的身份信息和信道接入信息告知移动设备,此时,移动设备可以开始向新的目标基站发送/接收数据报.从移动的角度看,切换已经完成,然而,在网络内部仍有一些工作要做
		4. 源基站也将停止向移动设备转发数据报,而是将它接收到的任何隧道化的数据报转发给目标基站,目标基站随后将这些数据报转发给移动设备
		5. 目标基站通知MME将是为移动设备服务的新基站,MME依次向服务网关和目标基站发出信号,以重新配置服务网关到基站隧道,使其在目标基站而不是源基站终止
		6. 目标基站向源基站确认隧道已被重新配置,从而允许源基站释放与该移动设备关联的资源
		7. 此时,目标基站也可以开始向移动设备发送数据报,包括源基站在切换过程中转发给目标基站的数据报,以及从服务网关重新配置后通过隧道到达的新数据报.它还可以将从移动设备接收到的出方向的数据报转发给到服务网关的隧道

#### 6.2 移动IP   

支持移动性的因特网架构和协议统称为移动IP,主要是在用于IPv4的RFC5944中定义的.    

移动IP的总体架构和要素与蜂窝提供商网络惊人地相似.    

在归属网络中,移动设备有一个永久的IP地址,被访网络在移动IP中成为外部网络,在被访网络中,移动设备将被分配一个管理地址.    

移动IP中的归属代理具有与LTE HSS类似的功能：通过接收来自移动主机访问的外部网络中的外部代理的更新信息,追踪移动设备的位置.    

4G/5G和移动IP都使用到移动节点的间接路由,使用隧道连接归属和被访/外部网络的网关路由器.    

移动IP标准包括三个主要部分：
- 代理发现：
	- 移动IP定义了由外部代理所使用的协议,以向希望连接到其网络的移动设备通告其移动服务：
		- 为移动设备提供一个转交地址以在外部网络中使用
		- 在移动设备的归属网络中向移动设备的归属代理注册移动设备
		- 向/从移动设备转发数据报
		- etc.
	- 在归属代理处注册：
		- 移动IP定义了移动设备或外部代理使用的协议,用于向移动设备的归属代理注册和注销一个转交地址
	- 数据报的间接路由：
		- 定义了数据报被归属代理转发到移动设备的方式,包括转发数据报和处理错误条件的规则,以及几种隧道形式

### 7. 无线和移动性：对高层协议的影响   

运输层协议(特别是TCP)在有线和无线网络中**有时**会有完全不同的性能：    
- TCP对于一个报文段不论是丢失还是出错,都将重传它：
	- 在移动用户的情况下,丢失可能源于网络拥塞(路由器缓存溢出)或者切换(列如,由于将报文段重路由到移动用户新的网络接入点时引入的时延)
	- 在所有情况下,TCP的接收方到发送方的ACK都仅仅表明未能收到一个完整的报文段,发送方并不知道报文段是由拥塞或切换,还是由于检测到比特错误而被丢弃的.所以发送方重传报文段
	- TCP隐含地假设报文段丢失是由于拥塞而非出错或者切换所致,无线链路中,比特错误比有线网络中普遍多得多,当这样的比特错误发生或者切换丢失时,没理由让发送方降低其拥塞窗口,从而降低发送速率

有三类方法可用于处理：   
- 本地恢复：
	- 目标是在比特差错出现的当时和当地将其恢复
- TCP发送方知晓无线链路：
	- 让TCP发送方和接收方知道无线链路的存在,从而将在有线网络中发生拥塞性丢包和在无线网络中发生的差错/丢包区分开,并且仅对有线网络中的拥塞性丢包采用拥塞控制
- 分离连接方法：
	- 在该方法中,移动用户和其他端点之间的端到端连接被断开为两个运输层连接：
		- 一个从移动主机到无线接入点
		- 一个从无线接入点到其他通信端点
	- 该端到端连接因此是一个由无线部分和一个有线部分级联形成的
	- 经无线段的运输层可以是一个标准的TCP连接,或是一个特别定制的运行在UDP上的差错恢复协议

**对应用层协议的影响**：   

由于无线频谱的共享特性,在无线链路上操作的应用程序,特别是在蜂窝无线链路上操作的应用程序,必须将带宽是为稀缺商品,比如,提供的Web服务的服务器无法提供与通过有线连接操作的浏览器相同的图像丰富的内容.     

尽管无线链路确实在应用层提供了挑战,但它们所支持的移动性也使一组丰富的位置感知和上下文感知应用程序成为可能.    



## 网络安全  

### 1. 什么是网络安全    

**安全通信(secure communication)** 具有下列性质：
- 机密性(confidentiality)：
	- 仅有发送方和希望的接收方能够理解传输报文的内容
	- 因为窃听者可以截获报文,这必须要求报文在一定程度上进行**加密(encrypted)**,使截取的报文无法被截获者所理解
- 报文完整性(message integrity)：
	- 确保通信的内容在传输过程中未被改变——或者恶意篡改或者意外改动
- 端点鉴别(end-point authentication)：
	- 发送方和接收方都应该能证实通信过程所涉及的另一方,以确信通信的另一方确实具有其所声称的身份
- 运行安全性(operational security)：
	- 反制对机构网络的攻击

入侵者能够潜在地执行下列行为：
- 窃听：
	- 监听并记录信道上传输的控制报文和数据报文
- 插入：
	- 在连接上插入报文
- 删除
- 修改
- 伪装：
	- 可以在分组的源地址写上伪装的地址
- 劫持：
	- 将发送方或者接收方踢出,接管连接
- 拒绝服务：
	- 阻止服务被其他正常用户使用
- etc....

### 2. 密码学原理   

现代主要使用以下两种加密体系：
- **对称密钥系统(symmetric key system)**：发送方和接收方使用相同的密钥
- **公开密钥系统(public key system)**：使用一对密钥,一个密钥为发送方和接收方两人所知,另一个只有一方知道

将报文的最初形式称为**明文(plaintext,cleartext)**.通过**加密算法(encryption algorithm)** 后加密其明文报文,生成的加密报文称为**密文(ciphertext)**.    

#### 2.1 对称密钥密码体制     

**凯撒密码(Caesar cipher)**：将每个字母用字母表中该字母后第k个字母进行替换,允许回绕     
- 一种改进方法是：**单码代替密码(monoalphabetic cipher)**：也是使用字母表中的一个字母替换该字母表中的另一个字母,然而,并非按照规则的模式进行替换,只要每个字母都有一个唯一的替换字母,任一字母就可用另一字母替换
- **多码代替密码(polyalphabetic encryption)**：对单码代替密码的改进,基本思想是使用多个单码代替密码,一个单码代替密码用于加密某明文报文中的一个特定位置的字母,就是约定一个单码序列,在用对应这个位置的序列的单码加密

**DES：Data Encryption Standard**    

- US加密标准
- 54-bit对称密钥,64-bit明文输入
- DES有多安全?
	- 被用了4个的时间破解
	- 可能有后门
- 使DES更安全：
	- 使用3个key,3重DES运算
	- 密文分组成串技术

##### 2.1.1 块密码    

其用于许多安全因特网协议,包括PGP(用于安全电子邮件),TLS(用于使TCP连接安全)和IPsec(用于使网络层传输安全).   

在块密码中,要加密的报文被处理为k比特的块.为了加密一个块,该密码采用了一对一映射,将k比特块的明文映射为k比特块的密文.     

为了阻止蛮力攻击,块密码通常使用由64比特甚至更多比特组成,注意到对于通常的k比特块密码,可能映射数量是2<sup>k</sup>!.    

尽管全表块密码对于不大的k值能够产生健壮的对称密钥加密方案,但不幸的是它们难以实现.因为映射表太大了.     

取而代之的是,块密码通常使用函数模拟随机排列表：
- 首先将64比特块划分为8个块,每个块由8比特组成
- 每个8比特由一个"8比特到8比特"表处理
- 接下来,这8个输出块被重新装配成一个64比特的块,该输出被回馈到64比特的输入,开始第二次循环
- 经过n次循环后,该函数提供了一个64比特的密文块
- 这种块密码算法的密钥将是8张排列表

目前有一些流行的快密码,包括DES,3DES和AES,这些标准都使用了函数,这些算法也都使用了比特串作为密钥,如DES使用了具有56比特密钥的64比特块,AES使用128比特块,能够使用128,192和256比特长的密钥进行操作.    

一个算法密钥决定了特定"小型表"映射和该算法内部的排列,对于这些密码进行蛮力攻击要循环通过所有密钥,使用每个密钥应用解密算法.    

AES: Advanced Encryption Standard   
- 新的对称,密钥NIST标准用于替换DES
- 数据128bit成组加密
- 128,192 or 256 bit keys
- 穷尽法解密如果使用1秒破解DES,需要花149万亿年破解AES   

##### 2.1.2 密码块链接   

如果使用块密码,通过直接将报文切割成k比特块并独立地加密每块,将出现一个微妙而重要的问题,对于两个或更多相同的明文块,块密码当然产生相同的密文,当攻击者看到相同的密文块,它可能潜在地猜出其明文,并且通过识别相同的密文块和利用支撑协议结构的知识,甚至能够解密整个报文.    

为此,可以在密文中混合某些随机性,使得相同的明文块产生不同的密文块,如对每个报文块生成一个随机数,与报文进行XOR操作之后加密,之后将随机数传给接收方进行解密.     

但这样会传输额外的比特,使所需的带宽增加,为了有效利用该技术,块密码通常使用一种称为**密码块链接(Cipher Block Chanining,CBC)** 的技术.其基本思想是仅随第一个报文发送一个随机值,然后让发送方和接收方使用计算的编码块代替后继的随机数.：
- 在加密报文之前,发送方生成一个随机的k比特串,称为**初始向量(Initialization Vector,IV)**,将该IV表示为c(0),发送方以明文方式将IV发送给接收方
- 对于第一个块,发送方计算m(1) XOR c(0),然后通过块密码算法运行得到的结果来得到对应的密文块,发送方想接收方发送加密块c(1)
- 对于第i个块,发送方根据c(i) = K<sub>s</sub>(m(i) XOR c(i-1))生成第i个密文块

当设计安全网络协议时,CBC有一种重要的后果：需要在协议中提供一种机制,以从发送方向接收方分发IV.   

#### 2.2 公开密钥加密   

在对称密钥密码学中,需要发送方和接收方对共享式对称密钥达成一致,但是它们如何第一次达成一致?在它们一辈子都见不到一面的前提下.    

为此产生了公开密钥加密.    

发送方和接收方无需共享密钥.   

将一个实体的公钥公诸于众.   

私钥则只有它自己知道.    

发送方通过公钥加密报文,发送给接收方,接收方通过私钥解密报文.   

因为任何都可以使用公钥,为此需要使用数字签名把发送方和报文绑定起来.    

##### 2.2.1 RSA   

**RSA算法(RSA algorithm,以创立人Ron Rivest,Adi Shamir和Leonard Adleman的姓的首字母命名)** 几乎已经成了公开密钥密码的代名词.    

RSA有两个互相关联的部分：
- 公钥和私钥的选择
- 解密和解密算法

为了生成RSA的公钥和私钥,Bob执行如下步骤：
- 选择两个大素数p和q,该值越大,破解越难,而执行加密和解密所用的时间也越长.RSA实验室推荐,p和q的乘积为1024比特的数量级
- 计算n=pq 和 z=(p-1)(q-1)
- 选择小于n的一个数e,且使e和z没有(非1的)公因数,即使它们互质,使用e表示加密的值
- 求一个数d,使得ed-1可以被z整除,使用d表示解密的值
- 得到公钥(n,e),私钥(n,d)

##### 2.2.2 会话密钥   

RSA所要求的指数运算是相当耗费时间的过程,所以,在实际应用中,RSA通常与对称密钥密码结合起来使用,如,选择一个用于加密数据本身的密钥,这个密钥有时被称为**会话密钥(session key)**,然后通过公钥对其进行加密,接收方解密后得到该会话密钥,这时可以进行对称加密通信.    

##### 2.2.3 RSA的工作原理   

在数论中有一个结论为：如果p和q是素数,且有n=nq和z=(p-1)(q-1),则x<sup>y</sup> mod n 与 x<sup>(y mod z)</sup> mod n是等同的,则(m<sup>e</sup> mod n)<sup>d</sup> mod n = (m<sup>ed</sup> mod n) = m<sup>ed mod z</sup> mod n,因为ed mod z 等于1,所以最终为m mod n = m.   

RSA的安全性依赖于这样的事实：目前没有已知的算法可以快速进行一个数的因数分解,这种情况下公开值n无法快速分解成素数p和q,另一方面,由于不确定是否存在因数分解一个数的快速算法,从这种意义上来说,RSA的安全性也是不确保的.   

另一种流行的公钥加密算法是Diffie-Hellman.它能够用来创建一个对称的会话密钥,该密钥再被用于加密长报文.   

#### 2.3 解密的几种类型   

- 加密算法已知,求密钥
- 加密算法和密钥均不知道

- 唯密文攻击(ciphertext-only attack)
	- 统计分析有助于对加密方案的唯密文攻击
- 已知明文攻击(known-plaintext attack)
	- 已经知道部分密文和明文的对应关系
- 选择明文攻击(chosen-plaintext attack)
	- 攻击者能够选择一段明文,并得到密文

### 3. 报文完整性和数字签名   

#### 3.1 密码散列函数   

**密码散列函数(cryptographic hash function)** 要求具有下列附加的性质：
- 找到任意两个不同的报文x和y使得H(x)=H(y)在计算上是不可能的

不严格地说,这种性质就意味着入侵者在计算上不可能用其他报文替换由散列函数保护的报文.    

Internet检验和：弱的散列函数：
- 具有一些散列函数的特性：
	- 产生报文m的固定长度摘要(16-bit sum)
	- 多对1的
- 但是给定一个散列值,很容易计算出另外一个报文2具有同样的散列值

MD5散列算法如今正在广泛使用,通过4步过程计算得到128比特的散列：
- 填充——先填1,然后填足够多的0,直到报文长度满足一定的条件
- 添加——在填充前添加一个用64比特表示的报文长度
- 初始化累加器
- 循环——在最还的循环步骤中,对报文的16字块进行4轮处理

目前正在使用的第二个主要散列算法是安全散列算法SHA-1(Security Hash Algorithm).    

>MD5和SHA-1都被我国的王小云院士破解了.   


#### 3.2 报文鉴别码   

为了执行报文完整性,除了使用密码散列函数外,通信双方约定一串比特串,称为**鉴别密钥(authentication key)**,通过其加上报文计算散列值得到**报文鉴别码(Message Authentication Code,MAC)**.   

MAC的一个优良特点是它不要求一种加密算法.     

目前最为流行的标准是HMAC,能够与MD5或SHA-1一道使用.   

#### 3.3 数字签名    

在数字领域,人们通常需要指出一个文件的所有者或者创作者,或者表明某人认可一个文件内容.**数字签名(digital signature)** 就是一种在数字领域实现这些目标的密码技术.    

正如手工签名一样,数字签名也应当以可以鉴别的,不可伪造的方式进行.    

对于加密进行数据签名的担心是,加密和解密的计算代价昂贵.更有效的方法是将散列函数引入数字签名.因为散列值通常比报文小的多,所以生成数字签名所需要的计算量大为减少.    

于MAC相比,数字签名是一种技术含量更高的技术,因为它需要一个如后面描述的,具有认证中心支撑的公钥技术设施(PKI).    

**公钥认证**   

数字签名的一个重要应用是**公钥认证(public key certification)**,即证实一个公钥属于某个特定的实体.    

要使公钥密码有用,需要能够证实你具有的公钥实际上就是与你进行通信的实体的公钥.   

因此有两个问题分别针对对称密钥和公共密钥：
- 相互通信的实体如何分享对称式的密钥
	- 通过trusted key distribution center(KDC)
- 将公钥于特定实体绑定通常由**认证中心(Certification Authority,CA)** 完成

CA的职责就是使识别和发行证书合法化,具有以下作用：
- 证实一个实体的真实身份
- 一旦验证了某个实体的身份,这个CA会生成一个将其身份和实体的公钥绑定起来的**证书(certificate)**,这个证书包含这个公钥和公钥所有者全局唯一的身份标识信息.由CA对这个证书进行数字签名

国际电信联盟(International Telecommunication Union,ITU)和IETF都研发了用于CA的系列标准.    

**信任树**   

- 根证书：根证书是未被签名证书或自签名的证书
	- 拿到一些CA的公钥
	- 渠道：安装OS自带的数字签名;从网上下载,你信任的数字证书
- 信任树：
	- 信任根证书CA颁发的证书,拿到了根CA的公钥
		- 信任了根
	- 由根CA签署的给一些机构的数字证书,包含了这些机构的数字证书
	- 由于你信任了根,从而能够可靠地拿到根CA签发的证书,可靠地拿到这些机构的公钥

>这些机构又可以自己给其他机构签发证书,因此成为二级CA,以此类推.   

### 4. 端点鉴别    

**端点鉴别(end-point authentication)** 就是一个实体经过计算机网络向另一个实体证明身份的过程.     

鉴别应当在报文和数据交换的基础上,作为某**鉴别协议(authentication protocol)** 的一部分独立完成,鉴别协议通常在两个通信实体运行其他协议之前运行.鉴别协议首先建立相互满意的各方的标识,仅当鉴别完成之后,各方才继续下面的工作.    

#### 4.1 鉴别协议ap2.0   

将IP地址作为鉴别的信息.   

如果一个人能够访问操作系统代码并能构建自己的操作系统内核：生成一个IP数据报,并在IP数据报中填入我们希望的任何源地址,再通过链路层协议把生成的数据报发送到第一跳路由器.  

这种为IP哄骗的一种形式.如果第一跳路由器被设置为只转发包含攻击者源地址的数据报,就可以避免IP哄骗,然而,这一种措施并未得到广泛采用或强制实施.   

#### 4.2 鉴别协议ap3.0   

使用秘密口令.口令是鉴别者和被鉴别者之间的一个共享秘密.   

Gmail,Facebook,Telnet,FTP和许多其他服务使用口令鉴别.     

如果口令被窃听到了,就很危险.   

#### 4.3 鉴别协议ap3.1   

加密口令.通过加密口令,能防止窃听者得知口令.     

尽管防止了口令被窃取,但此处使用密码术并不能解决鉴别问题.攻击者可以通过**回放攻击(palyback attack)** 的方式来假装用户.   

#### 4.4 鉴别协议ap4.0   

ap3.1失败的原因是因为不能区分用户的初始鉴别报文和后来入侵者回放的报文.即无法判断用户是否还活跃,或接收到的报文是否就是前面鉴别时的回放.     

这里于TCP连接建立时的场景很像,如果一个SYN报文来自较早连接的一个SYN报文段的旧副本,TCP连接的服务器一侧不会接受该连接.    

TCP服务器一侧如何解决判断用户是否真正还活跃的问题呢?——它选择一个很长时间内都不会再次使用的初始序号,把这个序号发给客户,然后等待客户以包含这个序号的ACK报文段来响应.     

此处,能够以相同的思路来解决.    

**不重数(nonce)** 是在一个协议的生存期中只使用一次的数.也就是说,一旦某协议使用了一个不重数,就永远不会再使用那个数字了.   

ap4.0以如下的方式使用一个不重数：
- Alice向Bob发送报文
- Bob选择一个不重数R,然后把R发给Alice
- Alice使用她与Bob共享的对称秘密密钥来加密这个不重数,然后把加密的不重数发回给Bob,由于Alice知道密钥并用它加密了一个值,使得Bob知道收到的报文是由Alice产生的,以确定Alice是活跃的
- Bob解密收到的报文,如果解密得到的不重数等于他发送给Alice的那个不重数,则可鉴别Alice的身份

不重数和对称密钥密码体制的使用形成了ap4.0的基础.一个自然的问题是,是否能够使用不重数和公开密钥密码体制来解决鉴别问题.    

### 5. 安全电子邮件   

#### 5.1 安全电子邮件概述   

在发送电子邮件时,最希望的安全特性：
- 重中之重的是机密性
- 发送方鉴别
- 报文完整性

**机密性**    

直接采用对称公钥的话分发困难,采用公钥的话,效率相对低下.   

为此使用会话密钥的方式：
- 发送方选择一个随机对称会话密钥
- 用这个密钥加密她的报文
- 用接收方的公钥加密这个对称密钥
- 级联该加密报文和加密的对称密钥以形成一个包
- 接收方收到后,用私钥解密得到对称密钥
- 用该密钥解密报文

**发送方鉴别和报文完整性**    

- 发送方对报文应用一个散列函数,得到一个报文摘要
- 用私钥对该摘要进行签名
- 把初始报文和该数字签名级起来生成一个包
- 向接收方发送
- 接收方使用公钥应用到被签名的报文摘要上
- 将该操作的结果与他自己对该报文的散列H进行比较

**机密性,发送方鉴别和报文完整性**   

- 发送方生成一个包,其中包含初始报文和该报文的数字签名过的散列
- 把这个包看作一个报文
- 用**机密性**的方式发送
- 接收方用**机密性**的方式接收,之后应用**发送方鉴别和报文完整性**的步骤

#### 5.2 PGP   

Phil Zimmermann于1991年所写的**PGP(Pretty Good Privacy)** 是电子邮件加密方案的一个范例.    

设计基本上和**机密性,发送方鉴别和报文完整性**的方式一致.    

PGP软件的不同版本使用MD5或SHA来计算报文摘要,使用CAST,三重DES或IDEA进行对称密钥加密,使用RSA进行公开密钥加密.    

安转PGP时,软件为用户产生一个公钥对,该公钥能被张贴到用户的网站上或放置在某台公钥服务器上.私钥则使用用户口令进行保护.用户每次访问私钥都要输入这个口令.    

PGP允许用户选择是否对报文进行数字签名,加密报文,或同时进行数字签名和加密.    

PGP也提供了一种公钥认证机制,但是这种机制与较为传统的CA差异很大.PGP公钥由一个可信Web验证.   

一些PGP用户通过保存密钥签署方(key-signing party)来互相签署对方的密钥.   

### 6. TLS   

#### 6.1 TLS握手   

1. 客户发送它支持的密码算法的列表,连同一个客户的不重数
2. 从该列表中,服务器选择一种对称算法,一种公钥算法和一种HMAC算法,它把它的选择以及证书和一个服务器不重数返回给客户
3. 客户验证该证书,提取服务器的公钥,生成一个**前主密钥(Pre-Master Secret,PMS)**,用服务器的公钥加密该PMS,并将加密的PMS发送给服务器
4. 使用相同的密钥导出函数,客户和服务器独立地从PMS和不重数中计算出**主密钥(Master Secret,MS)**,然后该MS被切片以生成两个密码和两个HMAC密钥,当选择的对称密钥应用于CBC(3DES或AES),则两个初始化向量也从该MS获得,这两个初始化向量分别用于该连接的两端
5. 客户发送所有握手报文的一个HMAC
6. 服务器发送所有握手报文的一个HMAC

#### 6.2 连接关闭   

在类型字段中指出该记录是否用于终止该TLS会话.    

### 7. IPsec   

**IP安全(IP Secrurity)** 协议更常被称为IPSec,它为网络层提供了安全性.    

许多机构使用IPSec创建了运行在公共因特网之上的**虚拟专用网(Virtual Private Network,VPN)**.    

- 网络层次的机密性：
	- 发送端主机对IP数据报中的数据进行加密
	- 数据：TCP或者UDP的段;ICMP和SNMP报文
- 网络层次的可认证性
	- 目标主机可以认证源主机IP地址
- 2个主要协议
	- 认证头部(AH)协议
	- 封装安全载荷(encapsulation security payload(ESP))协议
- 不管AH还是ESP,源和目标通信前要握手：
	- 创建一个网络层次的逻辑通道：安全关联security association
- 每一个SA都是单向的
- 由以下元组唯一确定：
	- 安全协议
	- 源IP地址
	- 32bit连接ID

**Authentication Header**   

- 提供源端的可认证性,数据完整性,但是不提供机密性
- 在IP头部和数据字段之间插入AH的头部
- 协议字段51
- 中间的路由器按照常规处理这个数据报

AH的头部包括：
- 连接ID
- 认证数据：对原始数据计算报文摘要,使用源端的私钥进行数字签名
- 下一个字段：定义了数据类型

**ESP**   

- 提供了机密性,主机的可认证性,数据的完整性
- 数据和ESP尾部部分被加密
- next header字段在ESP尾部
- ESP认证的头部与AH类似
- 协议号50

### 8. 实现安全的无线局域网和4G/5G蜂窝网络   

看书吧.     

### 9. 运行安全性：防火墙和入侵检测系统   

#### 9.1 防火墙   

**防火墙(firewall)** 是一个硬件和软件的结合体,它将一个机构的内部网络与整个因特网隔离开,允许一些数据分组而阻止另一些分组通过.    

防火墙允许网络管理员控制外部和被管理网络内部资源之间的访问,这种控制是通过管理流入和流出这些资源的流量实现的.   

防火墙具有3个目标：
- 从外部到内部和从内部到外部的所有流量都通过防火墙
- 仅被授权的流量允许通过
- 防火墙自身免于渗透

防火墙能够分为3类：
- 传统分组过滤器(traditional packet filter)
- 状态过滤器(stateful filter)
- 应用程序网关(application gateway)

**1. 传统分组过滤器**   

一个机构通常都有一个将其内部网络与其ISP相连的网关路由器.所有离开和进入内部网络的流量都要经过这个路由器,这个路由器正式进行**分组过滤(packet filtering)** 之处.   

分组过滤器独立地检查每个数据报,然后基于管理员特定的规则决定该数据报应当允许通过还是应当丢弃.过滤决定通常基于下列因素：
- IP源或目的地址
- 在IP数据报中的协议类型字段
- TCP或UDP的源和目的端口
- TCP标志比特
- ICMP报文类型
- 数据报离开和进入网络的不同规则
- 对不同路由器接口的不同规则

**2. 状态分组过滤器**   

状态过滤器实际跟踪TCP连接,并使用这种知识作出过滤决定.   

**3. 应用程序网关**    

一个**应用程序网关(application gateway)** 是一个应用程序特定的服务器,所有应用程序数据就必须通过它.多个应用程序网关可以在同一主机上运行,但是每一个网关都是有自己的进程的单独服务器.     

#### 9.2 入侵检测系统   

为了检测多种攻击类型,我们需要执行**深度分组检查(deep packet inspection)**,即查看首部字段以外部分,深入查看分组携带的实际应用数据.    

当观察到潜在恶意流量时能够产生告警的设备称为**入侵检测系统(Intrusion Detection System,IDS)**.   

滤除可疑流量的设备称为**入侵防止系统(Intrusion Prevention System,IPS)**.    

IDS能够用于检测多种攻击,包括网络映射,端口扫描,TCP栈扫描,DoS带宽洪泛攻击,蠕虫和病毒,操作系统脆弱性攻击和应用程序脆弱性攻击.    

IDS系统大致可分类为**基于特征的系统(signature-based system)** 或**基于异常的系统(anomaly-based system)**.    

基于特征维护了一个范围广泛的攻击特征数据库,每个特征是与一个入侵活动相关联的规则集.一个特征可能只是有关单个分组的特征列表,或者可能与一系列分组有关.    

缺点：
- 可能错误判断
- 对没有记录的新攻击缺乏判断力
- 可能处于处理过载状态并因此难以检测出许多恶意分组

基于异常的IDS观察正常运行的流量时,它会生成一个流量概况文件,然后它寻找统计上不寻常的分组流.    

不依赖现有攻击的以前知识.   

缺点：
- 区分正常流量和统计异常流量是一个极具挑战性的问题

目前广泛部署的基于特征的IDS.    
